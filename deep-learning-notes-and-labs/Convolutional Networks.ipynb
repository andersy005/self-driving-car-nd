{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (ConvNets or CNNs)\n",
    "\n",
    "> **Convolutional Networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.** ~ Deep Learning Book\n",
    "\n",
    "\n",
    "# 1. Intuition\n",
    "Let's develop better intuition for how Convolutional Neural Networks (CNN) work. We'll examine how humans classify images, and then see how CNNs use similar approaches.\n",
    "\n",
    "Let’s say we wanted to classify the following image of a dog as a Golden Retriever.\n",
    "<img src=\"assets/golden.jpg\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "\n",
    "As humans, how do we do this?\n",
    "\n",
    "One thing we do is that we identify certain parts of the dog, such as the nose, the eyes, and the fur. We essentially break up the image into smaller pieces, recognize the smaller pieces, and then combine those pieces to get an idea of the overall dog.\n",
    "\n",
    "In this case, we might break down the image into a combination of the following:\n",
    "\n",
    "- A nose\n",
    "- Two eyes\n",
    "- Golden fur\n",
    "\n",
    "\n",
    "These pieces can be seen below:\n",
    "<img src=\"assets/eye.png\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "<img src=\"assets/nose.png\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "<img src=\"assets/fur.png\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "\n",
    "**Going One Step Further**\n",
    "\n",
    "But let’s take this one step further. How do we determine what exactly a nose is? A Golden Retriever nose can be seen as an oval with two black holes inside it. Thus, one way of classifying a Retriever’s nose is to to break it up into smaller pieces and look for black holes (nostrils) and curves that define an oval as shown below.\n",
    "<img src=\"assets/curve.png\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "<img src=\"assets/nostril.png\"  width=\"200\" height=\"40\" alt=\"\">\n",
    "\n",
    "Broadly speaking, this is what a CNN learns to do. It learns to recognize basic lines and curves, then shapes and blobs, and then increasingly complex objects within the image. Finally, the CNN classifies the image by combining the larger, more complex objects.\n",
    "\n",
    "In our case, the levels in the hierarchy are:\n",
    "\n",
    "- Simple shapes, like ovals and dark circles\n",
    "- Complex objects (combinations of simple shapes), like eyes, nose, and fur\n",
    "- The dog as a whole (a combination of complex objects)\n",
    "\n",
    "With deep learning, we don't actually program the CNN to recognize these specific features. Rather, the CNN learns on its own to recognize such objects through forward propagation and backpropagation!\n",
    "\n",
    "It's amazing how well a CNN can learn to classify images, even though we never program the CNN with information about specific features to look for.\n",
    "![](assets/heirarchy-diagram.jpg)\n",
    "\n",
    "A CNN might have several layers, and each layer might capture a different level in the hierarchy of objects. The first layer is the lowest level in the hierarchy, where the CNN generally classifies small parts of the image into simple shapes like horizontal and vertical lines and simple blobs of colors. The subsequent layers tend to be higher levels in the hierarchy and generally classify more complex ideas like shapes (combinations of lines), and eventually full objects like dogs.\n",
    "\n",
    "Once again, the CNN **learns all of this on its own**. We don't ever have to tell the CNN to go looking for lines or curves or noses or fur. The CNN just learns from the training set and discovers which characteristics of a Golden Retriever are worth looking for.\n",
    "\n",
    "That's a good start! Hopefully you've developed some intuition about how CNNs work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Architecture Overview\n",
    "\n",
    "Convolutional Neural Networks (CNN) take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers a ConVNet have neurons arranged in 3 dimensions: **width, height, depth.**\n",
    "\n",
    "1) ![](assets/neural_net2.jpeg)\n",
    "<br><br>\n",
    "2) ![](assets/cnn.jpeg)\n",
    "\n",
    "> 1: A regular 3-layer Neural Network. 2: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels).\n",
    "\n",
    "\n",
    "# 3. Layers used to build ConvNets\n",
    "A simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through \n",
    "a differentiable function. \n",
    "\n",
    "Three main types of layers to build ConvNet architectures:\n",
    "- **Convolutional Layer**\n",
    "- **Pooling Layer**\n",
    "- **Fully-Connected Layer**\n",
    "\n",
    "*Example Architecture:*\n",
    "\n",
    "A simple ConvNet for [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) Classification could have the architecture \n",
    "**[INPUT - CONV - RELU - POOL - FC].**\n",
    "\n",
    "- INPUT[32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R, G, B.\n",
    "- CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters. (Filters are explained in later paragraph)\n",
    "- RELU layer will apply an elementwise activation function, such as the $max(0,x)$ thresholding at zero. This leaves the size of the volume unchanged([32x32x12]).\n",
    "- POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].\n",
    "- FC(full-connected) layer will compute the class scores, resulting in volume of size ([1x1x10]), where each of the 10 numbers correspond to a class score, such as among the 10 categories of  [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Notice that some layers contain parameters and other don't. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons).\n",
    "\n",
    "On the other hand, RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image.\n",
    "\n",
    "In summary:\n",
    "\n",
    "\n",
    "- A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores)\n",
    "- There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular)\n",
    "- Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function\n",
    "- Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don’t)\n",
    "- Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn’t)\n",
    "\n",
    "![](assets/convnet.jpeg)\n",
    "\n",
    "# 5. Convolutional Layer\n",
    "The Convolutional layer is the core building block of a ConvNet that does most of the computational heavy lifting.\n",
    "\n",
    "The CONV layer's parameters consist of a set of learnable filters. Every filter \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 5. Filters\n",
    "The first step for a CNN is to break up the image into smaller pieces We do this by selecting width and height that defines a filter.\n",
    "\n",
    "The filter looks at small pieces, or patches, of the image. These patches are the same size as the filter.\n",
    "![](assets/filter.png)\n",
    "\n",
    "\n",
    "We then simply slide this filter horizontally or vertically to focus on a different piece of the image. \n",
    "\n",
    "The amount by which the filter is referred to as **stride**. The stride is a **hyperparameter** which you, the engineer, can tune. Increasing the stride reduces the size of your model by reducing the number of total patches each layer observes. However, this usually comes with a reduction in accuracy.\n",
    "\n",
    "Example:\n",
    "\n",
    "We first start with the patch outlined in red. The width and height of our filter define the size of this square.\n",
    "\n",
    "<img src=\"assets/dog.png\"  width=\"500\" height=\"400\" alt=\"\">\n",
    "\n",
    "\n",
    "We then move the square over to the right by a given stride (2 in this case) to get another patch.\n",
    "\n",
    "<img src=\"assets/dog2.png\"  width=\"500\" height=\"400\" alt=\"\">\n",
    "\n",
    "What is important here is that we are **grouping together adjacent pixels** and treating them as a collective.\n",
    "\n",
    "In a normal, non ConvNet, we would have ignored this adjacency. In a normal network, we would have connected every pixel in the input image to a neuron in the next layer. In doing so, we would not have taken advantage of the fact that pixels in an image are close together for a reason and have special meaning.\n",
    "\n",
    "By taking advantage of this local structure, our CNN learns to classify local patterns, like shapes and objects, in an image.\n",
    "\n",
    "### Filter Depth\n",
    "It's Common to have more than one filter. Different filters pick up different qualities of a patch. For example, one filter might look for a particular color, while another might look for a kind of object of a specific shape. The amount of filters in a ConvNet layer is called the **filter depth**\n",
    "![](assets/depth.png)\n",
    "In the above example, a patch is connected to a neuron in the next layer. Source: Michael Neilsen.\n",
    "\n",
    "\n",
    "**How many neurons does each patch connect to?**\n",
    "\n",
    "That's dependent on our filter depth. If we have a depth of **k**, we connect each patch of pixels to **k** neurons in the next layer. This gives us the height of **k** in the next layer, as shown below. In practice, **k** is a hyperparameter we tune, and most ConvNets tend to pick the same starting values.\n",
    "\n",
    "<img src=\"assets/filter-depth.png\"  width=\"300\" height=\"250\" alt=\"\">\n",
    "\n",
    "But why connect a single patch to multiple neurons in the next layer? Isn’t one neuron good enough?\n",
    "\n",
    "Multiple neurons can be useful because a patch can have multiple interesting characteristics that we want to capture.\n",
    "\n",
    "For example, one patch might include some white teeth, some blonde whiskers, and part of a red tongue. In that case, we might want a filter depth of at least three - one for each of teeth, whiskers, and tongue.\n",
    "\n",
    "![](assets/teeth-whiskers-tongue.png)\n",
    "\n",
    "This patch of the dog has many interesting features we may want to capture. These include the presence of teeth, the presence of whiskers, and the pink color of the tongue.\n",
    "Having multiple neurons for a given patch ensures that our ConvNet can learn to capture whatever characteristics the CNN learns are important.\n",
    "\n",
    "Remember that the ConvNet isn't \"programmed\" to look for certain characteristics. Rather, it learns on its own which characteristics to notice.\n",
    "\n",
    "**Some useful formulas to calculate feature map sizes** \n",
    "\n",
    "SAME padding equation:\n",
    "```python\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width) / float(strides[2]))\n",
    "```\n",
    "VALID padding equation:\n",
    "```python\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Parameters\n",
    "Convolution leverages three important ideas that can help improve a machine learning system:\n",
    "- Sparse interactions\n",
    "- Parameter sharing\n",
    "- Equivariant representations\n",
    "\n",
    "\n",
    "Traditional NN layers use matrix multiplication by a matrix parameters with a separate parameter describing the interaction between each input unit and each output unit. CNN, however, typically have **sparse interactions**. This is accomplished by making the kernel smaller than the input. For example, when processing an image the input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that occupy only tens or hundreds of pixels.\n",
    "\n",
    "Therefore, we can store fewer parameters and reduce memory requirements of the model.\n",
    "\n",
    "### Parameter Sharing\n",
    "<img src=\"assets/kitten.png\"  width=\"400\" height=\"300\" alt=\"\">\n",
    "\n",
    "\n",
    "**Parameter sharing** refers to using the same parameter for more than one function in a model. In a CNN, each member of the kernels is used at every position of the input(except perhaps some of the boundary pixels, depending on the design decisions regarding the boundary). This reduces the storage requirements of the model to $k$ parameters. \n",
    "\n",
    "\n",
    "In a CNN, the particular form of parameter sharing causes the layer to have a property called **equivariance** to translation. A function is equivariant when the input changes, the output changes the same way. For Example a picture with a kitten in the middle. For a CNN it doesn't matter if the CNN is fed with a picture with a kitten in the corner. It will classify the same kitten as a kitten.\n",
    "\n",
    "When we are trying to classify a picture of a cat, we don’t care where in the image a cat is. If it’s in the top left or the bottom right, it’s still a cat in our eyes. We would like our CNNs to also possess this ability known as translation invariance. How can we achieve this?\n",
    "\n",
    "\n",
    "If we want a cat that’s in the top left patch to be classified in the same way as a cat in the bottom right patch, we need the weights and biases corresponding to those patches to be the same, so that they are classified the same way.\n",
    "\n",
    "This is exactly what we do in CNNs. The weights and biases we learn for a given output layer are shared across all patches in a given input layer. Note that as we increase the depth of our filter, the number of weights and biases we have to learn still increases, as the weights aren't shared across the output channels.\n",
    "\n",
    "There’s an additional benefit to sharing our parameters. If we did not reuse the same weights across all patches, we would have to learn new parameters for every single patch and hidden layer neuron pair. This does not scale well, especially for higher fidelity images. Thus, sharing parameters not only helps us with translation invariance, but also gives us a smaller, more scalable model.\n",
    "\n",
    "**Note:**\n",
    "- Convolution is not naturally equivariant to some other transformations, such as changes in the scale or rotation of an image.\n",
    "\n",
    "### Padding\n",
    "\n",
    "**A 5x5 grid with a 3x3 filter**\n",
    "![](assets/padding.png)\n",
    "\n",
    "\n",
    "Image Courtesy: Andrej Karpathy.\n",
    "\n",
    "Let's say we have a 5x5 grid and a filter of size 3x3 with a stride of 1. What's the width and height of the next layer? We see that we can fit at most three patches in each direction, giving us a dimension of 3x3 in our next layer. As we can see, the width and height of each subsequent layer decreases in such a scheme.\n",
    "\n",
    "\n",
    "In an ideal world, we'd be able to maintain the same width and height across layers so that we can continue to add layers without worrying about the dimensionality shrinking and so that we have consistency. How might we achieve this? One way is to simple add a border of 0s to our original 5x5 image. You can see what this looks like in the below image. \n",
    "Below is the same grid with 0 padding:\n",
    "\n",
    "![](assets/padding2.png)\n",
    "\n",
    "Image Courtesy: Andrej Karpathy.\n",
    "\n",
    "\n",
    "This would expand our original image to a 7x7. With this, we now see how our next layer's size is again a 5x5, keeping our dimensionality consistent.\n",
    "\n",
    "### Dimensionality\n",
    "From what we've learned so far, how can we calculate the number of neurons of each layer in our CNN?\n",
    "\n",
    "Given our input layer has a volume of W, our filter has a volume (height * width * depth) of F, we have a stride of S, and a padding of P, the following formula gives us the volume of the next layer: (W−F+2P)/S+1.\n",
    "\n",
    "Knowing the dimensionality of each additional layer helps us understand how large our model is and how our decisions around filter size and stride affect the size of our network.\n",
    "\n",
    "\n",
    "**1. Convolutional Layer Output Shape**\n",
    "\n",
    "*Introduction*\n",
    "\n",
    "Understanding dimensions will help you make accurate tradeoffs between model size and performance. As you'll see, some parameters have a much bigger impact on model size than others.\n",
    "\n",
    "*Setup*\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "- We have an input of shape 32x32x3 (HxWxD)\n",
    "- 20 filters of shape 8x8x3 (HxWxD)\n",
    "- A stride of 2 for both the height and width (S)\n",
    "- Valid padding of size 1 (P)\n",
    "- Recall the formula for calculating the new height or width:\n",
    "\n",
    "```python \n",
    "new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "```\n",
    "\n",
    "What's the shape of the output?\n",
    "\n",
    "We can get the new height and width with the above formula resulting in:\n",
    "\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "\n",
    "The new depth is equal to the number of filters, which is 20.\n",
    "\n",
    "This would correspond to the following implementation in TensorFlow\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "\n",
    "# (height, width, input_depth, output_depth)\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20)))\n",
    "\n",
    "filter_bias = tf.Variable(tf.Zeros(20))\n",
    "strides = [1, 2, 2, 1] #(batch, height, width, depth)\n",
    "padding = 'VALID'\n",
    "conv = tf.nn.Conv2d(input, filter_weights, strides, padding) + filter_bias\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "Note the output shape of conv will be [1, 13, 13, 20]. It's 4D to account for batch size, but more importantly, it's not [1, 14, 14, 20]. This is because the padding algorithm TensorFlow uses is not exactly the same as the one above. An alternative algorithm is to switch padding from 'VALID' to SAME which would result in an output shape of [1, 16, 16, 20]. If you're curious how padding works in TensorFlow, \n",
    "read this [document](https://www.tensorflow.org/api_docs/python/tf/nn/convolution).\n",
    "\n",
    "\n",
    "**2. Number of Parameters**\n",
    "\n",
    "We're now going to calculate the number of parameters of the convolutional layer. The answer from the last quiz will come into play here!\n",
    "\n",
    "Being able to calculate the number of parameters in a neural network is useful since we want to have control over how much memory a neural network uses.\n",
    "\n",
    "*Setup*\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "- We have an input of shape 32x32x3 (HxWxD)\n",
    "- 20 filters of shape 8x8x3 (HxWxD)\n",
    "- A stride of 2 for both the height and width (S)\n",
    "- Zero padding of size 1 (P)\n",
    "\n",
    "*Output Layer*\n",
    "\n",
    "- 14x14x20 (HxWxD)\n",
    "\n",
    "*Hint*\n",
    "\n",
    "- Without parameter sharing, each neuron in the output layer must connect to each neuron in the filter. In addition, each neuron in the output layer must also connect to a single bias neuron.\n",
    "- Without weight sharing every parameter in the filter has a connection with every neuron in the output. So, what we need to do is calculate the total number of parameters in the filter and the total number of neurons in the output.\n",
    "\n",
    "**Convolution Layer Parameters 1**\n",
    "\n",
    "How many parameters does the convolutional layer have (without parameter sharing)?\n",
    "\n",
    "\n",
    "Solution:\n",
    "\n",
    "There are 756560 total parameters. That's a HUGE amount! Here's how we calculate it:\n",
    "\n",
    "(8 x 8 x 3 + 1) x (14 x 14 x 20) = 756560 \n",
    "\n",
    "8 x 8 x 3 is the number of weights, we add 1 for the bias. Remember, each weight is assigned to every single part of the output (14 x 14 x 20). So we multiply these two numbers together and we get the final answer.\n",
    "\n",
    "\n",
    "\n",
    "**3. Parameter Sharing**\n",
    "\n",
    "Now we'd like you to calculate the number of parameters in the convolutional layer, if every neuron in the output layer shares its parameters with every other neuron in its same channel.\n",
    "\n",
    "This is the number of parameters actually used in a convolution layer ```python (tf.nn.conv2d())```\n",
    "\n",
    "*Setup*\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "- We have an input of shape 32x32x3 (HxWxD)\n",
    "- 20 filters of shape 8x8x3 (HxWxD)\n",
    "- A stride of 2 for both the height and width (S)\n",
    "- Zero padding of size 1 (P)\n",
    "\n",
    "*Output Layer*\n",
    "\n",
    "- 14x14x20 (HxWxD)\n",
    "\n",
    "*Hint*\n",
    "\n",
    "- With parameter sharing, each neuron in an output channel shares its weights with every other neuron in that channel. So the number of parameters is equal to the number of neurons in the filter, plus a bias neuron, all multiplied by the number of channels in the output layer.\n",
    "\n",
    "**Convolution Layer Parameters 2**\n",
    "\n",
    "How many parameters does the convolution layer have (with parameter sharing)?\n",
    "\n",
    "Solution\n",
    "\n",
    "There are 3860 total parameters. That's 196 times fewer parameters! Here's how the answer is calculated:\n",
    "\n",
    "(8 x 8 x 3 + 1) x 20 = 3840 + 20 = 3860\n",
    "\n",
    "That's 3840 weights and 20 biases. This should look similar to the answer from the previous problem. The difference being it's just 20 instead of (14 x 14 x 20). Remember, with weight sharing we use the same filter for an entire depth slice. Because of this we can get rid of 14 x 14 and be left with only 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Visualizing ConvNets\n",
    "\n",
    "Let's look at an example ConvNets to see how they work in action.\n",
    "\n",
    "The CNN we will look at is trained on ImageNet as described in [this paper by Zeiler and Fergus](http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf). In the images below (from the same paper), we’ll see what each layer in this network detects and see how each layer detects more and more complex ideas.\n",
    "\n",
    "**Layer 1** \n",
    "![](assets/layer-1-grid.png)\n",
    "\n",
    "The images above are from [Matthew Zeiler and Rob Fergus' deep visualization toolbox](https://www.youtube.com/watch?v=ghEmQSxT6tw), which lets us visualize what each layer in a CNN focuses on.\n",
    "\n",
    "Each image in the above grid represents a pattern that causes the neurons in the first layer to activate - in other words, they are patterns that the first layer recognizes. The top left image shows a -45 degree line, while the middle top square shows a +45 degree line. \n",
    "\n",
    "Let's now see some example images that cause such activations. The below grid of images all activated the -45 degree line. Notice how they are all selected despite the fact that they have different colors, gradients, and patterns.\n",
    "![](assets/grid-layer-1.png)\n",
    "\n",
    "So, the first layer of our CNN clearly picks out very simple shapes and patterns like lines and blobs.\n",
    "\n",
    "\n",
    "**Layer 2** \n",
    "![](assets/layer2.png)\n",
    "A visualization of the second layer in the CNN. Notice how we are picking up more complex ideas like circles and stripes. The gray grid on the left represents how this layer of the CNN activates (or \"what it sees\") based on the corresponding images from the grid on the right.\n",
    "\n",
    "We'll skip layer 4, which continues this progression, and jump right to the fifth and final layer of this CNN.\n",
    "\n",
    "The last layer picks out the highest order ideas that we care about for classification, like dog faces, bird faces, and bicycles.\n",
    "\n",
    "On to TensorFlow\n",
    "This concludes our high-level discussion of Convolutional Neural Networks.\n",
    "\n",
    "Next we'll practice actually building these networks in TensorFlow.\n",
    "\n",
    "\n",
    "# 8. TensorFlow Convolution Layer\n",
    "\n",
    "Let's examine how to implemement a CNN in TensorFlow.\n",
    "\n",
    "Tensorflow provides the ```python tf.nn.conv2d() and tf.nn.bias_add() ``` functions to create our own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(tf.float32, shape=[None, image_width, image_height, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal([filter_size_width, filter_size_height, color_channels, k_output]))\n",
    "\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "\n",
    "# Apply activation function \n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one more example on how to setup the dimensions of the ConvNet filters, weights, and biases. This is in many ways the trickiest part of using ConvNets in TensorFlow. Once you have a sense of how to set up the dimensions of these attributes, applying CNNs will be far more straight forward.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "our Input is (1,4,4,1)\n",
    "\n",
    "Setup the strides, padding and filter weight/bias (F_w and F_b) such that the output shape is (1, 2, 2, 3). Note that all of these except strides should be TensorFlow variables.\n",
    "\n",
    "Solution:\n",
    "\n",
    "Since we want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 3). we choose 'VALID' for the padding algorithm. we find it simpler to understand and it achieves the result we are looking for.\n",
    "\n",
    "```python\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "```\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "```python\n",
    "out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "```\n",
    "\n",
    "In order to change the depth from 1 to 3, we have to set the output depth of our filter appropriately:\n",
    "\n",
    "```python\n",
    "F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3))) # (height, width, input_depth, output_depth)\n",
    "F_b = tf.Variable(tf.zeros(3)) # (output_depth)\n",
    "```\n",
    "\n",
    "The input has a depth of 1, so we set that as the input_depth of the filter.\n",
    "\n",
    "The depth doesn't change during a pooling operation so we don't have to worry about that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Input (1,4,4,1)\n",
    "x = np.array([\n",
    "        [0, 1, 0.5, 10],\n",
    "        [2, 2.5, 1, -8],\n",
    "        [4, 0, 5, 6],\n",
    "        [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "\n",
    "X = tf.constant(x)\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal((2,2,1,3)))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(1, 2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(1, 2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. TensorFlow Pooling\n",
    "![](assets/pooling.JPG)\n",
    "\n",
    "A typical layer of a convolutional network consists of three stages. \n",
    "- In the first layer, the layer performs several convolutions in parallel to produce a set of linear activations. \n",
    "- In the second layer, each linear activation is run through a non linear activation function, such as the rectified linear activation function. This stage is sometimes called **the detector stage**. \n",
    "- In the third stage, we use a **pooling function** to modify the output of the layer further.\n",
    "\n",
    "A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the *max pooling* operation reports the maximum output within a rectangular neighborhood. \n",
    "\n",
    "Pooling helps to make the representation become approximately *invariant* to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change.\n",
    "\n",
    "Because pooling summarizes the responses over a whole neighborhood, it is possible to use fewer pooling units than detector units, by reporting summary statistics for pooling regions spaced $k$ pixels rather than $1$ pixel apart\n",
    "\n",
    "![](assets/max-pooling.png)\n",
    "\n",
    "The image above is an example of **max pooling** with a 2x2 filter and stride of 2. The four 2x2 colors represent each time the filter was applied to find th maximum value. \n",
    "\n",
    "For example, [[1, 0], [4, 6]] becomes 6, because 6 is the maximum value in this set. Similarly, [[2, 3], [6, 8]] becomes 8.\n",
    "\n",
    "Conceptually, the benefit of the max pooling operation is to reduce the size of the input, and allow the neural network to focus on only the most important elements. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values.\n",
    "\n",
    "TensorFlow provides the *tf.nn.max_pool()* function to apply max pooling to your convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply  Max Pooling\n",
    "conv_layer = tf.nn.max_pool(conv_layer, \n",
    "                           ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1],\n",
    "                           padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tf.nn.max_pool()* function performs max pooling with the ksize parameter as the size of the filter and the strides parameter as the length of the stride. 2x2 filters with a stride of 2x2 are common in practice.\n",
    "\n",
    "The ksize and strides parameters are structured as 4-element lists, with each element corresponding to a dimension of the input tensor ([batch, height, width, channels]). For both ksize and strides, the batch and channel dimensions are typically set to 1.\n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "A pooling layer is generally used to decrease the size of the output and prevent overfitting. Reducing overfitting is a consequence of the reducing the output size, which in turn, reduces the number of parameters in future layers.\n",
    "\n",
    "\n",
    "Recently, pooling layers have fallen out of favor. Some reasons are:\n",
    "\n",
    "- Recent datasets are so big and complex we're more concerned about underfitting.\n",
    "- Dropout is a much better regularizer.\n",
    "- Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of n numbers, thereby disregarding n-1 numbers completely.\n",
    "\n",
    "\n",
    "\n",
    "# 10. Convolutional Network in TensorFlow\n",
    "\n",
    "It's time to walk through an example ConvNet in TensorFlow. \n",
    "\n",
    "The structure of this network follows the classic structure of CNN, which is a mix of convolutional layers and max pooling, followed by fully-connected layers.\n",
    "\n",
    "We are going to use the MNIST dataset. Let's import the MNIST dataset and using a convenient TensorFlow function to batch, scale, and One-Hot encode the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you are running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10   # MNINST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Weights and Biases\n",
    "\n",
    "# Store layers wieght & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutions**\n",
    "![](assets/convolution-schematic.gif)\n",
    "\n",
    "Image courtesy of [UFLDL Tutorial](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)\n",
    "\n",
    "The above is an example of a convolution with a 3x3 filter and a stride of 1 being applied to data with a range of 0 to 1. The convolution for each 3x3 section is calculated against the weight, [[1, 0, 1], [0, 1, 0], [1, 0, 1]], then a bias is added to create the convolved feature on the right. In this case, the bias is zero. In TensorFlow, this is all done using *tf.nn.conv2d()* and *tf.nn.bias_add()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.nn.conv2d() function computes the convolution against weight W as shown above.\n",
    "\n",
    "In TensorFlow, stride is an array of 4 elements; the first element in the stride array indicates the stride for batch and last element indicates stride for features. It's good practice to remove the batches or features you want to skip from the dataset than to use stride. You can always set the first and last element to 1 in order to use all batches and features.\n",
    "\n",
    "The middle two elements are the strides for height and width respectively. I've mentioned stride as one number because you usually have a square stride where height = width. When someone says they are using a stride of 3, they usually mean tf.nn.conv2d(x, W, strides=[1, 3, 3, 1]).\n",
    "\n",
    "To make life easier, the code is using tf.nn.bias_add() to add the bias. Using tf.add() doesn't work when the tensors aren't the same shape.\n",
    "\n",
    "**Max Pooling**\n",
    "\n",
    "![](assets/maxpool.jpeg)\n",
    "\n",
    "The above is an example of max pooling with a 2x2 filter and stride of 2. The left square is the input and the right square is the output. The four 2x2 colors in input represents each time the filter was applied to create the max on the right side. For example, [[1, 1], [5, 6]] becomes 6 and [[3, 2], [1, 2]] becomes 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.nn.max_pool() function does exactly what you would expect, it performs max pooling with the ksize parameter as the size of the filter.\n",
    "\n",
    "**Model**\n",
    "\n",
    "![](assets/arch.png)\n",
    "\n",
    "In the code below, we're creating 3 layers alternating between convolutions and max pooling followed by a fully connected and output layer. The transformation of each layer to new dimensions are shown in the comments. For example, the first layer shapes the images from 28x28x1 to 28x28x32 in the convolution step. Then next step applies max pooling, turning each sample into 14x14x32. All the layers are applied from conv1 to output, producing 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    \n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output Layer - Class prediciton - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 71721.0625 Validation Accuracy: 0.097656\n",
      "Test Accuracy: 0.09765625\n",
      "Epoch  1, Batch   2 - Loss: 43279.5625 Validation Accuracy: 0.066406\n",
      "Test Accuracy: 0.078125\n",
      "Epoch  1, Batch   3 - Loss: 34834.5430 Validation Accuracy: 0.058594\n",
      "Test Accuracy: 0.08984375\n",
      "Epoch  1, Batch   4 - Loss: 29371.1641 Validation Accuracy: 0.093750\n",
      "Test Accuracy: 0.08984375\n",
      "Epoch  1, Batch   5 - Loss: 26687.7305 Validation Accuracy: 0.085938\n",
      "Test Accuracy: 0.09765625\n",
      "Epoch  1, Batch   6 - Loss: 26890.7109 Validation Accuracy: 0.113281\n",
      "Test Accuracy: 0.12109375\n",
      "Epoch  1, Batch   7 - Loss: 27383.0977 Validation Accuracy: 0.105469\n",
      "Test Accuracy: 0.1328125\n",
      "Epoch  1, Batch   8 - Loss: 23837.0684 Validation Accuracy: 0.085938\n",
      "Test Accuracy: 0.13671875\n",
      "Epoch  1, Batch   9 - Loss: 21657.1895 Validation Accuracy: 0.113281\n",
      "Test Accuracy: 0.125\n",
      "Epoch  1, Batch  10 - Loss: 21153.0195 Validation Accuracy: 0.113281\n",
      "Test Accuracy: 0.13671875\n",
      "Epoch  1, Batch  11 - Loss: 23806.5664 Validation Accuracy: 0.101562\n",
      "Test Accuracy: 0.12109375\n",
      "Epoch  1, Batch  12 - Loss: 19737.6406 Validation Accuracy: 0.128906\n",
      "Test Accuracy: 0.15625\n",
      "Epoch  1, Batch  13 - Loss: 15591.6611 Validation Accuracy: 0.148438\n",
      "Test Accuracy: 0.15625\n",
      "Epoch  1, Batch  14 - Loss: 21274.9141 Validation Accuracy: 0.140625\n",
      "Test Accuracy: 0.15625\n",
      "Epoch  1, Batch  15 - Loss: 18849.5195 Validation Accuracy: 0.136719\n",
      "Test Accuracy: 0.16015625\n",
      "Epoch  1, Batch  16 - Loss: 19649.6953 Validation Accuracy: 0.152344\n",
      "Test Accuracy: 0.171875\n",
      "Epoch  1, Batch  17 - Loss: 17313.2910 Validation Accuracy: 0.191406\n",
      "Test Accuracy: 0.1796875\n",
      "Epoch  1, Batch  18 - Loss: 17858.2246 Validation Accuracy: 0.199219\n",
      "Test Accuracy: 0.20703125\n",
      "Epoch  1, Batch  19 - Loss: 16393.9609 Validation Accuracy: 0.199219\n",
      "Test Accuracy: 0.203125\n",
      "Epoch  1, Batch  20 - Loss: 14828.3203 Validation Accuracy: 0.187500\n",
      "Test Accuracy: 0.203125\n",
      "Epoch  1, Batch  21 - Loss: 14831.7578 Validation Accuracy: 0.234375\n",
      "Test Accuracy: 0.1953125\n",
      "Epoch  1, Batch  22 - Loss: 15235.1670 Validation Accuracy: 0.218750\n",
      "Test Accuracy: 0.2109375\n",
      "Epoch  1, Batch  23 - Loss: 15885.4941 Validation Accuracy: 0.234375\n",
      "Test Accuracy: 0.2109375\n",
      "Epoch  1, Batch  24 - Loss: 14446.1875 Validation Accuracy: 0.218750\n",
      "Test Accuracy: 0.20703125\n",
      "Epoch  1, Batch  25 - Loss: 14618.9590 Validation Accuracy: 0.218750\n",
      "Test Accuracy: 0.22265625\n",
      "Epoch  1, Batch  26 - Loss: 17531.6445 Validation Accuracy: 0.257812\n",
      "Test Accuracy: 0.2109375\n",
      "Epoch  1, Batch  27 - Loss: 14012.2324 Validation Accuracy: 0.246094\n",
      "Test Accuracy: 0.23828125\n",
      "Epoch  1, Batch  28 - Loss: 14288.6504 Validation Accuracy: 0.261719\n",
      "Test Accuracy: 0.25\n",
      "Epoch  1, Batch  29 - Loss: 13504.8906 Validation Accuracy: 0.273438\n",
      "Test Accuracy: 0.25\n",
      "Epoch  1, Batch  30 - Loss: 13930.0977 Validation Accuracy: 0.246094\n",
      "Test Accuracy: 0.24609375\n",
      "Epoch  1, Batch  31 - Loss: 12768.5117 Validation Accuracy: 0.273438\n",
      "Test Accuracy: 0.2734375\n",
      "Epoch  1, Batch  32 - Loss: 11616.7773 Validation Accuracy: 0.269531\n",
      "Test Accuracy: 0.2578125\n",
      "Epoch  1, Batch  33 - Loss: 13854.8369 Validation Accuracy: 0.285156\n",
      "Test Accuracy: 0.26953125\n",
      "Epoch  1, Batch  34 - Loss: 11484.2256 Validation Accuracy: 0.316406\n",
      "Test Accuracy: 0.29296875\n",
      "Epoch  1, Batch  35 - Loss: 13783.5918 Validation Accuracy: 0.320312\n",
      "Test Accuracy: 0.28125\n",
      "Epoch  1, Batch  36 - Loss: 12933.6924 Validation Accuracy: 0.335938\n",
      "Test Accuracy: 0.2890625\n",
      "Epoch  1, Batch  37 - Loss: 10593.8496 Validation Accuracy: 0.343750\n",
      "Test Accuracy: 0.30859375\n",
      "Epoch  1, Batch  38 - Loss:  8272.4277 Validation Accuracy: 0.328125\n",
      "Test Accuracy: 0.3046875\n",
      "Epoch  1, Batch  39 - Loss:  8540.2148 Validation Accuracy: 0.375000\n",
      "Test Accuracy: 0.30078125\n",
      "Epoch  1, Batch  40 - Loss: 10654.2666 Validation Accuracy: 0.367188\n",
      "Test Accuracy: 0.3046875\n",
      "Epoch  1, Batch  41 - Loss: 11483.4229 Validation Accuracy: 0.339844\n",
      "Test Accuracy: 0.296875\n",
      "Epoch  1, Batch  42 - Loss:  9073.2070 Validation Accuracy: 0.343750\n",
      "Test Accuracy: 0.3125\n",
      "Epoch  1, Batch  43 - Loss:  7993.4453 Validation Accuracy: 0.355469\n",
      "Test Accuracy: 0.3125\n",
      "Epoch  1, Batch  44 - Loss:  8542.9941 Validation Accuracy: 0.371094\n",
      "Test Accuracy: 0.3203125\n",
      "Epoch  1, Batch  45 - Loss: 10207.4258 Validation Accuracy: 0.378906\n",
      "Test Accuracy: 0.3359375\n",
      "Epoch  1, Batch  46 - Loss:  7339.3311 Validation Accuracy: 0.367188\n",
      "Test Accuracy: 0.33203125\n",
      "Epoch  1, Batch  47 - Loss:  6252.6592 Validation Accuracy: 0.367188\n",
      "Test Accuracy: 0.33984375\n",
      "Epoch  1, Batch  48 - Loss:  6889.3076 Validation Accuracy: 0.386719\n",
      "Test Accuracy: 0.34375\n",
      "Epoch  1, Batch  49 - Loss:  8046.8672 Validation Accuracy: 0.421875\n",
      "Test Accuracy: 0.3671875\n",
      "Epoch  1, Batch  50 - Loss:  8583.9561 Validation Accuracy: 0.421875\n",
      "Test Accuracy: 0.36328125\n",
      "Epoch  1, Batch  51 - Loss:  8565.4756 Validation Accuracy: 0.386719\n",
      "Test Accuracy: 0.34375\n",
      "Epoch  1, Batch  52 - Loss:  9195.3594 Validation Accuracy: 0.394531\n",
      "Test Accuracy: 0.33984375\n",
      "Epoch  1, Batch  53 - Loss:  8851.4326 Validation Accuracy: 0.398438\n",
      "Test Accuracy: 0.359375\n",
      "Epoch  1, Batch  54 - Loss:  8677.1367 Validation Accuracy: 0.382812\n",
      "Test Accuracy: 0.35546875\n",
      "Epoch  1, Batch  55 - Loss:  8869.1982 Validation Accuracy: 0.390625\n",
      "Test Accuracy: 0.36328125\n",
      "Epoch  1, Batch  56 - Loss:  7168.7632 Validation Accuracy: 0.437500\n",
      "Test Accuracy: 0.38671875\n",
      "Epoch  1, Batch  57 - Loss:  9678.2188 Validation Accuracy: 0.429688\n",
      "Test Accuracy: 0.3828125\n",
      "Epoch  1, Batch  58 - Loss:  8482.2021 Validation Accuracy: 0.417969\n",
      "Test Accuracy: 0.36328125\n",
      "Epoch  1, Batch  59 - Loss:  9587.8125 Validation Accuracy: 0.417969\n",
      "Test Accuracy: 0.36328125\n",
      "Epoch  1, Batch  60 - Loss:  9676.2168 Validation Accuracy: 0.433594\n",
      "Test Accuracy: 0.3671875\n",
      "Epoch  1, Batch  61 - Loss:  8072.8828 Validation Accuracy: 0.453125\n",
      "Test Accuracy: 0.39453125\n",
      "Epoch  1, Batch  62 - Loss:  7571.9111 Validation Accuracy: 0.445312\n",
      "Test Accuracy: 0.39453125\n",
      "Epoch  1, Batch  63 - Loss:  8152.0513 Validation Accuracy: 0.449219\n",
      "Test Accuracy: 0.3828125\n",
      "Epoch  1, Batch  64 - Loss:  8503.1895 Validation Accuracy: 0.410156\n",
      "Test Accuracy: 0.40625\n",
      "Epoch  1, Batch  65 - Loss:  7661.7681 Validation Accuracy: 0.453125\n",
      "Test Accuracy: 0.40234375\n",
      "Epoch  1, Batch  66 - Loss:  7536.7427 Validation Accuracy: 0.460938\n",
      "Test Accuracy: 0.4296875\n",
      "Epoch  1, Batch  67 - Loss:  6459.6416 Validation Accuracy: 0.472656\n",
      "Test Accuracy: 0.4140625\n",
      "Epoch  1, Batch  68 - Loss:  5728.0459 Validation Accuracy: 0.464844\n",
      "Test Accuracy: 0.390625\n",
      "Epoch  1, Batch  69 - Loss:  8332.3027 Validation Accuracy: 0.464844\n",
      "Test Accuracy: 0.41015625\n",
      "Epoch  1, Batch  70 - Loss:  8158.2573 Validation Accuracy: 0.472656\n",
      "Test Accuracy: 0.4296875\n",
      "Epoch  1, Batch  71 - Loss: 10514.3535 Validation Accuracy: 0.476562\n",
      "Test Accuracy: 0.41796875\n",
      "Epoch  1, Batch  72 - Loss:  7947.3237 Validation Accuracy: 0.480469\n",
      "Test Accuracy: 0.43359375\n",
      "Epoch  1, Batch  73 - Loss:  8271.9492 Validation Accuracy: 0.488281\n",
      "Test Accuracy: 0.43359375\n",
      "Epoch  1, Batch  74 - Loss:  6909.4111 Validation Accuracy: 0.503906\n",
      "Test Accuracy: 0.4609375\n",
      "Epoch  1, Batch  75 - Loss:  7831.5669 Validation Accuracy: 0.468750\n",
      "Test Accuracy: 0.4296875\n",
      "Epoch  1, Batch  76 - Loss: 10431.3574 Validation Accuracy: 0.484375\n",
      "Test Accuracy: 0.45703125\n",
      "Epoch  1, Batch  77 - Loss:  8558.3867 Validation Accuracy: 0.468750\n",
      "Test Accuracy: 0.43359375\n",
      "Epoch  1, Batch  78 - Loss:  6938.8008 Validation Accuracy: 0.488281\n",
      "Test Accuracy: 0.453125\n",
      "Epoch  1, Batch  79 - Loss:  5614.2393 Validation Accuracy: 0.480469\n",
      "Test Accuracy: 0.44140625\n",
      "Epoch  1, Batch  80 - Loss:  6303.9746 Validation Accuracy: 0.492188\n",
      "Test Accuracy: 0.4375\n",
      "Epoch  1, Batch  81 - Loss:  5167.5449 Validation Accuracy: 0.480469\n",
      "Test Accuracy: 0.4609375\n",
      "Epoch  1, Batch  82 - Loss:  5239.8345 Validation Accuracy: 0.503906\n",
      "Test Accuracy: 0.47265625\n",
      "Epoch  1, Batch  83 - Loss:  5699.3550 Validation Accuracy: 0.511719\n",
      "Test Accuracy: 0.46484375\n",
      "Epoch  1, Batch  84 - Loss:  5712.7559 Validation Accuracy: 0.515625\n",
      "Test Accuracy: 0.46875\n",
      "Epoch  1, Batch  85 - Loss:  8031.1787 Validation Accuracy: 0.519531\n",
      "Test Accuracy: 0.46484375\n",
      "Epoch  1, Batch  86 - Loss:  6495.4238 Validation Accuracy: 0.476562\n",
      "Test Accuracy: 0.46875\n",
      "Epoch  1, Batch  87 - Loss:  5993.6792 Validation Accuracy: 0.488281\n",
      "Test Accuracy: 0.4609375\n",
      "Epoch  1, Batch  88 - Loss:  4901.8818 Validation Accuracy: 0.503906\n",
      "Test Accuracy: 0.453125\n",
      "Epoch  1, Batch  89 - Loss:  5115.3140 Validation Accuracy: 0.503906\n",
      "Test Accuracy: 0.48828125\n",
      "Epoch  1, Batch  90 - Loss:  5687.8848 Validation Accuracy: 0.500000\n",
      "Test Accuracy: 0.4765625\n",
      "Epoch  1, Batch  91 - Loss:  4793.9370 Validation Accuracy: 0.531250\n",
      "Test Accuracy: 0.4765625\n",
      "Epoch  1, Batch  92 - Loss:  5584.0122 Validation Accuracy: 0.531250\n",
      "Test Accuracy: 0.48046875\n",
      "Epoch  1, Batch  93 - Loss:  8053.2412 Validation Accuracy: 0.523438\n",
      "Test Accuracy: 0.4765625\n",
      "Epoch  1, Batch  94 - Loss:  7302.8682 Validation Accuracy: 0.527344\n",
      "Test Accuracy: 0.47265625\n",
      "Epoch  1, Batch  95 - Loss:  6182.4990 Validation Accuracy: 0.554688\n",
      "Test Accuracy: 0.48046875\n",
      "Epoch  1, Batch  96 - Loss:  4770.9233 Validation Accuracy: 0.542969\n",
      "Test Accuracy: 0.48828125\n",
      "Epoch  1, Batch  97 - Loss:  5232.9331 Validation Accuracy: 0.539062\n",
      "Test Accuracy: 0.50390625\n",
      "Epoch  1, Batch  98 - Loss:  7427.3984 Validation Accuracy: 0.535156\n",
      "Test Accuracy: 0.48828125\n",
      "Epoch  1, Batch  99 - Loss:  7206.8296 Validation Accuracy: 0.539062\n",
      "Test Accuracy: 0.48828125\n",
      "Epoch  1, Batch 100 - Loss:  7475.4551 Validation Accuracy: 0.535156\n",
      "Test Accuracy: 0.4921875\n",
      "Epoch  1, Batch 101 - Loss:  5096.0552 Validation Accuracy: 0.523438\n",
      "Test Accuracy: 0.49609375\n",
      "Epoch  1, Batch 102 - Loss:  5893.2715 Validation Accuracy: 0.535156\n",
      "Test Accuracy: 0.5078125\n",
      "Epoch  1, Batch 103 - Loss:  4687.7959 Validation Accuracy: 0.542969\n",
      "Test Accuracy: 0.49609375\n",
      "Epoch  1, Batch 104 - Loss:  5059.8169 Validation Accuracy: 0.550781\n",
      "Test Accuracy: 0.5078125\n",
      "Epoch  1, Batch 105 - Loss:  4961.6240 Validation Accuracy: 0.531250\n",
      "Test Accuracy: 0.5078125\n",
      "Epoch  1, Batch 106 - Loss:  4688.2300 Validation Accuracy: 0.558594\n",
      "Test Accuracy: 0.5234375\n",
      "Epoch  1, Batch 107 - Loss:  4786.0576 Validation Accuracy: 0.535156\n",
      "Test Accuracy: 0.5078125\n",
      "Epoch  1, Batch 108 - Loss:  3763.5632 Validation Accuracy: 0.550781\n",
      "Test Accuracy: 0.51171875\n",
      "Epoch  1, Batch 109 - Loss:  3764.3904 Validation Accuracy: 0.566406\n",
      "Test Accuracy: 0.51171875\n",
      "Epoch  1, Batch 110 - Loss:  4703.1426 Validation Accuracy: 0.554688\n",
      "Test Accuracy: 0.50390625\n",
      "Epoch  1, Batch 111 - Loss:  5344.8652 Validation Accuracy: 0.558594\n",
      "Test Accuracy: 0.51171875\n",
      "Epoch  1, Batch 112 - Loss:  4354.6250 Validation Accuracy: 0.550781\n",
      "Test Accuracy: 0.51953125\n",
      "Epoch  1, Batch 113 - Loss:  3938.3752 Validation Accuracy: 0.554688\n",
      "Test Accuracy: 0.51171875\n",
      "Epoch  1, Batch 114 - Loss:  3533.4873 Validation Accuracy: 0.570312\n",
      "Test Accuracy: 0.5078125\n",
      "Epoch  1, Batch 115 - Loss:  3906.1663 Validation Accuracy: 0.574219\n",
      "Test Accuracy: 0.515625\n",
      "Epoch  1, Batch 116 - Loss:  3933.7493 Validation Accuracy: 0.593750\n",
      "Test Accuracy: 0.51171875\n",
      "Epoch  1, Batch 117 - Loss:  5905.4297 Validation Accuracy: 0.570312\n",
      "Test Accuracy: 0.51953125\n",
      "Epoch  1, Batch 118 - Loss:  6081.3594 Validation Accuracy: 0.539062\n",
      "Test Accuracy: 0.5\n",
      "Epoch  1, Batch 119 - Loss:  5319.1191 Validation Accuracy: 0.558594\n",
      "Test Accuracy: 0.50390625\n",
      "Epoch  1, Batch 120 - Loss:  4449.5381 Validation Accuracy: 0.578125\n",
      "Test Accuracy: 0.53515625\n",
      "Epoch  1, Batch 121 - Loss:  4001.1575 Validation Accuracy: 0.589844\n",
      "Test Accuracy: 0.5234375\n",
      "Epoch  1, Batch 122 - Loss:  3911.7305 Validation Accuracy: 0.589844\n",
      "Test Accuracy: 0.5234375\n",
      "Epoch  1, Batch 123 - Loss:  4025.4548 Validation Accuracy: 0.589844\n",
      "Test Accuracy: 0.515625\n",
      "Epoch  1, Batch 124 - Loss:  5222.7754 Validation Accuracy: 0.605469\n",
      "Test Accuracy: 0.53515625\n",
      "Epoch  1, Batch 125 - Loss:  5361.7017 Validation Accuracy: 0.605469\n",
      "Test Accuracy: 0.546875\n",
      "Epoch  1, Batch 126 - Loss:  2847.9080 Validation Accuracy: 0.605469\n",
      "Test Accuracy: 0.546875\n",
      "Epoch  1, Batch 127 - Loss:  3597.3706 Validation Accuracy: 0.593750\n",
      "Test Accuracy: 0.55078125\n",
      "Epoch  1, Batch 128 - Loss:  4796.2451 Validation Accuracy: 0.589844\n",
      "Test Accuracy: 0.546875\n",
      "Epoch  1, Batch 129 - Loss:  5306.7710 Validation Accuracy: 0.539062\n",
      "Test Accuracy: 0.53125\n",
      "Epoch  1, Batch 130 - Loss:  4099.6890 Validation Accuracy: 0.585938\n",
      "Test Accuracy: 0.5390625\n",
      "Epoch  1, Batch 131 - Loss:  4102.3389 Validation Accuracy: 0.566406\n",
      "Test Accuracy: 0.51953125\n",
      "Epoch  1, Batch 132 - Loss:  2103.4387 Validation Accuracy: 0.566406\n",
      "Test Accuracy: 0.54296875\n",
      "Epoch  1, Batch 133 - Loss:  3161.4392 Validation Accuracy: 0.613281\n",
      "Test Accuracy: 0.5390625\n",
      "Epoch  1, Batch 134 - Loss:  5349.9429 Validation Accuracy: 0.593750\n",
      "Test Accuracy: 0.54296875\n",
      "Epoch  1, Batch 135 - Loss:  4635.7939 Validation Accuracy: 0.605469\n",
      "Test Accuracy: 0.54296875\n",
      "Epoch  1, Batch 136 - Loss:  4600.7627 Validation Accuracy: 0.593750\n",
      "Test Accuracy: 0.54296875\n",
      "Epoch  1, Batch 137 - Loss:  6401.5356 Validation Accuracy: 0.617188\n",
      "Test Accuracy: 0.5390625\n",
      "Epoch  1, Batch 138 - Loss:  6029.8462 Validation Accuracy: 0.613281\n",
      "Test Accuracy: 0.55078125\n",
      "Epoch  1, Batch 139 - Loss:  3632.4395 Validation Accuracy: 0.632812\n",
      "Test Accuracy: 0.55078125\n",
      "Epoch  1, Batch 140 - Loss:  3364.0200 Validation Accuracy: 0.621094\n",
      "Test Accuracy: 0.55859375\n",
      "Epoch  1, Batch 141 - Loss:  2576.5818 Validation Accuracy: 0.617188\n",
      "Test Accuracy: 0.55078125\n",
      "Epoch  1, Batch 142 - Loss:  3076.8579 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.5625\n",
      "Epoch  1, Batch 143 - Loss:  3378.5610 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.55859375\n",
      "Epoch  1, Batch 144 - Loss:  3898.5105 Validation Accuracy: 0.621094\n",
      "Test Accuracy: 0.546875\n",
      "Epoch  1, Batch 145 - Loss:  5098.8350 Validation Accuracy: 0.621094\n",
      "Test Accuracy: 0.546875\n",
      "Epoch  1, Batch 146 - Loss:  5258.0674 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.5625\n",
      "Epoch  1, Batch 147 - Loss:  6086.5361 Validation Accuracy: 0.625000\n",
      "Test Accuracy: 0.5703125\n",
      "Epoch  1, Batch 148 - Loss:  4273.8857 Validation Accuracy: 0.625000\n",
      "Test Accuracy: 0.5859375\n",
      "Epoch  1, Batch 149 - Loss:  5064.9355 Validation Accuracy: 0.628906\n",
      "Test Accuracy: 0.57421875\n",
      "Epoch  1, Batch 150 - Loss:  3652.0969 Validation Accuracy: 0.601562\n",
      "Test Accuracy: 0.5703125\n",
      "Epoch  1, Batch 151 - Loss:  4504.6719 Validation Accuracy: 0.613281\n",
      "Test Accuracy: 0.55078125\n",
      "Epoch  1, Batch 152 - Loss:  3047.7629 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.55859375\n",
      "Epoch  1, Batch 153 - Loss:  4790.3633 Validation Accuracy: 0.644531\n",
      "Test Accuracy: 0.5546875\n",
      "Epoch  1, Batch 154 - Loss:  3465.0728 Validation Accuracy: 0.640625\n",
      "Test Accuracy: 0.56640625\n",
      "Epoch  1, Batch 155 - Loss:  4795.2148 Validation Accuracy: 0.621094\n",
      "Test Accuracy: 0.5546875\n",
      "Epoch  1, Batch 156 - Loss:  4253.2061 Validation Accuracy: 0.644531\n",
      "Test Accuracy: 0.58203125\n",
      "Epoch  1, Batch 157 - Loss:  3094.8674 Validation Accuracy: 0.632812\n",
      "Test Accuracy: 0.57421875\n",
      "Epoch  1, Batch 158 - Loss:  3207.6816 Validation Accuracy: 0.613281\n",
      "Test Accuracy: 0.5546875\n",
      "Epoch  1, Batch 159 - Loss:  4001.2822 Validation Accuracy: 0.628906\n",
      "Test Accuracy: 0.5625\n",
      "Epoch  1, Batch 160 - Loss:  2277.6614 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.5625\n",
      "Epoch  1, Batch 161 - Loss:  2557.7451 Validation Accuracy: 0.632812\n",
      "Test Accuracy: 0.5703125\n",
      "Epoch  1, Batch 162 - Loss:  2660.5034 Validation Accuracy: 0.644531\n",
      "Test Accuracy: 0.57421875\n",
      "Epoch  1, Batch 163 - Loss:  4817.2046 Validation Accuracy: 0.636719\n",
      "Test Accuracy: 0.58203125\n",
      "Epoch  1, Batch 164 - Loss:  4273.2207 Validation Accuracy: 0.640625\n",
      "Test Accuracy: 0.58984375\n",
      "Epoch  1, Batch 165 - Loss:  3916.8062 Validation Accuracy: 0.628906\n",
      "Test Accuracy: 0.5703125\n",
      "Epoch  1, Batch 166 - Loss:  2653.3687 Validation Accuracy: 0.652344\n",
      "Test Accuracy: 0.58984375\n",
      "Epoch  1, Batch 167 - Loss:  2793.6675 Validation Accuracy: 0.644531\n",
      "Test Accuracy: 0.5859375\n",
      "Epoch  1, Batch 168 - Loss:  3882.3406 Validation Accuracy: 0.640625\n",
      "Test Accuracy: 0.5859375\n",
      "Epoch  1, Batch 169 - Loss:  5028.4058 Validation Accuracy: 0.648438\n",
      "Test Accuracy: 0.59765625\n",
      "Epoch  1, Batch 170 - Loss:  4314.2227 Validation Accuracy: 0.640625\n",
      "Test Accuracy: 0.59375\n",
      "Epoch  1, Batch 171 - Loss:  3362.7922 Validation Accuracy: 0.632812\n",
      "Test Accuracy: 0.59375\n",
      "Epoch  1, Batch 172 - Loss:  3020.4839 Validation Accuracy: 0.613281\n",
      "Test Accuracy: 0.60546875\n",
      "Epoch  1, Batch 173 - Loss:  3659.9009 Validation Accuracy: 0.617188\n",
      "Test Accuracy: 0.58984375\n",
      "Epoch  1, Batch 174 - Loss:  4471.3491 Validation Accuracy: 0.578125\n",
      "Test Accuracy: 0.59765625\n",
      "Epoch  1, Batch 175 - Loss:  2644.1221 Validation Accuracy: 0.582031\n",
      "Test Accuracy: 0.578125\n",
      "Epoch  1, Batch 176 - Loss:  3824.4507 Validation Accuracy: 0.582031\n",
      "Test Accuracy: 0.5859375\n",
      "Epoch  1, Batch 177 - Loss:  2335.5337 Validation Accuracy: 0.621094\n",
      "Test Accuracy: 0.59765625\n",
      "Epoch  1, Batch 178 - Loss:  3072.0933 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.58984375\n",
      "Epoch  1, Batch 179 - Loss:  4241.8184 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 180 - Loss:  2658.5659 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.6015625\n",
      "Epoch  1, Batch 181 - Loss:  2544.1062 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.60546875\n",
      "Epoch  1, Batch 182 - Loss:  4467.2300 Validation Accuracy: 0.671875\n",
      "Test Accuracy: 0.6015625\n",
      "Epoch  1, Batch 183 - Loss:  3420.6309 Validation Accuracy: 0.652344\n",
      "Test Accuracy: 0.59375\n",
      "Epoch  1, Batch 184 - Loss:  3265.4482 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.58984375\n",
      "Epoch  1, Batch 185 - Loss:  4751.3823 Validation Accuracy: 0.648438\n",
      "Test Accuracy: 0.609375\n",
      "Epoch  1, Batch 186 - Loss:  3001.5327 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.59765625\n",
      "Epoch  1, Batch 187 - Loss:  4493.5654 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 188 - Loss:  4201.3896 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.62109375\n",
      "Epoch  1, Batch 189 - Loss:  3532.9277 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.61328125\n",
      "Epoch  1, Batch 190 - Loss:  3484.3916 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.609375\n",
      "Epoch  1, Batch 191 - Loss:  3456.9485 Validation Accuracy: 0.632812\n",
      "Test Accuracy: 0.625\n",
      "Epoch  1, Batch 192 - Loss:  3532.8225 Validation Accuracy: 0.652344\n",
      "Test Accuracy: 0.625\n",
      "Epoch  1, Batch 193 - Loss:  3081.5425 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 194 - Loss:  2979.6069 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.61328125\n",
      "Epoch  1, Batch 195 - Loss:  4444.1611 Validation Accuracy: 0.679688\n",
      "Test Accuracy: 0.609375\n",
      "Epoch  1, Batch 196 - Loss:  4398.2202 Validation Accuracy: 0.667969\n",
      "Test Accuracy: 0.62109375\n",
      "Epoch  1, Batch 197 - Loss:  4078.4150 Validation Accuracy: 0.675781\n",
      "Test Accuracy: 0.625\n",
      "Epoch  1, Batch 198 - Loss:  2059.1299 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.6328125\n",
      "Epoch  1, Batch 199 - Loss:  3216.3521 Validation Accuracy: 0.691406\n",
      "Test Accuracy: 0.62890625\n",
      "Epoch  1, Batch 200 - Loss:  3336.7544 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 201 - Loss:  3996.9829 Validation Accuracy: 0.683594\n",
      "Test Accuracy: 0.625\n",
      "Epoch  1, Batch 202 - Loss:  2938.7456 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.60546875\n",
      "Epoch  1, Batch 203 - Loss:  3760.2666 Validation Accuracy: 0.664062\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 204 - Loss:  2296.5500 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 205 - Loss:  4219.3345 Validation Accuracy: 0.667969\n",
      "Test Accuracy: 0.62109375\n",
      "Epoch  1, Batch 206 - Loss:  4188.9014 Validation Accuracy: 0.679688\n",
      "Test Accuracy: 0.63671875\n",
      "Epoch  1, Batch 207 - Loss:  3069.3748 Validation Accuracy: 0.671875\n",
      "Test Accuracy: 0.61328125\n",
      "Epoch  1, Batch 208 - Loss:  3289.0015 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.625\n",
      "Epoch  1, Batch 209 - Loss:  5489.4937 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.62890625\n",
      "Epoch  1, Batch 210 - Loss:  3150.2114 Validation Accuracy: 0.667969\n",
      "Test Accuracy: 0.6171875\n",
      "Epoch  1, Batch 211 - Loss:  3254.7451 Validation Accuracy: 0.667969\n",
      "Test Accuracy: 0.640625\n",
      "Epoch  1, Batch 212 - Loss:  2934.2617 Validation Accuracy: 0.675781\n",
      "Test Accuracy: 0.6484375\n",
      "Epoch  1, Batch 213 - Loss:  3280.3499 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 214 - Loss:  4407.8892 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 215 - Loss:  4124.9287 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 216 - Loss:  2728.5693 Validation Accuracy: 0.660156\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 217 - Loss:  2312.2842 Validation Accuracy: 0.656250\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 218 - Loss:  3286.9453 Validation Accuracy: 0.679688\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 219 - Loss:  2384.5977 Validation Accuracy: 0.679688\n",
      "Test Accuracy: 0.64453125\n",
      "Epoch  1, Batch 220 - Loss:  4094.4561 Validation Accuracy: 0.675781\n",
      "Test Accuracy: 0.6484375\n",
      "Epoch  1, Batch 221 - Loss:  2537.5994 Validation Accuracy: 0.691406\n",
      "Test Accuracy: 0.64453125\n",
      "Epoch  1, Batch 222 - Loss:  3645.3647 Validation Accuracy: 0.679688\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 223 - Loss:  2200.7188 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.62890625\n",
      "Epoch  1, Batch 224 - Loss:  2027.8839 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.6328125\n",
      "Epoch  1, Batch 225 - Loss:  2363.4858 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.64453125\n",
      "Epoch  1, Batch 226 - Loss:   724.8885 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.65625\n",
      "Epoch  1, Batch 227 - Loss:  2590.1055 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.65625\n",
      "Epoch  1, Batch 228 - Loss:  2123.0386 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 229 - Loss:  1583.0161 Validation Accuracy: 0.691406\n",
      "Test Accuracy: 0.66796875\n",
      "Epoch  1, Batch 230 - Loss:  3363.6802 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.640625\n",
      "Epoch  1, Batch 231 - Loss:  3803.5288 Validation Accuracy: 0.675781\n",
      "Test Accuracy: 0.63671875\n",
      "Epoch  1, Batch 232 - Loss:  2880.0696 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.671875\n",
      "Epoch  1, Batch 233 - Loss:  3253.7839 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.65234375\n",
      "Epoch  1, Batch 234 - Loss:  3366.4761 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 235 - Loss:  2079.8596 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.6484375\n",
      "Epoch  1, Batch 236 - Loss:  3112.0146 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 237 - Loss:  2761.9414 Validation Accuracy: 0.691406\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 238 - Loss:  2776.3269 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.671875\n",
      "Epoch  1, Batch 239 - Loss:  1989.8857 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.671875\n",
      "Epoch  1, Batch 240 - Loss:  2706.8118 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.6640625\n",
      "Epoch  1, Batch 241 - Loss:  2644.1064 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.6484375\n",
      "Epoch  1, Batch 242 - Loss:  2627.7317 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.66796875\n",
      "Epoch  1, Batch 243 - Loss:  2562.6897 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.6484375\n",
      "Epoch  1, Batch 244 - Loss:  2528.2593 Validation Accuracy: 0.714844\n",
      "Test Accuracy: 0.62890625\n",
      "Epoch  1, Batch 245 - Loss:  1733.3563 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.640625\n",
      "Epoch  1, Batch 246 - Loss:  3286.1047 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.6640625\n",
      "Epoch  1, Batch 247 - Loss:  3610.0078 Validation Accuracy: 0.707031\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 248 - Loss:  2408.5852 Validation Accuracy: 0.687500\n",
      "Test Accuracy: 0.6640625\n",
      "Epoch  1, Batch 249 - Loss:  3676.8552 Validation Accuracy: 0.707031\n",
      "Test Accuracy: 0.65625\n",
      "Epoch  1, Batch 250 - Loss:  1808.8772 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 251 - Loss:  3439.5908 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 252 - Loss:  2951.0676 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.671875\n",
      "Epoch  1, Batch 253 - Loss:  3326.7473 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.66015625\n",
      "Epoch  1, Batch 254 - Loss:  2959.2178 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.63671875\n",
      "Epoch  1, Batch 255 - Loss:  3582.8923 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 256 - Loss:  2639.3533 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.66796875\n",
      "Epoch  1, Batch 257 - Loss:  3174.4824 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 258 - Loss:  2022.9684 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 259 - Loss:  2476.0886 Validation Accuracy: 0.707031\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 260 - Loss:  3062.4055 Validation Accuracy: 0.699219\n",
      "Test Accuracy: 0.65625\n",
      "Epoch  1, Batch 261 - Loss:  2682.0325 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.66796875\n",
      "Epoch  1, Batch 262 - Loss:  2247.2485 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 263 - Loss:  2584.4133 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 264 - Loss:  2122.5405 Validation Accuracy: 0.707031\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 265 - Loss:  2223.9644 Validation Accuracy: 0.714844\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 266 - Loss:  2296.7136 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 267 - Loss:  1115.0596 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 268 - Loss:  1905.7327 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 269 - Loss:  3639.7837 Validation Accuracy: 0.695312\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 270 - Loss:  1901.1047 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 271 - Loss:  1911.4254 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 272 - Loss:  3330.6252 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 273 - Loss:  3124.6902 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 274 - Loss:  1896.1218 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 275 - Loss:  2387.4341 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 276 - Loss:  2629.4297 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 277 - Loss:  2411.5466 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 278 - Loss:  3385.4082 Validation Accuracy: 0.703125\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 279 - Loss:  2130.0259 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 280 - Loss:  1526.3827 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 281 - Loss:  1735.0417 Validation Accuracy: 0.707031\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 282 - Loss:  3320.5840 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 283 - Loss:  2174.0090 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 284 - Loss:  3107.9189 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 285 - Loss:  3408.7014 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 286 - Loss:  2776.3032 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 287 - Loss:  1628.6102 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.671875\n",
      "Epoch  1, Batch 288 - Loss:  2021.6833 Validation Accuracy: 0.738281\n",
      "Test Accuracy: 0.7109375\n",
      "Epoch  1, Batch 289 - Loss:  2568.6118 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.71484375\n",
      "Epoch  1, Batch 290 - Loss:  2230.8232 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.71484375\n",
      "Epoch  1, Batch 291 - Loss:  3058.5408 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 292 - Loss:  4206.8022 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 293 - Loss:  2765.4910 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 294 - Loss:  1745.3834 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 295 - Loss:  2868.6362 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 296 - Loss:  2776.9644 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.71484375\n",
      "Epoch  1, Batch 297 - Loss:  3121.1743 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 298 - Loss:  2660.5842 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 299 - Loss:  1573.9038 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 300 - Loss:  2166.0801 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 301 - Loss:  1479.7939 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 302 - Loss:  1639.8276 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 303 - Loss:  1819.2357 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 304 - Loss:  2853.8181 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.6640625\n",
      "Epoch  1, Batch 305 - Loss:  1809.5238 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.66796875\n",
      "Epoch  1, Batch 306 - Loss:  2669.1672 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.6796875\n",
      "Epoch  1, Batch 307 - Loss:  2301.4507 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 308 - Loss:  2578.4575 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 309 - Loss:  2025.0198 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 310 - Loss:  1672.8063 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 311 - Loss:  2494.8574 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 312 - Loss:  2713.6465 Validation Accuracy: 0.738281\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 313 - Loss:  2301.5581 Validation Accuracy: 0.726562\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 314 - Loss:  2639.8579 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 315 - Loss:  1291.3469 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 316 - Loss:  2253.1528 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 317 - Loss:  2176.4775 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 318 - Loss:  2409.4341 Validation Accuracy: 0.757812\n",
      "Test Accuracy: 0.6953125\n",
      "Epoch  1, Batch 319 - Loss:  2520.3896 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 320 - Loss:  2358.7666 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.68359375\n",
      "Epoch  1, Batch 321 - Loss:  2504.4150 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 322 - Loss:  2837.8374 Validation Accuracy: 0.738281\n",
      "Test Accuracy: 0.67578125\n",
      "Epoch  1, Batch 323 - Loss:  2057.3389 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.69140625\n",
      "Epoch  1, Batch 324 - Loss:  2387.1831 Validation Accuracy: 0.738281\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 325 - Loss:  2695.0671 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 326 - Loss:  1770.1716 Validation Accuracy: 0.710938\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 327 - Loss:  1537.6897 Validation Accuracy: 0.722656\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 328 - Loss:  2438.5933 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.7109375\n",
      "Epoch  1, Batch 329 - Loss:  1919.2078 Validation Accuracy: 0.718750\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 330 - Loss:  1966.7483 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 331 - Loss:  3404.9250 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 332 - Loss:  3230.9302 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.73046875\n",
      "Epoch  1, Batch 333 - Loss:  2560.1877 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.6875\n",
      "Epoch  1, Batch 334 - Loss:  2339.0269 Validation Accuracy: 0.757812\n",
      "Test Accuracy: 0.71484375\n",
      "Epoch  1, Batch 335 - Loss:  2337.6123 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 336 - Loss:  2560.7737 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 337 - Loss:  1421.5410 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 338 - Loss:  2316.8250 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 339 - Loss:  2149.2236 Validation Accuracy: 0.757812\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 340 - Loss:  1679.4856 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 341 - Loss:  1799.5862 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 342 - Loss:  1977.1494 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 343 - Loss:  1779.9479 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 344 - Loss:  3270.1079 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 345 - Loss:  3917.6367 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 346 - Loss:  2731.7764 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 347 - Loss:  1952.2185 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 348 - Loss:  3874.1299 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 349 - Loss:  3552.3926 Validation Accuracy: 0.777344\n",
      "Test Accuracy: 0.69921875\n",
      "Epoch  1, Batch 350 - Loss:  1852.9000 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.71484375\n",
      "Epoch  1, Batch 351 - Loss:  2914.6553 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 352 - Loss:  2540.4868 Validation Accuracy: 0.730469\n",
      "Test Accuracy: 0.73046875\n",
      "Epoch  1, Batch 353 - Loss:  1772.0773 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 354 - Loss:  2468.7612 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 355 - Loss:  4057.7390 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.703125\n",
      "Epoch  1, Batch 356 - Loss:  2678.0464 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 357 - Loss:  2950.5730 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 358 - Loss:  2228.0176 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.7265625\n",
      "Epoch  1, Batch 359 - Loss:  1574.4790 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 360 - Loss:  1473.4292 Validation Accuracy: 0.742188\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 361 - Loss:  2187.3030 Validation Accuracy: 0.738281\n",
      "Test Accuracy: 0.73046875\n",
      "Epoch  1, Batch 362 - Loss:  2656.5596 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 363 - Loss:  1237.8521 Validation Accuracy: 0.734375\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 364 - Loss:  2345.4326 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 365 - Loss:  1878.3966 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 366 - Loss:  1669.6687 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 367 - Loss:  1382.4856 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 368 - Loss:  2419.7717 Validation Accuracy: 0.757812\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 369 - Loss:  3365.3379 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.71875\n",
      "Epoch  1, Batch 370 - Loss:  2537.0674 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 371 - Loss:  1699.0851 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 372 - Loss:  1391.9197 Validation Accuracy: 0.757812\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 373 - Loss:  2336.5186 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.7265625\n",
      "Epoch  1, Batch 374 - Loss:  1955.3330 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 375 - Loss:  2826.9136 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 376 - Loss:  2276.7883 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.7109375\n",
      "Epoch  1, Batch 377 - Loss:  1894.0311 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.70703125\n",
      "Epoch  1, Batch 378 - Loss:  1801.9685 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.7265625\n",
      "Epoch  1, Batch 379 - Loss:  1857.6082 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 380 - Loss:  2299.7314 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 381 - Loss:  1515.8997 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 382 - Loss:  1289.7866 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 383 - Loss:  2212.8230 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 384 - Loss:  2157.5183 Validation Accuracy: 0.777344\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 385 - Loss:  1515.7379 Validation Accuracy: 0.777344\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 386 - Loss:  2176.6719 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  1, Batch 387 - Loss:  2676.9985 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 388 - Loss:  1612.0773 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 389 - Loss:  1590.4727 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 390 - Loss:  1838.6111 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 391 - Loss:  3049.5630 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.73046875\n",
      "Epoch  1, Batch 392 - Loss:   909.8354 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  1, Batch 393 - Loss:  1706.5652 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 394 - Loss:  2072.5933 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  1, Batch 395 - Loss:  2134.7163 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 396 - Loss:  1557.0863 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  1, Batch 397 - Loss:  1552.5378 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  1, Batch 398 - Loss:  1956.3986 Validation Accuracy: 0.746094\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 399 - Loss:  1915.3016 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 400 - Loss:  1866.4451 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 401 - Loss:  2725.7053 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  1, Batch 402 - Loss:  1910.6150 Validation Accuracy: 0.753906\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 403 - Loss:  1885.8423 Validation Accuracy: 0.761719\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  1, Batch 404 - Loss:  1448.6255 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  1, Batch 405 - Loss:  1658.3237 Validation Accuracy: 0.777344\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  1, Batch 406 - Loss:  1569.2068 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  1, Batch 407 - Loss:  1791.7306 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 408 - Loss:  1016.0609 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  1, Batch 409 - Loss:  2319.7195 Validation Accuracy: 0.765625\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  1, Batch 410 - Loss:  1907.9556 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  1, Batch 411 - Loss:  1852.0568 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 412 - Loss:  2712.7561 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.7265625\n",
      "Epoch  1, Batch 413 - Loss:  1063.4553 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 414 - Loss:  1943.6436 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 415 - Loss:  1298.3456 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 416 - Loss:   778.1396 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 417 - Loss:  1012.4752 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 418 - Loss:  1679.7097 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.72265625\n",
      "Epoch  1, Batch 419 - Loss:  1402.8870 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  1, Batch 420 - Loss:   932.7219 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  1, Batch 421 - Loss:  1698.7095 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  1, Batch 422 - Loss:   367.7040 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.75\n",
      "Epoch  1, Batch 423 - Loss:   297.4503 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  1, Batch 424 - Loss:   923.5143 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.73046875\n",
      "Epoch  1, Batch 425 - Loss:  2877.2979 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  1, Batch 426 - Loss:  1700.9502 Validation Accuracy: 0.750000\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  1, Batch 427 - Loss:  1016.7832 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  1, Batch 428 - Loss:  2683.6650 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  1, Batch 429 - Loss:   824.7800 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch   1 - Loss:  1801.9421 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch   2 - Loss:  1995.2751 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  2, Batch   3 - Loss:  2021.0337 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.75\n",
      "Epoch  2, Batch   4 - Loss:   964.2973 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  2, Batch   5 - Loss:  2145.5298 Validation Accuracy: 0.769531\n",
      "Test Accuracy: 0.734375\n",
      "Epoch  2, Batch   6 - Loss:  1487.7463 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.75\n",
      "Epoch  2, Batch   7 - Loss:  2468.4346 Validation Accuracy: 0.777344\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  2, Batch   8 - Loss:  1585.3689 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  2, Batch   9 - Loss:  1391.1584 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  2, Batch  10 - Loss:  3081.0698 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.73828125\n",
      "Epoch  2, Batch  11 - Loss:  2132.1812 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.75\n",
      "Epoch  2, Batch  12 - Loss:  2020.3232 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  2, Batch  13 - Loss:  1667.5444 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.7421875\n",
      "Epoch  2, Batch  14 - Loss:  2068.8254 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  2, Batch  15 - Loss:  1462.5099 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  2, Batch  16 - Loss:  1803.4910 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  17 - Loss:  3000.3044 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  18 - Loss:  2022.7224 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  19 - Loss:  1710.0308 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  20 - Loss:  2295.7344 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  21 - Loss:  1518.5559 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  22 - Loss:  1303.8336 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  23 - Loss:  1854.3840 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  2, Batch  24 - Loss:  1962.5132 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  25 - Loss:  2242.4556 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  26 - Loss:  1221.0862 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  27 - Loss:  1984.6492 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  28 - Loss:  1687.1726 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  2, Batch  29 - Loss:  2366.0176 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.75\n",
      "Epoch  2, Batch  30 - Loss:  2307.7729 Validation Accuracy: 0.773438\n",
      "Test Accuracy: 0.74609375\n",
      "Epoch  2, Batch  31 - Loss:  1896.0592 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  2, Batch  32 - Loss:  1998.0483 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  33 - Loss:  1842.3094 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  34 - Loss:  1901.6797 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  35 - Loss:  1033.1504 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  36 - Loss:  1935.4280 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  37 - Loss:  2056.8584 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  38 - Loss:  1842.1946 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.75390625\n",
      "Epoch  2, Batch  39 - Loss:  1542.0092 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.7578125\n",
      "Epoch  2, Batch  40 - Loss:  2846.2065 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  2, Batch  41 - Loss:  1815.8176 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.75\n",
      "Epoch  2, Batch  42 - Loss:  2104.4636 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  43 - Loss:  2377.3074 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  44 - Loss:  1868.3563 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  45 - Loss:  1492.0358 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  46 - Loss:  2301.9219 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  47 - Loss:  1156.0122 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  48 - Loss:  1922.3555 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  49 - Loss:  1375.3223 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  50 - Loss:  2077.9312 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  51 - Loss:  2216.1528 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  52 - Loss:  1563.6141 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  53 - Loss:  1759.5580 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  54 - Loss:  1425.2004 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  55 - Loss:  2337.5461 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  56 - Loss:  2236.1509 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  57 - Loss:  2261.1821 Validation Accuracy: 0.789062\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  58 - Loss:  1784.9900 Validation Accuracy: 0.785156\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  59 - Loss:  1989.7106 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  60 - Loss:  1268.9790 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  61 - Loss:  1509.1431 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  62 - Loss:  2192.7698 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  63 - Loss:  1746.0353 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch  64 - Loss:  2131.2253 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch  65 - Loss:  2222.1433 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch  66 - Loss:  1678.3601 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch  67 - Loss:  1633.2715 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  68 - Loss:  1856.2021 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  69 - Loss:  1426.7976 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  70 - Loss:  1766.0212 Validation Accuracy: 0.781250\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  71 - Loss:  2009.0743 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  72 - Loss:  1768.7091 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  73 - Loss:  1813.1143 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  74 - Loss:  1600.6787 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  75 - Loss:  1557.5066 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  76 - Loss:   939.6997 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  77 - Loss:  1475.5706 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  78 - Loss:  2137.7297 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  79 - Loss:  1520.8955 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  80 - Loss:  1844.6543 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  81 - Loss:  2032.2078 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  82 - Loss:  1746.4717 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  83 - Loss:  2282.2246 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  84 - Loss:  2008.2924 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch  85 - Loss:  1572.3647 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  86 - Loss:  1060.9570 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  87 - Loss:  1526.3428 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  88 - Loss:  1564.1888 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch  89 - Loss:   724.0781 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  90 - Loss:  1966.7124 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  91 - Loss:  1376.2218 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch  92 - Loss:  1086.4667 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch  93 - Loss:  2269.4062 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch  94 - Loss:  1189.1176 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch  95 - Loss:  1246.7185 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch  96 - Loss:  1443.0132 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch  97 - Loss:  1636.7520 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch  98 - Loss:  1007.3177 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch  99 - Loss:  2257.2380 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch 100 - Loss:  1442.3627 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 101 - Loss:  1587.4333 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 102 - Loss:  1368.0790 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch 103 - Loss:  1005.1105 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.76953125\n",
      "Epoch  2, Batch 104 - Loss:  2325.9575 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch 105 - Loss:  1775.5581 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 106 - Loss:  1865.1936 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 107 - Loss:  1502.9270 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 108 - Loss:  1207.2146 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 109 - Loss:  2063.5520 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 110 - Loss:  2190.8105 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 111 - Loss:  1563.9502 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 112 - Loss:  1771.5707 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 113 - Loss:  1411.6609 Validation Accuracy: 0.800781\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 114 - Loss:  1377.2495 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 115 - Loss:  1837.9272 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.76171875\n",
      "Epoch  2, Batch 116 - Loss:  1221.0955 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch 117 - Loss:  1625.8821 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 118 - Loss:  1626.9890 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 119 - Loss:  1590.8396 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.765625\n",
      "Epoch  2, Batch 120 - Loss:  1456.2566 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 121 - Loss:  1743.3866 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 122 - Loss:  1547.4680 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 123 - Loss:  1946.5659 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 124 - Loss:  1962.4630 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 125 - Loss:  1837.1228 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 126 - Loss:  1767.9268 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.7734375\n",
      "Epoch  2, Batch 127 - Loss:  1735.1150 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch 128 - Loss:  1645.5995 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch 129 - Loss:  1623.5906 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 130 - Loss:  1833.3041 Validation Accuracy: 0.792969\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 131 - Loss:  2044.8591 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 132 - Loss:  1457.0725 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 133 - Loss:  1579.5808 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 134 - Loss:  1600.4344 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 135 - Loss:  1559.5664 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 136 - Loss:  1520.8176 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 137 - Loss:  1491.0582 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 138 - Loss:  1410.4731 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 139 - Loss:  1033.8033 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 140 - Loss:  1787.2366 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 141 - Loss:  1690.5251 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 142 - Loss:  1980.8818 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 143 - Loss:  1299.7979 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 144 - Loss:  1705.5297 Validation Accuracy: 0.796875\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 145 - Loss:  1229.6951 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 146 - Loss:  1012.3660 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 147 - Loss:  1449.6042 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 148 - Loss:  1283.2993 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 149 - Loss:  1659.1105 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 150 - Loss:  1672.9202 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 151 - Loss:  2229.3062 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 152 - Loss:  1261.7129 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 153 - Loss:  1791.8560 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 154 - Loss:  1486.6130 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 155 - Loss:  1318.1621 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 156 - Loss:  1464.8157 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 157 - Loss:  1066.6980 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 158 - Loss:  1269.3763 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 159 - Loss:  1814.0380 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 160 - Loss:  1533.4275 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 161 - Loss:  2213.1750 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 162 - Loss:  1205.6528 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 163 - Loss:  1893.6304 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 164 - Loss:  1074.8169 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 165 - Loss:  1785.7528 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 166 - Loss:  1969.0657 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 167 - Loss:   771.4592 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 168 - Loss:  1289.9672 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 169 - Loss:  1590.5852 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 170 - Loss:  1965.1414 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 171 - Loss:  1243.6355 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 172 - Loss:  1676.2751 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 173 - Loss:  1558.8944 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 174 - Loss:  1562.8362 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 175 - Loss:  1235.8544 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 176 - Loss:  2111.0071 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 177 - Loss:  1702.1824 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 178 - Loss:  1743.8359 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 179 - Loss:  1392.3596 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 180 - Loss:  2178.6992 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 181 - Loss:  1819.8398 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 182 - Loss:   703.9357 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 183 - Loss:  1062.8630 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 184 - Loss:  1396.5692 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 185 - Loss:  1726.7968 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 186 - Loss:  1537.6365 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 187 - Loss:  1445.3987 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 188 - Loss:  1092.2397 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 189 - Loss:  1022.6783 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 190 - Loss:  1722.2963 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 191 - Loss:  1228.2749 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 192 - Loss:  1479.7327 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 193 - Loss:  1142.3003 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 194 - Loss:  1783.2585 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 195 - Loss:  1359.3442 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 196 - Loss:  2480.3967 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 197 - Loss:  1490.3579 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 198 - Loss:  1568.0594 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 199 - Loss:  2076.4919 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 200 - Loss:   899.6635 Validation Accuracy: 0.804688\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 201 - Loss:  1318.8621 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 202 - Loss:  1970.8403 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 203 - Loss:  1228.6538 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 204 - Loss:  1303.2422 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 205 - Loss:  1134.0403 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 206 - Loss:  1480.9124 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 207 - Loss:  1528.6108 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 208 - Loss:  1629.6949 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 209 - Loss:  1783.6785 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 210 - Loss:  2026.3254 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 211 - Loss:  1831.6591 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 212 - Loss:  1857.6760 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 213 - Loss:  1345.2607 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 214 - Loss:  2296.8271 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 215 - Loss:  1069.9779 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.77734375\n",
      "Epoch  2, Batch 216 - Loss:  1577.6183 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 217 - Loss:  1584.3350 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 218 - Loss:  1133.4382 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 219 - Loss:  1612.0850 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 220 - Loss:  1850.9681 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 221 - Loss:  2228.4062 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 222 - Loss:   634.2279 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 223 - Loss:  1439.6823 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 224 - Loss:  1129.1525 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 225 - Loss:  1367.0684 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 226 - Loss:  1204.5121 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 227 - Loss:  1646.5121 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 228 - Loss:  2110.8015 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 229 - Loss:  1212.1628 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 230 - Loss:  1477.4304 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 231 - Loss:  1928.3466 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 232 - Loss:  1962.7607 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 233 - Loss:  1470.4150 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 234 - Loss:  1231.4480 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 235 - Loss:  1747.1970 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.78515625\n",
      "Epoch  2, Batch 236 - Loss:  2432.2183 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 237 - Loss:  2389.2817 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 238 - Loss:  1095.1283 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 239 - Loss:  1631.1892 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 240 - Loss:   882.1744 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 241 - Loss:  1945.0569 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 242 - Loss:  1452.6453 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 243 - Loss:  1440.9955 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 244 - Loss:  1200.6364 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 245 - Loss:  1189.2856 Validation Accuracy: 0.808594\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 246 - Loss:  1820.3621 Validation Accuracy: 0.812500\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 247 - Loss:  1058.0878 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 248 - Loss:  2000.7554 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 249 - Loss:  1180.1373 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 250 - Loss:  1228.7039 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 251 - Loss:  1130.3689 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 252 - Loss:  1154.3206 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 253 - Loss:  1647.5465 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.7890625\n",
      "Epoch  2, Batch 254 - Loss:  1493.0570 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.78125\n",
      "Epoch  2, Batch 255 - Loss:  1169.4326 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 256 - Loss:   904.4686 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 257 - Loss:  1293.0242 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 258 - Loss:  1916.1165 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 259 - Loss:  1363.5704 Validation Accuracy: 0.816406\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 260 - Loss:  1793.1880 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 261 - Loss:  1358.0505 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 262 - Loss:  1120.7142 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 263 - Loss:  1701.4438 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 264 - Loss:  1491.7076 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 265 - Loss:  1016.3966 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 266 - Loss:   840.1876 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 267 - Loss:  1478.5219 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 268 - Loss:   844.0039 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 269 - Loss:  1850.5886 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 270 - Loss:  1629.1245 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 271 - Loss:  1551.4226 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 272 - Loss:  1274.2507 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 273 - Loss:  1447.8812 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 274 - Loss:  1354.4707 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 275 - Loss:  1433.9023 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 276 - Loss:  1997.4454 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 277 - Loss:  1322.8489 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 278 - Loss:  1226.7390 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 279 - Loss:  1649.0837 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 280 - Loss:  1780.7102 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.79296875\n",
      "Epoch  2, Batch 281 - Loss:  1143.7156 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 282 - Loss:  1056.4189 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 283 - Loss:   926.0628 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 284 - Loss:  1296.1265 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 285 - Loss:  2062.6589 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.796875\n",
      "Epoch  2, Batch 286 - Loss:  1225.7610 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80078125\n",
      "Epoch  2, Batch 287 - Loss:  1082.4484 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 288 - Loss:  1418.7914 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 289 - Loss:   630.2682 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 290 - Loss:   707.1902 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 291 - Loss:  1190.6289 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 292 - Loss:  1729.7727 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 293 - Loss:  1719.9697 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 294 - Loss:  2400.7063 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 295 - Loss:  1329.6466 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 296 - Loss:  1002.6827 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 297 - Loss:  1012.0923 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 298 - Loss:   931.0721 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 299 - Loss:  1212.2308 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 300 - Loss:  1526.6039 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 301 - Loss:  1585.3560 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 302 - Loss:  1733.6453 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 303 - Loss:  1316.4000 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 304 - Loss:  1943.9736 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 305 - Loss:  1995.5210 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 306 - Loss:  1325.7893 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 307 - Loss:  2162.3633 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 308 - Loss:  1158.5671 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 309 - Loss:  1799.5770 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 310 - Loss:  1298.2433 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 311 - Loss:   916.6092 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 312 - Loss:  1457.2915 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 313 - Loss:   916.0447 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 314 - Loss:  1058.7668 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 315 - Loss:  1373.0925 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 316 - Loss:  1198.6720 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 317 - Loss:   730.2822 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 318 - Loss:  2061.7170 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 319 - Loss:   839.5898 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 320 - Loss:   953.7056 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 321 - Loss:  1384.6453 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 322 - Loss:  1630.0863 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 323 - Loss:  1281.9912 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 324 - Loss:   563.1241 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 325 - Loss:  1065.4058 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 326 - Loss:  1372.9929 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 327 - Loss:   677.0084 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  2, Batch 328 - Loss:  1574.2102 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 329 - Loss:  1184.8115 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 330 - Loss:  1326.5876 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 331 - Loss:  1274.4386 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 332 - Loss:  1471.4133 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 333 - Loss:  1109.4539 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 334 - Loss:   664.9019 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 335 - Loss:  1983.2432 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 336 - Loss:  1065.2499 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 337 - Loss:  1177.9944 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 338 - Loss:  1203.5868 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 339 - Loss:  1247.3589 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 340 - Loss:  1276.5171 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 341 - Loss:  1572.9358 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 342 - Loss:   765.0013 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 343 - Loss:  1972.2709 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 344 - Loss:  1292.1907 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 345 - Loss:  1316.4749 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 346 - Loss:  1062.6847 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 347 - Loss:  1297.5823 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 348 - Loss:   803.3714 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 349 - Loss:  1954.5203 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 350 - Loss:  1423.2822 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 351 - Loss:  1433.2811 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 352 - Loss:  1686.0479 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 353 - Loss:  1027.1074 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 354 - Loss:  1125.8755 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 355 - Loss:   848.3000 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 356 - Loss:  1181.3624 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 357 - Loss:   915.7927 Validation Accuracy: 0.820312\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 358 - Loss:  1543.3705 Validation Accuracy: 0.824219\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 359 - Loss:  1414.0719 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 360 - Loss:  1330.9573 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 361 - Loss:  1165.9624 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 362 - Loss:  1222.4314 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 363 - Loss:  1528.6393 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 364 - Loss:  1321.3390 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 365 - Loss:  1303.7166 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 366 - Loss:  1614.3145 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 367 - Loss:   999.5172 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 368 - Loss:  1336.1438 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 369 - Loss:  1208.9073 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 370 - Loss:   830.8196 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 371 - Loss:  1451.1211 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 372 - Loss:  1857.2139 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 373 - Loss:   991.9294 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  2, Batch 374 - Loss:  1395.3958 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 375 - Loss:   839.0966 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 376 - Loss:  1832.7772 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 377 - Loss:  1240.5950 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 378 - Loss:   640.1515 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 379 - Loss:  1670.7188 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  2, Batch 380 - Loss:  1539.0728 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  2, Batch 381 - Loss:  1279.6531 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 382 - Loss:  1992.5870 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 383 - Loss:   775.3873 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 384 - Loss:  1013.3481 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 385 - Loss:  1484.7378 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 386 - Loss:  1508.3105 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 387 - Loss:  1395.1870 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 388 - Loss:  1509.2437 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 389 - Loss:  2003.6582 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 390 - Loss:  2007.5226 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 391 - Loss:  1447.8143 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 392 - Loss:  1044.1067 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 393 - Loss:  1187.6788 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 394 - Loss:  1167.1169 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 395 - Loss:  1335.9146 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 396 - Loss:  1385.9974 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 397 - Loss:  1487.6366 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 398 - Loss:   807.0426 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 399 - Loss:  1240.5920 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 400 - Loss:   820.3358 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 401 - Loss:  1252.1997 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 402 - Loss:  1397.0740 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 403 - Loss:  1113.0040 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 404 - Loss:  2215.4536 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 405 - Loss:  1471.3801 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 406 - Loss:   901.6443 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 407 - Loss:  2626.9124 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 408 - Loss:  1169.4613 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  2, Batch 409 - Loss:  1321.3813 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 410 - Loss:  1739.1454 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 411 - Loss:  1115.4052 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 412 - Loss:  1135.6816 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 413 - Loss:  1643.2407 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 414 - Loss:   444.2028 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 415 - Loss:  1045.0013 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 416 - Loss:  1527.7163 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 417 - Loss:  1262.5186 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 418 - Loss:  1599.0913 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 419 - Loss:  2031.6902 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  2, Batch 420 - Loss:  1700.4863 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 421 - Loss:  1222.6057 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8046875\n",
      "Epoch  2, Batch 422 - Loss:  1268.3440 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 423 - Loss:  1783.4255 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8125\n",
      "Epoch  2, Batch 424 - Loss:  1342.6309 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.80859375\n",
      "Epoch  2, Batch 425 - Loss:  1373.6550 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  2, Batch 426 - Loss:   844.5665 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 427 - Loss:  1264.0612 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  2, Batch 428 - Loss:  1192.5903 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  2, Batch 429 - Loss:  1606.2870 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch   1 - Loss:   796.8921 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  3, Batch   2 - Loss:  1053.5237 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch   3 - Loss:  1284.9753 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch   4 - Loss:   972.5444 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch   5 - Loss:   931.1589 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch   6 - Loss:  1013.3906 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch   7 - Loss:  1057.9122 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch   8 - Loss:  1647.9385 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch   9 - Loss:  1630.0546 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  10 - Loss:   725.6628 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.81640625\n",
      "Epoch  3, Batch  11 - Loss:  1177.6230 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch  12 - Loss:   944.0864 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  13 - Loss:  1422.4541 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  14 - Loss:   910.6169 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  15 - Loss:  1200.6877 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch  16 - Loss:  1727.4243 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  17 - Loss:   349.4963 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  18 - Loss:  1139.7728 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  19 - Loss:  1690.1354 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  20 - Loss:  1278.3308 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  21 - Loss:  1245.6277 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  22 - Loss:  1323.5413 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  23 - Loss:   553.2836 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  24 - Loss:   661.1118 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  25 - Loss:  1131.8400 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  26 - Loss:   843.0309 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  27 - Loss:   825.1560 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  28 - Loss:  1429.3545 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  29 - Loss:   669.0624 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  30 - Loss:  1134.4397 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  31 - Loss:  1305.6062 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  32 - Loss:  1342.8973 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  33 - Loss:  1528.9192 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  34 - Loss:   843.1366 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  35 - Loss:   607.3721 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  36 - Loss:  1655.4080 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch  37 - Loss:  1624.8430 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  38 - Loss:  1324.8093 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  39 - Loss:   866.4558 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch  40 - Loss:  1751.6322 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  41 - Loss:  1403.9702 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  42 - Loss:   962.5432 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  43 - Loss:  1814.5145 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  44 - Loss:   761.6409 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  45 - Loss:  1550.4097 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  46 - Loss:  1104.5283 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  47 - Loss:   715.3303 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  48 - Loss:  1331.1831 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  49 - Loss:   625.8635 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  50 - Loss:  2438.4543 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  51 - Loss:  1219.1194 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  52 - Loss:  1425.2241 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  53 - Loss:   525.7751 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  54 - Loss:   878.6572 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  55 - Loss:  1567.9569 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  56 - Loss:  1433.4438 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  57 - Loss:   835.0121 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  58 - Loss:  1554.0526 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  59 - Loss:   861.3357 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  60 - Loss:   747.9620 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  61 - Loss:  1387.5413 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  62 - Loss:  1230.4265 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  63 - Loss:   845.1456 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  64 - Loss:  1434.0460 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  65 - Loss:   804.7018 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  66 - Loss:  1078.5447 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  67 - Loss:  1293.4225 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch  68 - Loss:   688.4745 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  69 - Loss:   896.9421 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8203125\n",
      "Epoch  3, Batch  70 - Loss:  1858.8574 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  71 - Loss:  1082.8079 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  72 - Loss:  1007.4304 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  73 - Loss:   929.4507 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch  74 - Loss:   789.6339 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  75 - Loss:  1884.8989 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch  76 - Loss:  1179.2722 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  77 - Loss:  1033.4661 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  78 - Loss:  1208.8201 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  79 - Loss:  1430.6766 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  80 - Loss:   821.9103 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch  81 - Loss:  1258.5082 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  82 - Loss:   939.3940 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  83 - Loss:  2113.1313 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  84 - Loss:  1462.9928 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch  85 - Loss:  1422.1642 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  86 - Loss:   792.3909 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  87 - Loss:   668.8118 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  88 - Loss:   883.4347 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  89 - Loss:   918.8030 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  90 - Loss:  1302.7786 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  91 - Loss:  1217.7272 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  92 - Loss:  1073.0560 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch  93 - Loss:  1635.7700 Validation Accuracy: 0.828125\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  94 - Loss:   885.3038 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch  95 - Loss:  1266.0757 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  96 - Loss:  1118.6215 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  97 - Loss:   745.8870 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch  98 - Loss:  1060.8022 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch  99 - Loss:  1143.7460 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 100 - Loss:   542.0032 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 101 - Loss:   762.1865 Validation Accuracy: 0.835938\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch 102 - Loss:  1017.2177 Validation Accuracy: 0.832031\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 103 - Loss:   808.1901 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 104 - Loss:  1451.9363 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 105 - Loss:   996.9728 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 106 - Loss:  1183.1641 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 107 - Loss:  1675.6492 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 108 - Loss:   780.8907 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 109 - Loss:  1465.7659 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 110 - Loss:   571.0079 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 111 - Loss:  1343.1375 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 112 - Loss:  1519.4089 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 113 - Loss:   771.6312 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 114 - Loss:   648.6265 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch 115 - Loss:   659.1765 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 116 - Loss:   920.3810 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 117 - Loss:  1274.2478 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 118 - Loss:  1448.7620 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 119 - Loss:  1733.2938 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 120 - Loss:  1341.9712 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 121 - Loss:  1887.8842 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 122 - Loss:   936.7841 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 123 - Loss:  1632.6367 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.82421875\n",
      "Epoch  3, Batch 124 - Loss:   953.8231 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 125 - Loss:   985.9495 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 126 - Loss:  1799.5819 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 127 - Loss:  1332.6606 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 128 - Loss:  1815.9685 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 129 - Loss:  1762.8662 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 130 - Loss:  1126.5916 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 131 - Loss:   889.4762 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 132 - Loss:  1156.6091 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 133 - Loss:  2193.0671 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 134 - Loss:  1280.8684 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 135 - Loss:  1202.8638 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 136 - Loss:  1931.2600 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 137 - Loss:  1134.5256 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 138 - Loss:   722.4716 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 139 - Loss:   929.6531 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 140 - Loss:  1355.0011 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 141 - Loss:  1293.7954 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 142 - Loss:  1323.5183 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 143 - Loss:   735.7197 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 144 - Loss:  1058.0854 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 145 - Loss:   707.7103 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 146 - Loss:   801.5793 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 147 - Loss:  1310.2603 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 148 - Loss:   970.3513 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 149 - Loss:  1055.2869 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 150 - Loss:  1237.3467 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 151 - Loss:  1643.2992 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 152 - Loss:  1360.2417 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 153 - Loss:  1643.0811 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 154 - Loss:   951.2073 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 155 - Loss:  1370.8699 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 156 - Loss:  1212.5260 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 157 - Loss:  1106.3934 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 158 - Loss:  1469.3950 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 159 - Loss:   975.0326 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 160 - Loss:  1047.6145 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 161 - Loss:   792.4185 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 162 - Loss:   873.6340 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 163 - Loss:  1229.2983 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 164 - Loss:   850.1327 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 165 - Loss:  1557.1979 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 166 - Loss:  2061.1416 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 167 - Loss:  1011.9658 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 168 - Loss:   634.6316 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 169 - Loss:  1517.7397 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 170 - Loss:  1082.6948 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 171 - Loss:  1521.7861 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 172 - Loss:  1676.0991 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 173 - Loss:   887.1360 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 174 - Loss:   967.2277 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 175 - Loss:   733.2498 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 176 - Loss:  1969.3219 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 177 - Loss:  1675.9653 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 178 - Loss:   981.5778 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 179 - Loss:  1174.6265 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.828125\n",
      "Epoch  3, Batch 180 - Loss:  1462.6897 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 181 - Loss:  1678.3364 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 182 - Loss:  1593.2786 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 183 - Loss:  1032.0123 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 184 - Loss:   969.1232 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 185 - Loss:   949.4827 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 186 - Loss:  1257.3770 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 187 - Loss:  1003.4125 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 188 - Loss:  1070.5994 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 189 - Loss:  1803.2416 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 190 - Loss:  1152.6302 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 191 - Loss:  1500.5020 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 192 - Loss:   690.1874 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 193 - Loss:   492.0073 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 194 - Loss:  1387.8840 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 195 - Loss:  1180.7981 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 196 - Loss:  1367.0430 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 197 - Loss:  1278.3024 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 198 - Loss:  1459.2771 Validation Accuracy: 0.839844\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 199 - Loss:   583.4263 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 200 - Loss:  1333.2700 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 201 - Loss:   970.8746 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 202 - Loss:   575.4806 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 203 - Loss:  1103.9905 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 204 - Loss:  1427.2126 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 205 - Loss:   705.5625 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 206 - Loss:  1506.8953 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 207 - Loss:   919.1127 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 208 - Loss:  1004.7623 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 209 - Loss:   689.6907 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 210 - Loss:  1075.4727 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 211 - Loss:   693.7435 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 212 - Loss:   470.3096 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 213 - Loss:  1173.5743 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 214 - Loss:  1636.4390 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 215 - Loss:  1313.3455 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 216 - Loss:  1304.8949 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 217 - Loss:  1152.0375 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 218 - Loss:  2224.3694 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 219 - Loss:   924.5274 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 220 - Loss:  1224.1122 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 221 - Loss:  1249.0610 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 222 - Loss:  1463.8362 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 223 - Loss:   983.1698 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 224 - Loss:   896.9088 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 225 - Loss:  1019.7252 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 226 - Loss:   646.3701 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 227 - Loss:  1164.0935 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 228 - Loss:  1094.9607 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 229 - Loss:   535.3604 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 230 - Loss:   787.9991 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 231 - Loss:  1420.8602 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 232 - Loss:  1086.0205 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 233 - Loss:   845.3394 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 234 - Loss:  1142.6418 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 235 - Loss:   665.4321 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 236 - Loss:  1285.7729 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 237 - Loss:   807.7358 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 238 - Loss:  1340.9894 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 239 - Loss:   984.4695 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 240 - Loss:   728.4775 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 241 - Loss:   947.1945 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 242 - Loss:  1079.3433 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 243 - Loss:  1005.5275 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 244 - Loss:   780.6393 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 245 - Loss:  1844.1049 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.83203125\n",
      "Epoch  3, Batch 246 - Loss:   791.1705 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 247 - Loss:   805.0255 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 248 - Loss:  1156.9434 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 249 - Loss:  1528.0684 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 250 - Loss:  1289.1272 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 251 - Loss:   897.1302 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 252 - Loss:  1001.6482 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 253 - Loss:  1251.8826 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 254 - Loss:  1092.8046 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 255 - Loss:  1077.1759 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 256 - Loss:  1282.0686 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 257 - Loss:   976.8287 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 258 - Loss:  1572.3673 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 259 - Loss:  1424.4734 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 260 - Loss:   744.3691 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 261 - Loss:  1040.4226 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 262 - Loss:   977.5492 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 263 - Loss:  1050.7278 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 264 - Loss:  1891.6561 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 265 - Loss:   530.9011 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 266 - Loss:  1250.4883 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 267 - Loss:  1263.9979 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 268 - Loss:  1773.5767 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 269 - Loss:   637.7889 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 270 - Loss:   796.5984 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 271 - Loss:  1107.4734 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 272 - Loss:  1316.9402 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 273 - Loss:  1106.7360 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 274 - Loss:  1030.7115 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 275 - Loss:   979.1287 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 276 - Loss:   595.3862 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 277 - Loss:   942.0623 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 278 - Loss:   801.5222 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 279 - Loss:   788.1906 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 280 - Loss:  1134.7827 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 281 - Loss:  1256.3450 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 282 - Loss:  1110.5808 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 283 - Loss:  1457.2966 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 284 - Loss:   729.7140 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 285 - Loss:  1450.4501 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 286 - Loss:   941.8179 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 287 - Loss:   944.8862 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 288 - Loss:   983.5545 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 289 - Loss:  1110.0314 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 290 - Loss:  1073.0612 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 291 - Loss:   916.6565 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 292 - Loss:  1334.9899 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 293 - Loss:   821.1691 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 294 - Loss:  1293.6307 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 295 - Loss:   910.4553 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 296 - Loss:  1430.6355 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 297 - Loss:  1395.1189 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 298 - Loss:   935.6488 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 299 - Loss:  1006.3863 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 300 - Loss:   596.1470 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 301 - Loss:   730.5682 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 302 - Loss:   951.8938 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 303 - Loss:   434.7596 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 304 - Loss:  1543.0265 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 305 - Loss:  1327.0364 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 306 - Loss:  1191.7402 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 307 - Loss:  1526.1870 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 308 - Loss:  1324.6614 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 309 - Loss:   959.9959 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 310 - Loss:   774.5085 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 311 - Loss:   839.9288 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 312 - Loss:  1067.5403 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 313 - Loss:  1007.9805 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 314 - Loss:  1070.9088 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 315 - Loss:   762.7519 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 316 - Loss:   836.4133 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 317 - Loss:  1282.2689 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 318 - Loss:  1343.2175 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 319 - Loss:   785.9260 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 320 - Loss:   751.5702 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 321 - Loss:  1512.3658 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 322 - Loss:  1802.8226 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 323 - Loss:  1299.5378 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 324 - Loss:   945.1649 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 325 - Loss:   597.5192 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 326 - Loss:  1210.0981 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 327 - Loss:  1184.8245 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 328 - Loss:   842.5181 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 329 - Loss:  1160.9811 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 330 - Loss:  1216.2241 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 331 - Loss:   586.7592 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 332 - Loss:  1022.3803 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 333 - Loss:  1153.3308 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  3, Batch 334 - Loss:   822.2341 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 335 - Loss:  1583.1263 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 336 - Loss:   793.3569 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 337 - Loss:  1059.9778 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 338 - Loss:  1352.7699 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  3, Batch 339 - Loss:   753.7998 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 340 - Loss:   956.7661 Validation Accuracy: 0.843750\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 341 - Loss:   849.9526 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 342 - Loss:   574.8721 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 343 - Loss:   564.8505 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 344 - Loss:  1294.7695 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 345 - Loss:  1155.5309 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 346 - Loss:  1298.5306 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 347 - Loss:  1149.1737 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 348 - Loss:  1318.8872 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 349 - Loss:  1104.1566 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 350 - Loss:   567.7910 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  3, Batch 351 - Loss:  1405.8964 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 352 - Loss:   996.6906 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 353 - Loss:  1340.1021 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 354 - Loss:   880.2045 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 355 - Loss:   706.2606 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 356 - Loss:  1042.2950 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 357 - Loss:   889.7483 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 358 - Loss:  1279.1216 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 359 - Loss:  1150.4492 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 360 - Loss:   610.6572 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 361 - Loss:   594.4545 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 362 - Loss:  1442.9132 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 363 - Loss:   399.8421 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 364 - Loss:  1405.3855 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 365 - Loss:  1284.7212 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 366 - Loss:   686.6541 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 367 - Loss:  1478.7922 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 368 - Loss:   770.6423 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 369 - Loss:   767.2875 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 370 - Loss:  1009.9806 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 371 - Loss:   935.0234 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 372 - Loss:   812.4857 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 373 - Loss:  1013.4197 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 374 - Loss:   562.2801 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 375 - Loss:  1073.9357 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 376 - Loss:  1008.5780 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 377 - Loss:   964.4561 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 378 - Loss:   351.9721 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 379 - Loss:   649.7605 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 380 - Loss:  1300.1343 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 381 - Loss:   625.4860 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8359375\n",
      "Epoch  3, Batch 382 - Loss:   863.8562 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 383 - Loss:   918.5927 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 384 - Loss:  1022.0114 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 385 - Loss:  1060.3242 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 386 - Loss:  1202.9177 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 387 - Loss:   955.7275 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 388 - Loss:  1397.9005 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 389 - Loss:   517.6693 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 390 - Loss:   664.3238 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 391 - Loss:  1175.8162 Validation Accuracy: 0.847656\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 392 - Loss:   879.9750 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 393 - Loss:   518.9202 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 394 - Loss:  1726.0298 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 395 - Loss:   902.1028 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 396 - Loss:  1484.9077 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 397 - Loss:   940.3383 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 398 - Loss:  1169.6432 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 399 - Loss:  1287.5364 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 400 - Loss:  1284.5613 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 401 - Loss:  1061.3351 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 402 - Loss:   815.8235 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 403 - Loss:   935.7640 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 404 - Loss:   886.9503 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 405 - Loss:   575.8375 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 406 - Loss:   866.7959 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 407 - Loss:  1013.5991 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 408 - Loss:   403.7937 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 409 - Loss:  1537.7312 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 410 - Loss:   619.4962 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 411 - Loss:  1247.7578 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 412 - Loss:  1221.9214 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 413 - Loss:   888.7896 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 414 - Loss:  1547.8210 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 415 - Loss:   831.6262 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 416 - Loss:   496.3364 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 417 - Loss:  1240.9539 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 418 - Loss:   690.1054 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 419 - Loss:   996.9440 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84375\n",
      "Epoch  3, Batch 420 - Loss:   748.7819 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 421 - Loss:   609.3624 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.83984375\n",
      "Epoch  3, Batch 422 - Loss:   420.5262 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 423 - Loss:  1104.7880 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  3, Batch 424 - Loss:   456.6465 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 425 - Loss:  1252.9039 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 426 - Loss:   946.9695 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  3, Batch 427 - Loss:  1205.1737 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  3, Batch 428 - Loss:   985.5723 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  3, Batch 429 - Loss:  1237.1711 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch   1 - Loss:   761.6106 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  4, Batch   2 - Loss:   729.3059 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch   3 - Loss:  1152.1528 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch   4 - Loss:  1213.7568 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch   5 - Loss:  1549.5399 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch   6 - Loss:   653.7582 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch   7 - Loss:   510.9451 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch   8 - Loss:   496.8598 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch   9 - Loss:   863.3111 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch  10 - Loss:  1147.2834 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch  11 - Loss:  1425.0089 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  12 - Loss:   781.3062 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch  13 - Loss:   723.9767 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  14 - Loss:   870.7007 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  15 - Loss:  1083.2705 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  16 - Loss:   789.1160 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  17 - Loss:  1423.9817 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  18 - Loss:   750.6424 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch  19 - Loss:  1092.0063 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  20 - Loss:   520.9229 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  21 - Loss:  1400.2700 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  22 - Loss:   982.1078 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  23 - Loss:  1091.5194 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  24 - Loss:   747.0035 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  25 - Loss:   813.8425 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  26 - Loss:  1197.2490 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  27 - Loss:  1115.3799 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  28 - Loss:   374.5030 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  29 - Loss:   875.0695 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  30 - Loss:  1277.2886 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch  31 - Loss:  1032.6067 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.84765625\n",
      "Epoch  4, Batch  32 - Loss:   619.2508 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  33 - Loss:   956.6553 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch  34 - Loss:   957.0157 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  35 - Loss:   486.8918 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  36 - Loss:  1098.0076 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  37 - Loss:   693.3527 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  38 - Loss:   776.6686 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  39 - Loss:  1506.2150 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  40 - Loss:   395.6839 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  41 - Loss:   862.8121 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  42 - Loss:   675.8046 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  43 - Loss:   507.9642 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  44 - Loss:   489.9964 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  45 - Loss:  1322.1475 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  46 - Loss:   830.7833 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  47 - Loss:   690.7686 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  48 - Loss:  1040.5928 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  49 - Loss:   848.0714 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  50 - Loss:   626.2504 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  51 - Loss:   375.6388 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  52 - Loss:   826.4733 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  53 - Loss:   800.6520 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  54 - Loss:   878.6292 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch  55 - Loss:   723.3893 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  56 - Loss:  1032.4575 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  57 - Loss:  1071.0781 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  58 - Loss:  1103.7922 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  59 - Loss:  1034.1252 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  60 - Loss:   960.4013 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  61 - Loss:  1125.0215 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  62 - Loss:  1295.6250 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch  63 - Loss:   971.1492 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  64 - Loss:   429.8070 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  65 - Loss:   980.6655 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  66 - Loss:   922.3418 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  67 - Loss:  1054.7933 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  68 - Loss:  1493.9038 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  69 - Loss:  1004.2681 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  70 - Loss:   799.5358 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  71 - Loss:  1074.7340 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  72 - Loss:   601.4924 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  73 - Loss:   747.3230 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  74 - Loss:   849.5882 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  75 - Loss:  1063.6379 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  76 - Loss:   638.1951 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  77 - Loss:   768.1500 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  78 - Loss:   877.8232 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  79 - Loss:   573.7691 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  80 - Loss:   757.0670 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  81 - Loss:  1226.7867 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  82 - Loss:  1618.0922 Validation Accuracy: 0.851562\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  83 - Loss:   549.1478 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  84 - Loss:  1127.6423 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  85 - Loss:  1079.6477 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  86 - Loss:  1116.2074 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  87 - Loss:   765.7327 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  88 - Loss:   636.2254 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  89 - Loss:   712.5455 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  90 - Loss:   706.5197 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  91 - Loss:   803.0067 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  92 - Loss:  1161.3533 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  93 - Loss:  1172.3877 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch  94 - Loss:  1249.9473 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  95 - Loss:   820.8855 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch  96 - Loss:   819.5310 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch  97 - Loss:   926.8143 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  98 - Loss:  1036.2820 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch  99 - Loss:   651.0659 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 100 - Loss:  1604.4121 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 101 - Loss:   627.9626 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 102 - Loss:  1021.7515 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 103 - Loss:  1008.0161 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 104 - Loss:   987.5857 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 105 - Loss:   773.5925 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 106 - Loss:  1222.6792 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 107 - Loss:   692.4719 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 108 - Loss:  1199.6433 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 109 - Loss:   607.7086 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 110 - Loss:   971.4374 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 111 - Loss:  1223.0287 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 112 - Loss:   279.7914 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 113 - Loss:   704.9409 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 114 - Loss:   880.8511 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 115 - Loss:  1146.8402 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 116 - Loss:   451.6832 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 117 - Loss:  1260.8345 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  4, Batch 118 - Loss:   820.0432 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 119 - Loss:   770.5015 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 120 - Loss:   758.5046 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 121 - Loss:   635.9267 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 122 - Loss:  1170.8851 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 123 - Loss:   988.0873 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 124 - Loss:   739.6759 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 125 - Loss:   760.5272 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 126 - Loss:   875.0239 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 127 - Loss:   940.6306 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 128 - Loss:  1331.4265 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 129 - Loss:  1438.5837 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 130 - Loss:   356.6160 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 131 - Loss:   485.9101 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 132 - Loss:   656.2468 Validation Accuracy: 0.855469\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 133 - Loss:  1170.1161 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 134 - Loss:  1461.5913 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 135 - Loss:  1162.6104 Validation Accuracy: 0.859375\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 136 - Loss:  1356.1940 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 137 - Loss:  1091.6481 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 138 - Loss:  1036.3479 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 139 - Loss:  1382.1384 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 140 - Loss:   710.7731 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 141 - Loss:  1023.0592 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 142 - Loss:   829.9889 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 143 - Loss:  1097.4534 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 144 - Loss:  1074.4891 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 145 - Loss:   693.7000 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 146 - Loss:  1163.9456 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 147 - Loss:  1222.1667 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 148 - Loss:  1048.6553 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 149 - Loss:   708.7219 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 150 - Loss:   864.2141 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 151 - Loss:  1137.1490 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 152 - Loss:   862.6851 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 153 - Loss:  1229.4138 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 154 - Loss:   257.5837 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 155 - Loss:   973.8206 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 156 - Loss:  1190.0719 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 157 - Loss:   951.7192 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 158 - Loss:   863.0415 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 159 - Loss:   885.0632 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 160 - Loss:   706.2354 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 161 - Loss:   864.4695 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 162 - Loss:  1206.3250 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 163 - Loss:  1252.6604 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 164 - Loss:  1354.3480 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 165 - Loss:   604.5739 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 166 - Loss:   539.6292 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 167 - Loss:  1072.9392 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 168 - Loss:  1215.5957 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 169 - Loss:  1115.8906 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 170 - Loss:   573.4163 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 171 - Loss:   770.6586 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 172 - Loss:  1481.0972 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 173 - Loss:   723.8831 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 174 - Loss:   820.6471 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 175 - Loss:  1113.8921 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 176 - Loss:  1004.9435 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 177 - Loss:   915.1459 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 178 - Loss:   536.9847 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 179 - Loss:   692.1950 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 180 - Loss:  1133.2346 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 181 - Loss:   617.4459 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 182 - Loss:   987.5261 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 183 - Loss:  1701.6162 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 184 - Loss:   721.6288 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 185 - Loss:   888.4480 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 186 - Loss:   565.8577 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 187 - Loss:   969.4939 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 188 - Loss:   794.9716 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 189 - Loss:   894.5077 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 190 - Loss:   563.2153 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 191 - Loss:   633.0604 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 192 - Loss:  1147.5625 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 193 - Loss:   947.6121 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 194 - Loss:  1235.9744 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 195 - Loss:  1030.9984 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 196 - Loss:  1073.9591 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 197 - Loss:   337.6707 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 198 - Loss:   867.1760 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 199 - Loss:   928.9338 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 200 - Loss:   671.4584 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 201 - Loss:   824.9857 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 202 - Loss:   890.4163 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 203 - Loss:  1686.3693 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 204 - Loss:   834.3085 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 205 - Loss:   886.7570 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 206 - Loss:  1109.0447 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 207 - Loss:   936.4993 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 208 - Loss:  1077.9321 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 209 - Loss:   604.1036 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 210 - Loss:   903.2394 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 211 - Loss:  1151.0944 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 212 - Loss:   555.4952 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 213 - Loss:  1572.1063 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 214 - Loss:   827.4736 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 215 - Loss:  1483.0413 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 216 - Loss:   590.6490 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 217 - Loss:   765.8351 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 218 - Loss:   610.1425 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 219 - Loss:   641.5592 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 220 - Loss:  1010.5562 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 221 - Loss:   446.0508 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 222 - Loss:   825.2263 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 223 - Loss:   688.9976 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 224 - Loss:  1887.1768 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 225 - Loss:   974.7820 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 226 - Loss:   934.7532 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 227 - Loss:  1090.7118 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 228 - Loss:  1383.3269 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 229 - Loss:   921.1191 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 230 - Loss:   695.9016 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 231 - Loss:  1819.8368 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 232 - Loss:   853.9776 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 233 - Loss:   892.1207 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 234 - Loss:  1267.3718 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 235 - Loss:  1041.4814 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 236 - Loss:   723.5256 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 237 - Loss:  1042.9362 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 238 - Loss:   726.3392 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 239 - Loss:  1321.6792 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 240 - Loss:   544.1842 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 241 - Loss:   615.6899 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 242 - Loss:   541.4712 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 243 - Loss:   874.9924 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 244 - Loss:   943.0447 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 245 - Loss:  1168.2820 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 246 - Loss:   305.7560 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 247 - Loss:  1191.0330 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 248 - Loss:   691.5601 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 249 - Loss:   701.5858 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 250 - Loss:   915.0673 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 251 - Loss:  1065.0905 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 252 - Loss:  1289.2188 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 253 - Loss:   354.2896 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 254 - Loss:   645.4373 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 255 - Loss:   571.9530 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 256 - Loss:   704.7632 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 257 - Loss:  1376.9282 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 258 - Loss:   799.8718 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 259 - Loss:   953.8146 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 260 - Loss:   879.1932 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 261 - Loss:  1054.3207 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 262 - Loss:   563.9174 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 263 - Loss:   865.8154 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 264 - Loss:  1021.9983 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 265 - Loss:   514.3026 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 266 - Loss:  1059.8660 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 267 - Loss:   955.8054 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 268 - Loss:   572.1423 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 269 - Loss:   410.2844 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 270 - Loss:   199.0206 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 271 - Loss:   795.8738 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 272 - Loss:  1016.6550 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.85546875\n",
      "Epoch  4, Batch 273 - Loss:  1267.1539 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 274 - Loss:   533.5115 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 275 - Loss:   696.2237 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 276 - Loss:   821.7074 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 277 - Loss:   805.3317 Validation Accuracy: 0.867188\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 278 - Loss:  1649.6407 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 279 - Loss:   743.4887 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 280 - Loss:   982.9154 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 281 - Loss:   942.0568 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 282 - Loss:  1003.0394 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 283 - Loss:  1232.3268 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 284 - Loss:   428.4247 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 285 - Loss:  1142.1345 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 286 - Loss:   638.7573 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 287 - Loss:   676.4434 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8515625\n",
      "Epoch  4, Batch 288 - Loss:   684.0057 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 289 - Loss:  1121.5684 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 290 - Loss:   904.6289 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 291 - Loss:   948.9128 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 292 - Loss:   672.2618 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 293 - Loss:   291.8562 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 294 - Loss:   683.8845 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 295 - Loss:  1095.8259 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 296 - Loss:  1013.0245 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 297 - Loss:   508.3207 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 298 - Loss:  1324.2483 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 299 - Loss:   886.2678 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 300 - Loss:  1202.5210 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 301 - Loss:   828.0815 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 302 - Loss:   496.2329 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 303 - Loss:  1411.9551 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 304 - Loss:  1048.5841 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 305 - Loss:  1038.2681 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 306 - Loss:   835.7017 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 307 - Loss:   782.9735 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 308 - Loss:   486.9073 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 309 - Loss:  1110.4019 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 310 - Loss:  1362.4834 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 311 - Loss:   683.2086 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 312 - Loss:   954.8297 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 313 - Loss:  1034.5388 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 314 - Loss:   951.2993 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 315 - Loss:  1265.1577 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 316 - Loss:  1028.8694 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 317 - Loss:   673.3391 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 318 - Loss:   929.8411 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 319 - Loss:   985.0709 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 320 - Loss:   828.5413 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 321 - Loss:   593.3770 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 322 - Loss:  1139.8934 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 323 - Loss:   922.3864 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 324 - Loss:  1004.5751 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 325 - Loss:  1423.5009 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 326 - Loss:   701.0753 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 327 - Loss:  1627.7507 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 328 - Loss:   287.6153 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 329 - Loss:  1066.4445 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 330 - Loss:   572.0117 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 331 - Loss:   898.3337 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 332 - Loss:   835.2313 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 333 - Loss:  1123.6050 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 334 - Loss:  1155.2087 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 335 - Loss:   867.9476 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 336 - Loss:  1059.7715 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 337 - Loss:   557.4481 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 338 - Loss:   417.3266 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 339 - Loss:   657.2306 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 340 - Loss:  1084.9780 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 341 - Loss:   969.5947 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 342 - Loss:  1172.5519 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 343 - Loss:   853.3250 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 344 - Loss:   804.7592 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 345 - Loss:   669.0337 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 346 - Loss:   977.4219 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 347 - Loss:  1453.9763 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 348 - Loss:   791.6234 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 349 - Loss:   837.5550 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 350 - Loss:   563.4292 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 351 - Loss:   541.6000 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 352 - Loss:   560.8926 Validation Accuracy: 0.871094\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  4, Batch 353 - Loss:  1236.8490 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 354 - Loss:   843.8287 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 355 - Loss:   645.9553 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 356 - Loss:   640.5518 Validation Accuracy: 0.863281\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 357 - Loss:  1327.7424 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 358 - Loss:   892.8223 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 359 - Loss:   945.1586 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 360 - Loss:   647.2440 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 361 - Loss:   741.6262 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 362 - Loss:   612.4842 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 363 - Loss:   831.6730 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 364 - Loss:   507.5429 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 365 - Loss:   595.8381 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 366 - Loss:   726.4865 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 367 - Loss:   888.6608 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 368 - Loss:   296.3345 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 369 - Loss:  1107.0190 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 370 - Loss:   921.3959 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 371 - Loss:   711.7705 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 372 - Loss:   528.9023 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 373 - Loss:  1152.6998 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 374 - Loss:  1155.5300 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 375 - Loss:   471.9687 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 376 - Loss:  1030.7089 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 377 - Loss:   561.4850 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.86328125\n",
      "Epoch  4, Batch 378 - Loss:   963.2659 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 379 - Loss:   627.8275 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 380 - Loss:   530.4269 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 381 - Loss:   960.4026 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 382 - Loss:   332.4327 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 383 - Loss:   778.0613 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 384 - Loss:   722.2574 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 385 - Loss:  1065.6385 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 386 - Loss:   358.1165 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 387 - Loss:   969.3376 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 388 - Loss:   970.8557 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 389 - Loss:   976.5366 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 390 - Loss:   765.6662 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  4, Batch 391 - Loss:   759.1222 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  4, Batch 392 - Loss:   826.8312 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 393 - Loss:  1114.4485 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 394 - Loss:   866.9348 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  4, Batch 395 - Loss:  1155.5184 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  4, Batch 396 - Loss:   728.3923 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 397 - Loss:   652.4541 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 398 - Loss:   970.0746 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  4, Batch 399 - Loss:   661.4279 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 400 - Loss:   873.6710 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 401 - Loss:   379.2713 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 402 - Loss:   587.0775 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 403 - Loss:  1196.4430 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 404 - Loss:   841.1426 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 405 - Loss:   630.2009 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 406 - Loss:  1138.0581 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 407 - Loss:  1804.7441 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 408 - Loss:   319.7117 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 409 - Loss:   326.4221 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  4, Batch 410 - Loss:   938.4307 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.875\n",
      "Epoch  4, Batch 411 - Loss:   682.2386 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  4, Batch 412 - Loss:   562.0702 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 413 - Loss:   740.7247 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  4, Batch 414 - Loss:   525.0807 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 415 - Loss:   845.7347 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 416 - Loss:  1250.8655 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 417 - Loss:   639.5853 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  4, Batch 418 - Loss:   938.6938 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  4, Batch 419 - Loss:   519.6367 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 420 - Loss:   681.9833 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 421 - Loss:   946.7778 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 422 - Loss:   649.5548 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 423 - Loss:   961.9512 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 424 - Loss:   771.5646 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 425 - Loss:   748.0688 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  4, Batch 426 - Loss:  1219.5317 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 427 - Loss:   718.2163 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  4, Batch 428 - Loss:   700.5581 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  4, Batch 429 - Loss:   831.0726 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch   1 - Loss:   751.7340 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch   2 - Loss:   650.9288 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch   3 - Loss:   711.0190 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch   4 - Loss:   906.5704 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch   5 - Loss:  1073.6638 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch   6 - Loss:  1077.2887 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch   7 - Loss:   462.9963 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch   8 - Loss:   839.5509 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch   9 - Loss:   865.6957 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch  10 - Loss:   744.3267 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  11 - Loss:   726.5290 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch  12 - Loss:   491.5565 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch  13 - Loss:   713.4583 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  14 - Loss:  1135.1497 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  15 - Loss:   798.2783 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  16 - Loss:  1138.2078 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  17 - Loss:   853.2367 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  18 - Loss:   813.0323 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  19 - Loss:   624.6881 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  20 - Loss:   456.2939 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  21 - Loss:   457.8674 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  22 - Loss:   621.1778 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  23 - Loss:   585.1297 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  24 - Loss:   747.2568 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  25 - Loss:   649.1079 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  26 - Loss:   570.8172 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  27 - Loss:  1297.3639 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  28 - Loss:  1061.2814 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  29 - Loss:   533.6937 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  30 - Loss:  1066.4137 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  31 - Loss:   408.2536 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  32 - Loss:   838.2420 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch  33 - Loss:  1417.0103 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  34 - Loss:   539.3770 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  35 - Loss:   817.0137 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  36 - Loss:   789.1566 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  37 - Loss:   740.2957 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch  38 - Loss:   783.4700 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  39 - Loss:   762.2880 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  40 - Loss:   223.2090 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  41 - Loss:   550.1897 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  42 - Loss:  1005.4849 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  43 - Loss:   489.1324 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  44 - Loss:  1009.3833 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  45 - Loss:   284.9315 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  46 - Loss:   388.5496 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  47 - Loss:   853.5504 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  48 - Loss:   992.7684 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  49 - Loss:   511.9385 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  50 - Loss:   539.2951 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  51 - Loss:   838.8147 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  52 - Loss:   924.1901 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  53 - Loss:   589.9182 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  54 - Loss:   529.7330 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  55 - Loss:   990.6742 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  56 - Loss:  1011.3442 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch  57 - Loss:  1150.7365 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  58 - Loss:   633.5761 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  59 - Loss:   595.8876 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  60 - Loss:   684.0771 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  61 - Loss:  1382.1052 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  62 - Loss:  1329.0054 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  63 - Loss:   600.6923 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  64 - Loss:   728.7969 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  65 - Loss:   382.3035 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch  66 - Loss:   621.7097 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  67 - Loss:   775.7670 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  68 - Loss:   718.4351 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  69 - Loss:   518.9417 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  70 - Loss:   363.0633 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  71 - Loss:   791.9606 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  72 - Loss:   455.0534 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  73 - Loss:   983.4148 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  74 - Loss:  1183.6343 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  75 - Loss:   699.5278 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  76 - Loss:   993.9108 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  77 - Loss:   823.9733 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  78 - Loss:   683.4281 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch  79 - Loss:   404.3006 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  80 - Loss:  1026.6257 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  81 - Loss:  1179.5344 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  5, Batch  82 - Loss:   594.4620 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  83 - Loss:  1109.1417 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.859375\n",
      "Epoch  5, Batch  84 - Loss:   839.2327 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  85 - Loss:   689.2395 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  5, Batch  86 - Loss:   750.2402 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch  87 - Loss:  1191.3892 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8671875\n",
      "Epoch  5, Batch  88 - Loss:   577.2516 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  89 - Loss:   774.0006 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch  90 - Loss:   661.5511 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  91 - Loss:   263.8112 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  92 - Loss:   918.1570 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  93 - Loss:   514.7710 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch  94 - Loss:   641.2723 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  95 - Loss:   410.2405 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  96 - Loss:   800.6493 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch  97 - Loss:  1336.3706 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch  98 - Loss:   340.8394 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch  99 - Loss:  1128.1295 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 100 - Loss:  1066.7222 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 101 - Loss:   783.1253 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 102 - Loss:  1032.4794 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 103 - Loss:  1272.2979 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 104 - Loss:   967.2563 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 105 - Loss:   832.6873 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 106 - Loss:  1213.6537 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 107 - Loss:   471.0062 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 108 - Loss:   771.7591 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 109 - Loss:   670.0395 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 110 - Loss:   307.3321 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 111 - Loss:   603.5354 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 112 - Loss:   691.2803 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 113 - Loss:   836.7427 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 114 - Loss:  1534.4926 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 115 - Loss:   922.5126 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 116 - Loss:   566.6044 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 117 - Loss:   486.6848 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 118 - Loss:   528.0789 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 119 - Loss:   799.8640 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 120 - Loss:   693.0817 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 121 - Loss:   572.9256 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 122 - Loss:   752.3155 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 123 - Loss:   768.1960 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 124 - Loss:  1157.5276 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 125 - Loss:  1355.2004 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 126 - Loss:   821.2211 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 127 - Loss:  1068.9368 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch 128 - Loss:   960.9778 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch 129 - Loss:   628.9537 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 130 - Loss:   960.3282 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 131 - Loss:   402.9521 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 132 - Loss:   693.8828 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 133 - Loss:   935.0623 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 134 - Loss:   995.8218 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 135 - Loss:   886.0872 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 136 - Loss:  1207.5496 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 137 - Loss:   634.8075 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 138 - Loss:   623.7438 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 139 - Loss:   871.8365 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 140 - Loss:   990.1599 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 141 - Loss:   732.3741 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 142 - Loss:   409.1747 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 143 - Loss:   571.3922 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 144 - Loss:   610.0341 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 145 - Loss:   926.9216 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 146 - Loss:   413.6344 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 147 - Loss:   814.2090 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 148 - Loss:  1104.4144 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 149 - Loss:  1359.1638 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 150 - Loss:   533.4232 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 151 - Loss:  1117.3514 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 152 - Loss:   517.0392 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 153 - Loss:   611.3574 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 154 - Loss:   921.1672 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 155 - Loss:   621.4288 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 156 - Loss:   573.8938 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 157 - Loss:   366.0868 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 158 - Loss:   638.9066 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 159 - Loss:   743.4308 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 160 - Loss:   630.6273 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 161 - Loss:   749.8492 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 162 - Loss:   489.7166 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 163 - Loss:  1176.9568 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 164 - Loss:  1179.8373 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 165 - Loss:   767.6326 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 166 - Loss:   834.2972 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 167 - Loss:   454.2763 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 168 - Loss:   812.9847 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 169 - Loss:  1240.0554 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 170 - Loss:   607.3435 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 171 - Loss:   796.7360 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 172 - Loss:  1064.6934 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 173 - Loss:   667.7756 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 174 - Loss:  1255.8872 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 175 - Loss:   687.1012 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 176 - Loss:   533.8571 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 177 - Loss:   489.1681 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 178 - Loss:   581.0364 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 179 - Loss:   490.1436 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 180 - Loss:   717.2943 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 181 - Loss:   380.0873 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 182 - Loss:   516.3735 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 183 - Loss:   553.6976 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 184 - Loss:   891.8645 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 185 - Loss:   850.2238 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 186 - Loss:   950.2723 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 187 - Loss:  1125.8818 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 188 - Loss:   965.8408 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 189 - Loss:   973.1010 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 190 - Loss:   588.8234 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch 191 - Loss:   641.7068 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 192 - Loss:   828.2660 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch 193 - Loss:  1150.1829 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 194 - Loss:   725.8425 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 195 - Loss:   950.3954 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 196 - Loss:   482.8148 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 197 - Loss:  1031.4595 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 198 - Loss:   576.2755 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 199 - Loss:   991.5761 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 200 - Loss:   465.2098 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 201 - Loss:   278.1550 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 202 - Loss:   596.1512 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 203 - Loss:   690.8057 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 204 - Loss:   720.7959 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 205 - Loss:   613.8694 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 206 - Loss:   758.7982 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 207 - Loss:   676.6321 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 208 - Loss:   753.9099 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 209 - Loss:  1005.9641 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 210 - Loss:   935.6417 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 211 - Loss:   642.6426 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 212 - Loss:   937.6948 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 213 - Loss:   420.9837 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 214 - Loss:  1388.4093 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 215 - Loss:   896.2026 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 216 - Loss:   376.7074 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 217 - Loss:  1020.1469 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 218 - Loss:  1250.0442 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 219 - Loss:   614.9656 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 220 - Loss:   672.8026 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 221 - Loss:   584.9467 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 222 - Loss:   797.8312 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 223 - Loss:  1115.4059 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 224 - Loss:  1055.4128 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 225 - Loss:   546.2317 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 226 - Loss:   843.8893 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 227 - Loss:   804.9257 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 228 - Loss:   885.6460 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 229 - Loss:   647.3364 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 230 - Loss:   399.9550 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 231 - Loss:   609.6795 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 232 - Loss:   573.9012 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 233 - Loss:   650.1355 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 234 - Loss:   337.5407 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 235 - Loss:  1125.3431 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 236 - Loss:   858.4964 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 237 - Loss:   997.5544 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 238 - Loss:   918.1283 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 239 - Loss:   384.5470 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 240 - Loss:   705.6339 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 241 - Loss:   526.9373 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 242 - Loss:   876.5131 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 243 - Loss:  1076.4193 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 244 - Loss:   598.2258 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 245 - Loss:   720.2411 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 246 - Loss:   733.6586 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 247 - Loss:   624.8278 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 248 - Loss:  1204.3730 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 249 - Loss:   617.0338 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 250 - Loss:   606.5283 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 251 - Loss:   716.1376 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 252 - Loss:   639.4783 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 253 - Loss:   454.1113 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 254 - Loss:   619.4952 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 255 - Loss:   679.6888 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 256 - Loss:   823.4362 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 257 - Loss:   685.3070 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 258 - Loss:   815.8403 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 259 - Loss:   509.2284 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 260 - Loss:   365.5766 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 261 - Loss:    84.7873 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 262 - Loss:   888.6924 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 263 - Loss:   646.4651 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 264 - Loss:  1020.1845 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 265 - Loss:   456.0667 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 266 - Loss:   739.9166 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 267 - Loss:  1312.0244 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 268 - Loss:   944.0901 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 269 - Loss:   971.9718 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 270 - Loss:   975.5458 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 271 - Loss:   964.8804 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 272 - Loss:   767.4760 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 273 - Loss:   467.5933 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 274 - Loss:   948.0640 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 275 - Loss:   581.1945 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 276 - Loss:   405.1080 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 277 - Loss:  1025.3567 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 278 - Loss:   798.7217 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 279 - Loss:   825.3376 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 280 - Loss:  1002.8947 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 281 - Loss:   490.8008 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87109375\n",
      "Epoch  5, Batch 282 - Loss:   727.3126 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch 283 - Loss:   509.9004 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch 284 - Loss:   618.1034 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.875\n",
      "Epoch  5, Batch 285 - Loss:   636.1170 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 286 - Loss:   803.8943 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 287 - Loss:   768.2815 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 288 - Loss:  1424.0150 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 289 - Loss:  1482.5129 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 290 - Loss:   983.3845 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 291 - Loss:   439.9342 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 292 - Loss:   641.8594 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 293 - Loss:   487.9294 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 294 - Loss:   394.5140 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 295 - Loss:   927.7224 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 296 - Loss:   712.3619 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 297 - Loss:   933.9988 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 298 - Loss:   931.6777 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 299 - Loss:   863.6255 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 300 - Loss:   464.7453 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 301 - Loss:   655.3607 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 302 - Loss:  1130.5530 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 303 - Loss:   723.6442 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 304 - Loss:   746.5055 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 305 - Loss:   992.1993 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 306 - Loss:   896.8527 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 307 - Loss:  1241.2688 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 308 - Loss:   712.1613 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 309 - Loss:   693.2551 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 310 - Loss:   430.3265 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 311 - Loss:   440.6909 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 312 - Loss:  1298.7412 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 313 - Loss:   772.9071 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 314 - Loss:   906.3657 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 315 - Loss:   504.0902 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 316 - Loss:   841.0851 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 317 - Loss:  1024.7104 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 318 - Loss:   873.4350 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 319 - Loss:   763.2902 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 320 - Loss:   609.7665 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 321 - Loss:   515.2428 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 322 - Loss:   887.3329 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 323 - Loss:   774.9928 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 324 - Loss:   854.6858 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 325 - Loss:   457.5864 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 326 - Loss:   559.7384 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 327 - Loss:   556.3352 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 328 - Loss:  1000.0466 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 329 - Loss:   726.2150 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 330 - Loss:   432.6440 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 331 - Loss:   963.7989 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 332 - Loss:   694.0131 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 333 - Loss:   415.1812 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 334 - Loss:   919.5670 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 335 - Loss:   995.5490 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 336 - Loss:  1251.6837 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  5, Batch 337 - Loss:   682.4609 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 338 - Loss:   699.4992 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 339 - Loss:   964.9349 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 340 - Loss:   729.1776 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 341 - Loss:   853.0981 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 342 - Loss:   721.9158 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 343 - Loss:   785.1978 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 344 - Loss:   545.3829 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 345 - Loss:   546.0067 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 346 - Loss:   418.7857 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 347 - Loss:   735.4738 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 348 - Loss:   489.1474 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 349 - Loss:   945.0226 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 350 - Loss:   645.2112 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 351 - Loss:   651.7075 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 352 - Loss:   547.4685 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 353 - Loss:   786.5468 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 354 - Loss:   544.2183 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 355 - Loss:   708.4719 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 356 - Loss:   795.7255 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 357 - Loss:   568.9764 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 358 - Loss:   818.5391 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 359 - Loss:   826.4081 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 360 - Loss:   793.1742 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 361 - Loss:  1027.6450 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 362 - Loss:   625.2475 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 363 - Loss:  1086.1833 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 364 - Loss:   565.6241 Validation Accuracy: 0.878906\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 365 - Loss:   448.4375 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 366 - Loss:   470.9002 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 367 - Loss:   590.6523 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 368 - Loss:   447.0613 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 369 - Loss:   917.3666 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 370 - Loss:  1079.1548 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 371 - Loss:   556.5240 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 372 - Loss:   765.3853 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 373 - Loss:   664.2681 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 374 - Loss:   590.2499 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  5, Batch 375 - Loss:   772.3074 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 376 - Loss:   288.3871 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 377 - Loss:   580.1407 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 378 - Loss:   560.0062 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 379 - Loss:  1104.4565 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 380 - Loss:   456.3118 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 381 - Loss:   603.1198 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 382 - Loss:   338.3820 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 383 - Loss:   801.5531 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 384 - Loss:   854.3812 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 385 - Loss:   881.1357 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 386 - Loss:   819.0786 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 387 - Loss:  1266.5874 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 388 - Loss:   654.3483 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 389 - Loss:   792.4804 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 390 - Loss:   602.2631 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 391 - Loss:   587.1752 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 392 - Loss:  1000.7355 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 393 - Loss:   439.6097 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 394 - Loss:   689.0477 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 395 - Loss:   770.7109 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 396 - Loss:  1032.5449 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 397 - Loss:  1170.7507 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 398 - Loss:   444.6884 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 399 - Loss:   895.4908 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 400 - Loss:   882.8408 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 401 - Loss:   950.2817 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 402 - Loss:   974.3014 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 403 - Loss:   785.6179 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 404 - Loss:   815.7430 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  5, Batch 405 - Loss:  1435.9343 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 406 - Loss:   699.8455 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 407 - Loss:   722.5059 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 408 - Loss:   581.6001 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 409 - Loss:   679.1982 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 410 - Loss:   519.1724 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 411 - Loss:   240.5635 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 412 - Loss:   677.7991 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 413 - Loss:   871.6813 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 414 - Loss:   302.7990 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 415 - Loss:   596.8630 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 416 - Loss:   581.0786 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 417 - Loss:   331.2403 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 418 - Loss:   607.9105 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 419 - Loss:   853.3190 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 420 - Loss:   990.1581 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 421 - Loss:   308.1492 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 422 - Loss:   910.1024 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 423 - Loss:   721.7605 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  5, Batch 424 - Loss:   702.4514 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  5, Batch 425 - Loss:   402.3648 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  5, Batch 426 - Loss:   746.6328 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  5, Batch 427 - Loss:   230.6092 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  5, Batch 428 - Loss:  1030.3519 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  5, Batch 429 - Loss:  1289.1814 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch   1 - Loss:   779.9138 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch   2 - Loss:   633.3352 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch   3 - Loss:   516.5319 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch   4 - Loss:   744.6841 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch   5 - Loss:   997.0798 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch   6 - Loss:   737.5159 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch   7 - Loss:   578.9565 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch   8 - Loss:   860.1222 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch   9 - Loss:   890.8413 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  10 - Loss:   518.3169 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  11 - Loss:   371.8822 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  12 - Loss:   779.6829 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  13 - Loss:   726.4165 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  14 - Loss:   870.8871 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  15 - Loss:   771.1581 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  16 - Loss:   469.3158 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  17 - Loss:   593.9761 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  18 - Loss:   583.4056 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  19 - Loss:   635.3887 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  20 - Loss:   452.9183 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  21 - Loss:   523.6433 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  22 - Loss:   956.6709 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  23 - Loss:   803.7009 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  24 - Loss:  1026.0701 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  25 - Loss:   605.6052 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  26 - Loss:   384.3271 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  27 - Loss:   272.0041 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  28 - Loss:   471.8473 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  29 - Loss:   823.0068 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  30 - Loss:   941.9140 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  31 - Loss:   871.7601 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  32 - Loss:   597.0321 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  33 - Loss:   409.5941 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  34 - Loss:   664.7516 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  35 - Loss:   709.1885 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  36 - Loss:   454.7598 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch  37 - Loss:   595.2933 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  38 - Loss:  1169.4277 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  39 - Loss:  1076.5562 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  40 - Loss:   460.3411 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  41 - Loss:  1057.9269 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  42 - Loss:   448.7231 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  43 - Loss:   608.5344 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  44 - Loss:  1223.8743 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  45 - Loss:   434.9115 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  46 - Loss:   836.4863 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  47 - Loss:   479.5478 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  48 - Loss:  1221.6570 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  49 - Loss:   879.8110 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  50 - Loss:  1054.8365 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  51 - Loss:  1121.6097 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  52 - Loss:   471.7876 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  53 - Loss:   709.1455 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  54 - Loss:   826.8461 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  55 - Loss:   819.8571 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  56 - Loss:   718.3129 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  57 - Loss:   291.9401 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  58 - Loss:   528.6483 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  59 - Loss:   698.9116 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  60 - Loss:   936.2968 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  61 - Loss:   770.7913 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  62 - Loss:   984.0781 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  63 - Loss:  1224.4755 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  64 - Loss:   989.5432 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  65 - Loss:   637.9138 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  66 - Loss:   660.0436 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  67 - Loss:   526.4814 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  68 - Loss:   805.5790 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  69 - Loss:  1229.3464 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  70 - Loss:   720.2877 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  71 - Loss:   705.1042 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  72 - Loss:   764.0939 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  73 - Loss:   478.2735 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  74 - Loss:   510.5981 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  75 - Loss:   931.2056 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  76 - Loss:   530.9769 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  77 - Loss:   901.1107 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  78 - Loss:   825.7800 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  79 - Loss:   552.0879 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  80 - Loss:   269.8629 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch  81 - Loss:    84.5128 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch  82 - Loss:   922.8215 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  83 - Loss:   899.0852 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  84 - Loss:   563.1300 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  85 - Loss:   836.7758 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  86 - Loss:   739.6837 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  87 - Loss:  1122.4266 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch  88 - Loss:   481.8787 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  89 - Loss:   379.8138 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  90 - Loss:   487.8556 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch  91 - Loss:   833.9962 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch  92 - Loss:   782.1571 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch  93 - Loss:   595.0905 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  94 - Loss:   903.0942 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  95 - Loss:   639.1136 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  96 - Loss:   820.2065 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch  97 - Loss:   686.8672 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch  98 - Loss:   637.2487 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch  99 - Loss:   287.6240 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 100 - Loss:   467.1892 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 101 - Loss:   689.7318 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 102 - Loss:   566.7694 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 103 - Loss:   500.8881 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 104 - Loss:   736.9037 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 105 - Loss:  1107.5728 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 106 - Loss:   638.6807 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 107 - Loss:  1043.7847 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 108 - Loss:   749.1117 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 109 - Loss:   747.7744 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 110 - Loss:   605.2710 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 111 - Loss:   490.5526 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 112 - Loss:   773.5062 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 113 - Loss:   327.2055 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 114 - Loss:   271.9366 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 115 - Loss:   294.3089 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 116 - Loss:   732.4416 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 117 - Loss:   873.2313 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 118 - Loss:   529.1022 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 119 - Loss:   484.9279 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 120 - Loss:   962.9265 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 121 - Loss:  1072.1305 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 122 - Loss:   420.7861 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 123 - Loss:   555.5157 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 124 - Loss:   576.8933 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 125 - Loss:  1064.5449 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 126 - Loss:   313.6815 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 127 - Loss:  1020.6652 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 128 - Loss:   775.2474 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 129 - Loss:   658.7521 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 130 - Loss:   220.5977 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 131 - Loss:   899.3477 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 132 - Loss:   365.3469 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 133 - Loss:  1135.6089 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 134 - Loss:   846.5787 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 135 - Loss:   521.8888 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 136 - Loss:   586.5493 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 137 - Loss:   435.7425 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 138 - Loss:   654.6823 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 139 - Loss:   806.8750 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 140 - Loss:  1005.8027 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 141 - Loss:   564.4366 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 142 - Loss:  1037.9352 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 143 - Loss:   596.9442 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 144 - Loss:   521.6107 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 145 - Loss:   562.9309 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 146 - Loss:   508.5484 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 147 - Loss:   389.6991 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 148 - Loss:   299.3996 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 149 - Loss:   558.6505 Validation Accuracy: 0.882812\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 150 - Loss:   785.0828 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch 151 - Loss:  1247.2019 Validation Accuracy: 0.875000\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 152 - Loss:   796.0851 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 153 - Loss:   566.7191 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 154 - Loss:  1100.5951 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 155 - Loss:   695.7814 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  6, Batch 156 - Loss:   514.6340 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  6, Batch 157 - Loss:   539.2719 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 158 - Loss:   737.9719 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch 159 - Loss:   560.8279 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch 160 - Loss:   604.9111 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 161 - Loss:   613.7917 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  6, Batch 162 - Loss:   717.6304 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 163 - Loss:   864.1664 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 164 - Loss:   928.7495 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 165 - Loss:   569.0168 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8828125\n",
      "Epoch  6, Batch 166 - Loss:   967.5281 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 167 - Loss:   646.7439 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 168 - Loss:   543.9242 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 169 - Loss:   585.9019 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 170 - Loss:   744.8252 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 171 - Loss:   740.6426 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 172 - Loss:   629.0759 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 173 - Loss:   658.0173 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 174 - Loss:  1008.9319 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 175 - Loss:   659.3054 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 176 - Loss:   575.9236 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 177 - Loss:   748.9355 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 178 - Loss:   571.9995 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 179 - Loss:   661.7755 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 180 - Loss:   510.3054 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 181 - Loss:   769.1156 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 182 - Loss:   512.1898 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 183 - Loss:   935.2842 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 184 - Loss:   483.3049 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 185 - Loss:   830.3436 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 186 - Loss:   779.6261 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 187 - Loss:   965.2389 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 188 - Loss:   527.2314 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 189 - Loss:   547.0668 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 190 - Loss:   751.5461 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 191 - Loss:   236.4537 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 192 - Loss:   557.8424 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 193 - Loss:   670.8174 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 194 - Loss:   762.4980 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 195 - Loss:   362.0314 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 196 - Loss:   454.3214 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 197 - Loss:   608.8202 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 198 - Loss:   758.1523 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 199 - Loss:   627.2116 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 200 - Loss:   642.6131 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 201 - Loss:   546.5070 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 202 - Loss:  1088.0134 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 203 - Loss:   397.2097 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 204 - Loss:   735.1689 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 205 - Loss:  1098.5614 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 206 - Loss:   608.9155 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 207 - Loss:   426.3993 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 208 - Loss:   970.2532 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 209 - Loss:   745.8758 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 210 - Loss:   540.6628 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 211 - Loss:   618.6825 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 212 - Loss:   389.9047 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 213 - Loss:   369.7178 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 214 - Loss:   893.5258 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 215 - Loss:   572.4588 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 216 - Loss:  1107.2356 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 217 - Loss:   519.3086 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 218 - Loss:   291.8271 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 219 - Loss:   265.9603 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 220 - Loss:   406.9798 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 221 - Loss:   914.4052 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 222 - Loss:   558.9408 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 223 - Loss:   159.2288 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 224 - Loss:   725.8101 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 225 - Loss:   616.4484 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 226 - Loss:   395.5184 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 227 - Loss:   664.1177 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 228 - Loss:   973.9615 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 229 - Loss:   455.0482 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 230 - Loss:   680.8684 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.87890625\n",
      "Epoch  6, Batch 231 - Loss:   821.5828 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 232 - Loss:   612.2393 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 233 - Loss:   778.0781 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 234 - Loss:   252.3808 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 235 - Loss:   528.4047 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 236 - Loss:   613.1053 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 237 - Loss:   887.6792 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 238 - Loss:   717.6955 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 239 - Loss:   752.0320 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 240 - Loss:   774.2880 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 241 - Loss:   826.2587 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 242 - Loss:   399.3060 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 243 - Loss:   429.7764 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 244 - Loss:   808.5259 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 245 - Loss:   414.2240 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 246 - Loss:   471.7467 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 247 - Loss:   451.7366 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 248 - Loss:  1034.7256 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 249 - Loss:   543.3884 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 250 - Loss:   627.2877 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 251 - Loss:   587.6207 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 252 - Loss:   862.3655 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 253 - Loss:   601.8643 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 254 - Loss:   411.6252 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 255 - Loss:   531.8639 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 256 - Loss:   617.2251 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 257 - Loss:   624.2960 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 258 - Loss:   716.0496 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 259 - Loss:   798.2858 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 260 - Loss:   600.3444 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 261 - Loss:   802.9011 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 262 - Loss:  1065.8809 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 263 - Loss:   557.4667 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 264 - Loss:   882.1745 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 265 - Loss:   997.9150 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 266 - Loss:   541.5818 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 267 - Loss:   789.7410 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  6, Batch 268 - Loss:   327.9640 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 269 - Loss:   700.3781 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 270 - Loss:   627.3447 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 271 - Loss:  1175.5299 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 272 - Loss:   610.9701 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 273 - Loss:   856.0859 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 274 - Loss:   470.1126 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 275 - Loss:   562.0483 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 276 - Loss:   796.1473 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 277 - Loss:   864.3956 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 278 - Loss:   943.9901 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 279 - Loss:   233.5048 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 280 - Loss:   860.8608 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 281 - Loss:   432.5663 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 282 - Loss:   805.4523 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 283 - Loss:   547.4803 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 284 - Loss:   345.5897 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 285 - Loss:   275.6834 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 286 - Loss:   837.4117 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 287 - Loss:   251.2832 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 288 - Loss:   982.0098 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 289 - Loss:   584.0631 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 290 - Loss:   440.6849 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 291 - Loss:   611.7392 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 292 - Loss:  1236.6667 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 293 - Loss:   999.1962 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 294 - Loss:   330.9221 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 295 - Loss:   599.0193 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 296 - Loss:   526.9528 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 297 - Loss:   506.8502 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 298 - Loss:   893.5913 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 299 - Loss:   733.9609 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 300 - Loss:   423.2581 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 301 - Loss:   540.7823 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 302 - Loss:   314.0636 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 303 - Loss:   803.9618 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 304 - Loss:   504.2848 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 305 - Loss:   812.6693 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 306 - Loss:   476.2331 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 307 - Loss:   827.8387 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 308 - Loss:   825.4520 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 309 - Loss:   407.3056 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 310 - Loss:   435.8557 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 311 - Loss:   648.8250 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 312 - Loss:   667.9893 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 313 - Loss:  1030.1393 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 314 - Loss:   543.9311 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 315 - Loss:   712.0624 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 316 - Loss:   796.2297 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 317 - Loss:   233.7911 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 318 - Loss:   613.1606 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 319 - Loss:   820.6444 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 320 - Loss:   791.7645 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 321 - Loss:   570.9722 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 322 - Loss:   567.6563 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 323 - Loss:   510.2212 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 324 - Loss:   894.7526 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 325 - Loss:   617.0057 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 326 - Loss:   774.2982 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 327 - Loss:   879.9336 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 328 - Loss:   532.3400 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 329 - Loss:   623.9946 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 330 - Loss:   450.8283 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 331 - Loss:   508.0558 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 332 - Loss:   794.4869 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 333 - Loss:   501.8177 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 334 - Loss:   753.5999 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 335 - Loss:   633.5664 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 336 - Loss:   431.3856 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 337 - Loss:   454.7113 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 338 - Loss:   942.3425 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 339 - Loss:   528.0714 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 340 - Loss:   332.4150 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 341 - Loss:   883.0720 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 342 - Loss:  1038.5609 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 343 - Loss:   558.1418 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 344 - Loss:   158.8729 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 345 - Loss:   143.4047 Validation Accuracy: 0.890625\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 346 - Loss:   708.6588 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 347 - Loss:   333.3903 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 348 - Loss:   549.9474 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 349 - Loss:   810.2584 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 350 - Loss:   607.0612 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 351 - Loss:   772.7384 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 352 - Loss:   402.3964 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 353 - Loss:   652.8574 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 354 - Loss:   409.1624 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 355 - Loss:   660.0500 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 356 - Loss:   416.0589 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 357 - Loss:   484.5518 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 358 - Loss:  1358.2681 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 359 - Loss:  1230.4084 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 360 - Loss:   449.6334 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 361 - Loss:   376.4692 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 362 - Loss:  1075.8320 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 363 - Loss:   702.0735 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 364 - Loss:   516.7909 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 365 - Loss:   994.2731 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 366 - Loss:   929.3103 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 367 - Loss:   730.6027 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 368 - Loss:   584.0731 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 369 - Loss:   652.3827 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 370 - Loss:   509.1311 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 371 - Loss:   682.5869 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 372 - Loss:   901.8016 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 373 - Loss:   425.4959 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 374 - Loss:   401.7643 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 375 - Loss:   520.9871 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 376 - Loss:   785.3871 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 377 - Loss:   263.5690 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 378 - Loss:   510.8856 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 379 - Loss:   635.5490 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 380 - Loss:   847.9529 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 381 - Loss:   462.7863 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 382 - Loss:  1065.2196 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 383 - Loss:   179.0952 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 384 - Loss:   538.2960 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 385 - Loss:   658.3945 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 386 - Loss:   719.1957 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 387 - Loss:   920.2964 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 388 - Loss:   986.2144 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 389 - Loss:   674.7623 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 390 - Loss:   756.7638 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 391 - Loss:   818.5142 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 392 - Loss:   227.2538 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 393 - Loss:   474.9357 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 394 - Loss:   697.7456 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  6, Batch 395 - Loss:   498.1968 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  6, Batch 396 - Loss:   526.2069 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  6, Batch 397 - Loss:  1246.0820 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 398 - Loss:   566.8973 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 399 - Loss:   904.9052 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 400 - Loss:   364.0357 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 401 - Loss:   653.9911 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 402 - Loss:   439.2625 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 403 - Loss:   669.4862 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 404 - Loss:   740.9105 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 405 - Loss:   763.0613 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 406 - Loss:   695.0510 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 407 - Loss:  1174.9692 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 408 - Loss:   572.5770 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 409 - Loss:   853.7070 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 410 - Loss:   974.7086 Validation Accuracy: 0.886719\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 411 - Loss:   208.0008 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 412 - Loss:   633.8718 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 413 - Loss:   603.4755 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  6, Batch 414 - Loss:   665.9652 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 415 - Loss:   877.1644 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 416 - Loss:   629.1873 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 417 - Loss:   684.3610 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  6, Batch 418 - Loss:   367.8586 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 419 - Loss:   823.3650 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  6, Batch 420 - Loss:  1205.4526 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 421 - Loss:   980.6822 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 422 - Loss:   474.8483 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  6, Batch 423 - Loss:   513.5939 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  6, Batch 424 - Loss:   399.9370 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  6, Batch 425 - Loss:   657.4518 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 426 - Loss:   412.0113 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 427 - Loss:   484.2167 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 428 - Loss:   482.7321 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  6, Batch 429 - Loss:   533.0546 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch   1 - Loss:   256.7490 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch   2 - Loss:   601.0694 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch   3 - Loss:   585.8567 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch   4 - Loss:   459.8096 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch   5 - Loss:   573.1990 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch   6 - Loss:   599.1655 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch   7 - Loss:   814.7083 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch   8 - Loss:   624.4261 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch   9 - Loss:   449.8713 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  10 - Loss:   467.4898 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  11 - Loss:   461.8719 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  12 - Loss:  1088.4139 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  13 - Loss:   555.6617 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  14 - Loss:   821.9327 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  15 - Loss:   873.3899 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  16 - Loss:   582.2862 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  17 - Loss:   606.1486 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  18 - Loss:   505.2767 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  19 - Loss:   307.7407 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  20 - Loss:   546.2421 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  21 - Loss:   725.3628 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  22 - Loss:   611.5133 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  23 - Loss:   684.5453 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch  24 - Loss:   151.9726 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  25 - Loss:   232.1849 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  26 - Loss:   264.8633 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  27 - Loss:  1291.7692 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  28 - Loss:   702.3506 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  29 - Loss:   672.3077 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  30 - Loss:   623.0418 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  31 - Loss:   205.4753 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch  32 - Loss:   446.7728 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  33 - Loss:   626.0933 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  34 - Loss:   579.1887 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch  35 - Loss:   406.3607 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  36 - Loss:   747.7505 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  37 - Loss:   237.6784 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  38 - Loss:   448.2685 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  39 - Loss:   336.7137 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  40 - Loss:   374.4818 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  41 - Loss:   338.3502 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  42 - Loss:   874.0533 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  43 - Loss:   652.7916 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  44 - Loss:   661.9447 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  45 - Loss:   293.2364 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch  46 - Loss:   346.0558 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  47 - Loss:   567.4217 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  48 - Loss:   617.1608 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch  49 - Loss:   511.0708 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  50 - Loss:   477.6069 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  51 - Loss:   837.4485 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  52 - Loss:   606.6244 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  53 - Loss:   542.7001 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  54 - Loss:   613.8525 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  55 - Loss:   792.9802 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  56 - Loss:   823.2334 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  57 - Loss:   740.0774 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  58 - Loss:   373.8490 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  59 - Loss:   403.7823 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  60 - Loss:   737.4285 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  61 - Loss:   734.5604 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  62 - Loss:   476.4410 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  63 - Loss:   770.6498 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  64 - Loss:   815.8785 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  65 - Loss:   816.9823 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch  66 - Loss:  1270.3837 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  67 - Loss:   721.7169 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  68 - Loss:   977.8040 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  69 - Loss:   500.3457 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  70 - Loss:   723.6594 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch  71 - Loss:   558.5320 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  72 - Loss:   380.9806 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  73 - Loss:   312.9548 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  74 - Loss:   551.2323 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  75 - Loss:   257.5936 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  76 - Loss:   186.3545 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  77 - Loss:   911.6060 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  78 - Loss:   679.3951 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  79 - Loss:   521.2660 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  80 - Loss:   775.4021 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  81 - Loss:   442.8630 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  82 - Loss:   440.8388 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  83 - Loss:   557.3490 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  84 - Loss:  1202.8005 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch  85 - Loss:   535.6357 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  86 - Loss:   426.6110 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  87 - Loss:  1058.0260 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  88 - Loss:   422.8585 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  89 - Loss:   636.7462 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  90 - Loss:   442.6851 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  91 - Loss:   472.4012 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  92 - Loss:   688.0366 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch  93 - Loss:   774.6843 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  94 - Loss:   527.2167 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  95 - Loss:   481.9931 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  96 - Loss:   576.1549 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch  97 - Loss:   553.8843 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch  98 - Loss:   293.8267 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch  99 - Loss:   851.6257 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 100 - Loss:  1309.3450 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 101 - Loss:   639.2130 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 102 - Loss:   476.6454 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 103 - Loss:   689.6571 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  7, Batch 104 - Loss:   341.9710 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 105 - Loss:   782.4052 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 106 - Loss:   536.5336 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 107 - Loss:   889.0228 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 108 - Loss:   442.0912 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 109 - Loss:   576.5605 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 110 - Loss:   837.5793 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 111 - Loss:   658.0562 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 112 - Loss:   415.9005 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 113 - Loss:   690.9371 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 114 - Loss:   915.5339 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 115 - Loss:   613.9352 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 116 - Loss:   677.6603 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 117 - Loss:   874.5679 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 118 - Loss:   580.7173 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 119 - Loss:   716.9265 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 120 - Loss:   324.6931 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 121 - Loss:   439.2284 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 122 - Loss:   682.3306 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 123 - Loss:   840.8702 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch 124 - Loss:   601.3783 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 125 - Loss:   824.7615 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 126 - Loss:   644.4564 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 127 - Loss:   786.4846 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 128 - Loss:   432.7187 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 129 - Loss:   589.7863 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 130 - Loss:   548.1193 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 131 - Loss:   508.8023 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 132 - Loss:   422.0704 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 133 - Loss:   595.6514 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 134 - Loss:   412.5149 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 135 - Loss:  1342.8809 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 136 - Loss:   724.2831 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 137 - Loss:   197.0078 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 138 - Loss:   282.2818 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 139 - Loss:   480.9959 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 140 - Loss:   429.4573 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 141 - Loss:   566.1465 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 142 - Loss:   675.4902 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 143 - Loss:   442.0873 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 144 - Loss:   337.9938 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 145 - Loss:   427.7894 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 146 - Loss:   813.2040 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 147 - Loss:  1050.7601 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 148 - Loss:  1174.3359 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 149 - Loss:   823.2534 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 150 - Loss:   528.0565 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 151 - Loss:   363.0129 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 152 - Loss:   358.7611 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 153 - Loss:   889.1079 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 154 - Loss:   744.3492 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 155 - Loss:   483.8706 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 156 - Loss:  1077.1987 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 157 - Loss:   767.2006 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 158 - Loss:   411.8121 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 159 - Loss:   579.6211 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 160 - Loss:   673.3060 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 161 - Loss:   554.7559 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 162 - Loss:   522.1579 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 163 - Loss:   822.1635 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 164 - Loss:   826.5360 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 165 - Loss:   549.5255 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 166 - Loss:   320.1872 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 167 - Loss:   202.8535 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 168 - Loss:   380.0792 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 169 - Loss:   891.3497 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 170 - Loss:   528.8031 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 171 - Loss:   681.5596 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 172 - Loss:   442.4785 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 173 - Loss:   713.5193 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 174 - Loss:   461.5071 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 175 - Loss:   519.6790 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 176 - Loss:   495.7929 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 177 - Loss:   802.8284 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 178 - Loss:   752.8394 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 179 - Loss:   553.6315 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 180 - Loss:   447.3132 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 181 - Loss:   524.5337 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 182 - Loss:   792.0436 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 183 - Loss:   941.0529 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 184 - Loss:   610.0073 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 185 - Loss:   280.2480 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 186 - Loss:   659.1405 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 187 - Loss:   286.0483 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 188 - Loss:   771.8649 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 189 - Loss:   958.9385 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 190 - Loss:   488.9508 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 191 - Loss:   806.8010 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 192 - Loss:   128.0415 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 193 - Loss:   921.5264 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 194 - Loss:   727.1515 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 195 - Loss:   757.2669 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 196 - Loss:   546.2406 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 197 - Loss:   739.4635 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 198 - Loss:   665.0453 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 199 - Loss:   460.5352 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 200 - Loss:   375.2139 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 201 - Loss:   947.9601 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 202 - Loss:   814.4598 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 203 - Loss:   860.8621 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 204 - Loss:   551.7332 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 205 - Loss:   847.0394 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 206 - Loss:   764.9534 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 207 - Loss:   516.3937 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 208 - Loss:   567.9993 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 209 - Loss:   338.9105 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 210 - Loss:   681.1459 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 211 - Loss:   215.0121 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 212 - Loss:   785.6353 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 213 - Loss:   599.8241 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 214 - Loss:   480.7512 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 215 - Loss:  1051.7990 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.890625\n",
      "Epoch  7, Batch 216 - Loss:   210.9121 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.88671875\n",
      "Epoch  7, Batch 217 - Loss:   680.2441 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 218 - Loss:   840.1668 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 219 - Loss:   695.6851 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 220 - Loss:   936.2476 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 221 - Loss:   451.2955 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 222 - Loss:   381.9252 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 223 - Loss:   660.9925 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 224 - Loss:   350.4347 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 225 - Loss:   468.0011 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 226 - Loss:   380.1421 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 227 - Loss:   307.7122 Validation Accuracy: 0.894531\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 228 - Loss:   327.1882 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 229 - Loss:   282.0561 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 230 - Loss:   431.2560 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 231 - Loss:   410.8221 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 232 - Loss:   543.5900 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 233 - Loss:   918.7789 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 234 - Loss:   419.4645 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 235 - Loss:   523.7187 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 236 - Loss:   597.9401 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 237 - Loss:   532.3889 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 238 - Loss:   122.0946 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 239 - Loss:   475.8750 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 240 - Loss:   313.2019 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 241 - Loss:   559.9781 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 242 - Loss:   469.0684 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 243 - Loss:   462.8582 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 244 - Loss:   641.7319 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 245 - Loss:   463.9695 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 246 - Loss:   685.3863 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 247 - Loss:   485.2091 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 248 - Loss:   689.1143 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 249 - Loss:   418.1992 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 250 - Loss:   540.5526 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 251 - Loss:   791.4210 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 252 - Loss:   519.4409 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 253 - Loss:   626.5916 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 254 - Loss:   812.1234 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 255 - Loss:   204.6158 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 256 - Loss:   554.7433 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 257 - Loss:   437.4140 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 258 - Loss:   694.4943 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 259 - Loss:   650.3295 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 260 - Loss:   717.9420 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 261 - Loss:   825.2451 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 262 - Loss:   732.7893 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 263 - Loss:   799.8945 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 264 - Loss:   903.9255 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 265 - Loss:   395.2537 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 266 - Loss:   547.7927 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 267 - Loss:   331.0163 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 268 - Loss:  1202.5845 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 269 - Loss:   234.6082 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 270 - Loss:   403.6524 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 271 - Loss:   232.2465 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 272 - Loss:   724.3663 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 273 - Loss:   392.5486 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 274 - Loss:  1012.6643 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 275 - Loss:   180.6670 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 276 - Loss:   480.9753 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 277 - Loss:   788.8633 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 278 - Loss:   822.2246 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 279 - Loss:   799.6872 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 280 - Loss:   368.1908 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 281 - Loss:   643.6344 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 282 - Loss:   413.9709 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 283 - Loss:   582.4369 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 284 - Loss:   730.1891 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 285 - Loss:   393.8588 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 286 - Loss:   569.8762 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  7, Batch 287 - Loss:   856.9902 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 288 - Loss:   501.3575 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  7, Batch 289 - Loss:   446.3363 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 290 - Loss:   409.7270 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 291 - Loss:   349.6375 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 292 - Loss:  1117.8296 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 293 - Loss:   458.0733 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 294 - Loss:   496.0030 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 295 - Loss:   989.1196 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 296 - Loss:   600.2914 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 297 - Loss:   891.7770 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 298 - Loss:   607.8447 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 299 - Loss:   687.3221 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 300 - Loss:   971.8666 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 301 - Loss:   483.7855 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 302 - Loss:   614.6757 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 303 - Loss:   259.1405 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 304 - Loss:   963.6376 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 305 - Loss:   343.0598 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 306 - Loss:   766.0453 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 307 - Loss:   789.1042 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 308 - Loss:   404.8871 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 309 - Loss:   524.6089 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 310 - Loss:   579.0396 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 311 - Loss:   380.9365 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 312 - Loss:   875.7471 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 313 - Loss:   179.7545 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 314 - Loss:   698.7975 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 315 - Loss:   588.7076 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 316 - Loss:   764.6243 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 317 - Loss:   342.4821 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  7, Batch 318 - Loss:   518.5745 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 319 - Loss:  1158.5382 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 320 - Loss:   524.9932 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 321 - Loss:   382.1592 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 322 - Loss:   603.4866 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 323 - Loss:   451.9067 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 324 - Loss:   366.8683 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 325 - Loss:   407.3371 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 326 - Loss:   558.8895 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 327 - Loss:   528.3229 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 328 - Loss:   542.5399 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 329 - Loss:   782.9893 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 330 - Loss:   434.4432 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 331 - Loss:   839.6140 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 332 - Loss:   322.2177 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 333 - Loss:   702.6757 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 334 - Loss:   740.0754 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 335 - Loss:   737.8774 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 336 - Loss:   725.2727 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 337 - Loss:   570.7333 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 338 - Loss:  1085.6514 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 339 - Loss:   920.9163 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 340 - Loss:    90.6693 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 341 - Loss:   315.4572 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 342 - Loss:   325.4421 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 343 - Loss:   716.5791 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 344 - Loss:   527.1136 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 345 - Loss:   382.3430 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 346 - Loss:   485.6573 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  7, Batch 347 - Loss:   556.5859 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 348 - Loss:   921.3927 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 349 - Loss:   621.7320 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 350 - Loss:   947.5950 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 351 - Loss:   419.5521 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 352 - Loss:   702.8315 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 353 - Loss:   821.1835 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 354 - Loss:   278.8719 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 355 - Loss:   541.4728 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 356 - Loss:   371.6317 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 357 - Loss:   660.9733 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 358 - Loss:   685.1880 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 359 - Loss:   405.6804 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 360 - Loss:   443.0445 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 361 - Loss:   328.5670 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 362 - Loss:   425.3680 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 363 - Loss:   275.1505 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 364 - Loss:   790.7888 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 365 - Loss:   260.6371 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 366 - Loss:   384.7124 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 367 - Loss:  1043.4163 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 368 - Loss:   688.5053 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 369 - Loss:   299.3740 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 370 - Loss:   233.0017 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 371 - Loss:   670.8909 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 372 - Loss:   295.1411 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 373 - Loss:   640.8941 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 374 - Loss:   507.7406 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 375 - Loss:   466.3188 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 376 - Loss:   829.0013 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 377 - Loss:   851.0348 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 378 - Loss:   385.6605 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 379 - Loss:   710.5590 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 380 - Loss:   369.7360 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 381 - Loss:   528.1750 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  7, Batch 382 - Loss:   429.2263 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 383 - Loss:   383.4348 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  7, Batch 384 - Loss:   399.3210 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 385 - Loss:   474.8814 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 386 - Loss:   220.0993 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 387 - Loss:   943.2153 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 388 - Loss:   166.2892 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 389 - Loss:   737.9855 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 390 - Loss:   634.2346 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 391 - Loss:  1046.2498 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 392 - Loss:   460.0655 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 393 - Loss:   355.1268 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 394 - Loss:   645.7703 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 395 - Loss:   911.6963 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 396 - Loss:   477.3851 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 397 - Loss:  1128.3081 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 398 - Loss:   755.1071 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 399 - Loss:   634.9501 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 400 - Loss:   683.9694 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 401 - Loss:  1415.0127 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 402 - Loss:   914.9120 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 403 - Loss:   830.4030 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 404 - Loss:   750.9532 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 405 - Loss:   282.0178 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 406 - Loss:   507.5294 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 407 - Loss:   564.7611 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 408 - Loss:  1153.9580 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 409 - Loss:   169.7772 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 410 - Loss:   396.6378 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 411 - Loss:   703.1334 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 412 - Loss:   708.1595 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 413 - Loss:   425.6065 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 414 - Loss:   471.6491 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  7, Batch 415 - Loss:   679.4541 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 416 - Loss:   411.2458 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 417 - Loss:   538.6600 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 418 - Loss:   209.2845 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 419 - Loss:   375.1830 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 420 - Loss:   967.3901 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  7, Batch 421 - Loss:   716.2779 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 422 - Loss:   776.6321 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 423 - Loss:  1057.8032 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 424 - Loss:   292.6039 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  7, Batch 425 - Loss:   513.0737 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 426 - Loss:   629.2664 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 427 - Loss:   477.0918 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  7, Batch 428 - Loss:   765.9574 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  7, Batch 429 - Loss:   611.7607 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch   1 - Loss:   933.7795 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch   2 - Loss:   791.0927 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch   3 - Loss:   719.3645 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch   4 - Loss:   572.1697 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  8, Batch   5 - Loss:   667.4610 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch   6 - Loss:   891.8117 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch   7 - Loss:   672.7700 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch   8 - Loss:   519.4407 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch   9 - Loss:   440.4349 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  10 - Loss:   351.0258 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch  11 - Loss:   732.9384 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch  12 - Loss:   481.7530 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  13 - Loss:   631.7236 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  14 - Loss:   649.3193 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  15 - Loss:   314.4543 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  16 - Loss:   596.4015 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  17 - Loss:   838.8505 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  18 - Loss:   192.5792 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  19 - Loss:   423.4992 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch  20 - Loss:   412.6366 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  21 - Loss:   300.9543 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  22 - Loss:   469.2874 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  23 - Loss:   794.8503 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch  24 - Loss:   140.3612 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  25 - Loss:   601.9253 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  26 - Loss:   876.0870 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  27 - Loss:   483.5898 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch  28 - Loss:   356.2477 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  29 - Loss:   707.3604 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  30 - Loss:   430.1048 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  31 - Loss:   313.8002 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  32 - Loss:  1196.4164 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  33 - Loss:   637.6624 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  34 - Loss:   417.5370 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  35 - Loss:   488.5379 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch  36 - Loss:   193.8152 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  8, Batch  37 - Loss:   579.6759 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  38 - Loss:   377.4616 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  39 - Loss:   718.3951 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  40 - Loss:   653.3254 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  41 - Loss:   786.4474 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  42 - Loss:   451.1740 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  43 - Loss:   328.7246 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  44 - Loss:   804.8279 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  45 - Loss:   614.9888 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  46 - Loss:   516.0696 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  47 - Loss:   513.4586 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  48 - Loss:   400.0809 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  49 - Loss:   466.5806 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  50 - Loss:   907.8067 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  51 - Loss:   592.3463 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  52 - Loss:   184.5032 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  53 - Loss:   623.8041 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  54 - Loss:   709.3800 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  55 - Loss:   433.8418 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  56 - Loss:   471.2806 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  57 - Loss:  1029.9343 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  58 - Loss:   415.0411 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  59 - Loss:   210.9326 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  60 - Loss:   329.4556 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  61 - Loss:   378.3543 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  62 - Loss:   291.8954 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  63 - Loss:  1087.6940 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  64 - Loss:   870.0437 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  65 - Loss:   525.4619 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  66 - Loss:   239.9069 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  67 - Loss:   980.8737 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  68 - Loss:   719.1439 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  69 - Loss:   475.2076 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  70 - Loss:   639.6707 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  71 - Loss:   417.2815 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  72 - Loss:   314.5266 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  73 - Loss:   930.2161 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  74 - Loss:   369.1281 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch  75 - Loss:   331.4936 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  76 - Loss:   415.8804 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch  77 - Loss:   538.1204 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  78 - Loss:   783.4017 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  79 - Loss:   475.4910 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  80 - Loss:   888.7088 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  81 - Loss:   393.5815 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  82 - Loss:   548.2039 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch  83 - Loss:   479.1490 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  84 - Loss:   269.4621 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  85 - Loss:   345.5363 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  86 - Loss:   855.5108 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  87 - Loss:   369.6863 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  88 - Loss:   405.1231 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  89 - Loss:   477.1995 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  90 - Loss:   454.4146 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  91 - Loss:   591.9567 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  92 - Loss:   604.1932 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  93 - Loss:   970.9058 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  94 - Loss:   497.7376 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  95 - Loss:   434.5855 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch  96 - Loss:   328.3740 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch  97 - Loss:   409.8964 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  98 - Loss:   575.9249 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch  99 - Loss:   493.8752 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 100 - Loss:   810.3740 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 101 - Loss:   364.7609 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 102 - Loss:   246.7405 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 103 - Loss:   477.9499 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 104 - Loss:   558.9283 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 105 - Loss:   591.1864 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 106 - Loss:   456.5334 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 107 - Loss:   414.6988 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 108 - Loss:   669.4978 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 109 - Loss:   705.7806 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 110 - Loss:   301.2413 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 111 - Loss:   286.8763 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 112 - Loss:   809.8408 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 113 - Loss:   386.5045 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 114 - Loss:   299.9167 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 115 - Loss:   393.9826 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 116 - Loss:   649.8796 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 117 - Loss:   385.0260 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 118 - Loss:   548.6747 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 119 - Loss:   449.7166 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 120 - Loss:  1008.8655 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 121 - Loss:   635.3395 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 122 - Loss:   653.1906 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 123 - Loss:   640.5891 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 124 - Loss:   366.5935 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 125 - Loss:   789.1675 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 126 - Loss:   235.9912 Validation Accuracy: 0.898438\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 127 - Loss:   377.2336 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 128 - Loss:   478.8423 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 129 - Loss:   497.1365 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 130 - Loss:   653.7879 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 131 - Loss:   507.5058 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 132 - Loss:   585.9569 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 133 - Loss:   710.6780 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 134 - Loss:   483.4024 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 135 - Loss:   363.2898 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 136 - Loss:   670.7303 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 137 - Loss:   769.3756 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 138 - Loss:   237.3524 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 139 - Loss:   393.7648 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 140 - Loss:   603.5371 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 141 - Loss:  1010.4653 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 142 - Loss:   850.7206 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 143 - Loss:   105.4669 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 144 - Loss:   468.4700 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 145 - Loss:   107.1761 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 146 - Loss:   572.2951 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 147 - Loss:   353.4480 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 148 - Loss:   669.9374 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 149 - Loss:   620.3643 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 150 - Loss:   416.0983 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 151 - Loss:   386.5942 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 152 - Loss:   630.9384 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 153 - Loss:   481.9052 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 154 - Loss:   417.8539 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 155 - Loss:   259.7930 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 156 - Loss:   733.2572 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 157 - Loss:   410.4783 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 158 - Loss:   229.3203 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 159 - Loss:   355.5880 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 160 - Loss:   551.6716 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 161 - Loss:   470.1736 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.89453125\n",
      "Epoch  8, Batch 162 - Loss:   499.6873 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 163 - Loss:   413.4838 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 164 - Loss:   443.0912 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 165 - Loss:   786.9367 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 166 - Loss:   699.1354 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 167 - Loss:  1092.4279 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 168 - Loss:   649.3767 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 169 - Loss:   708.5376 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 170 - Loss:   559.4350 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 171 - Loss:   335.7362 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.8984375\n",
      "Epoch  8, Batch 172 - Loss:   797.6859 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 173 - Loss:   409.5430 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 174 - Loss:   731.5720 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 175 - Loss:   349.4274 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 176 - Loss:   475.5658 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 177 - Loss:   584.1562 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 178 - Loss:   417.5656 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 179 - Loss:   639.1468 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 180 - Loss:   556.2834 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 181 - Loss:   505.7651 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 182 - Loss:   417.0101 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 183 - Loss:   835.2072 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 184 - Loss:   812.5753 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 185 - Loss:   494.4575 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 186 - Loss:   373.3814 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 187 - Loss:   169.3135 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 188 - Loss:   522.0674 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 189 - Loss:   453.5840 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 190 - Loss:   652.0120 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  8, Batch 191 - Loss:   634.0287 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 192 - Loss:   564.6316 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 193 - Loss:   611.2483 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 194 - Loss:   501.2451 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 195 - Loss:   294.1525 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 196 - Loss:   419.5125 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 197 - Loss:   494.7891 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 198 - Loss:   965.7607 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 199 - Loss:   714.0289 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 200 - Loss:   197.5088 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 201 - Loss:   550.0560 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 202 - Loss:   472.6519 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 203 - Loss:   343.3481 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 204 - Loss:   297.9583 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 205 - Loss:   529.5100 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 206 - Loss:   608.8353 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 207 - Loss:   614.0648 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 208 - Loss:   413.8431 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 209 - Loss:   673.1041 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 210 - Loss:   308.3877 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 211 - Loss:   510.2722 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 212 - Loss:   439.5412 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 213 - Loss:   466.0525 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 214 - Loss:   673.3633 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 215 - Loss:   648.9374 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 216 - Loss:   233.6984 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 217 - Loss:   594.3563 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 218 - Loss:   774.3552 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 219 - Loss:   556.1896 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 220 - Loss:   414.7939 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 221 - Loss:   894.8295 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 222 - Loss:   490.4453 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 223 - Loss:   420.3387 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 224 - Loss:   453.0795 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 225 - Loss:   863.6697 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 226 - Loss:   462.8660 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 227 - Loss:   888.4420 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 228 - Loss:   370.8787 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 229 - Loss:   259.1597 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 230 - Loss:   981.6968 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 231 - Loss:   254.9803 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 232 - Loss:   274.1546 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 233 - Loss:   886.8328 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 234 - Loss:   374.6177 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 235 - Loss:   711.5487 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 236 - Loss:   560.0193 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 237 - Loss:   604.7205 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 238 - Loss:   486.6340 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 239 - Loss:   131.4054 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 240 - Loss:   234.5673 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 241 - Loss:   907.0391 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 242 - Loss:   563.7907 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 243 - Loss:   427.3248 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 244 - Loss:   244.0853 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 245 - Loss:   393.0790 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 246 - Loss:   317.2687 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 247 - Loss:   316.7864 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 248 - Loss:   221.5903 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 249 - Loss:   664.4512 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 250 - Loss:   607.9658 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 251 - Loss:   794.0095 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 252 - Loss:   365.4424 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 253 - Loss:   380.8410 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 254 - Loss:   536.8369 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 255 - Loss:   424.9550 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 256 - Loss:   388.9137 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 257 - Loss:   924.2050 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 258 - Loss:   762.6375 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 259 - Loss:   661.5168 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 260 - Loss:   794.6984 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 261 - Loss:  1040.3989 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 262 - Loss:   569.6578 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 263 - Loss:   268.9514 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 264 - Loss:   436.0000 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 265 - Loss:   476.4210 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 266 - Loss:   424.0268 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 267 - Loss:   672.3021 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 268 - Loss:   758.1352 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 269 - Loss:   427.5916 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 270 - Loss:   530.8094 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 271 - Loss:   375.1500 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 272 - Loss:   513.4355 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 273 - Loss:   472.3501 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 274 - Loss:   530.6487 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 275 - Loss:   340.8712 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 276 - Loss:   528.6133 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 277 - Loss:   791.3298 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 278 - Loss:   720.7778 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 279 - Loss:   400.4601 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 280 - Loss:   417.5417 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 281 - Loss:   748.0770 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 282 - Loss:   293.4430 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  8, Batch 283 - Loss:   678.8453 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 284 - Loss:   500.2347 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 285 - Loss:   711.1573 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 286 - Loss:   508.5068 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 287 - Loss:   479.1374 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 288 - Loss:   488.2020 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 289 - Loss:   382.8139 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 290 - Loss:   504.2516 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 291 - Loss:  1075.6191 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 292 - Loss:   242.2779 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 293 - Loss:   776.0725 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 294 - Loss:   517.6772 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 295 - Loss:   553.1182 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 296 - Loss:   429.0129 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 297 - Loss:   730.6033 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 298 - Loss:   505.3003 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 299 - Loss:   710.5314 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 300 - Loss:   577.9453 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 301 - Loss:  1090.7839 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 302 - Loss:   501.8753 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 303 - Loss:   603.6951 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 304 - Loss:   475.3161 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 305 - Loss:   669.9334 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 306 - Loss:   911.8439 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 307 - Loss:   434.2998 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 308 - Loss:   598.4731 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 309 - Loss:   370.3762 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 310 - Loss:   191.0407 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 311 - Loss:   715.6090 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 312 - Loss:   400.8254 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 313 - Loss:   551.9125 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 314 - Loss:   264.4094 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 315 - Loss:   665.7018 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 316 - Loss:   581.3365 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 317 - Loss:   627.3895 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 318 - Loss:   301.0835 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 319 - Loss:   738.1298 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 320 - Loss:   591.2083 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 321 - Loss:   660.1165 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 322 - Loss:   631.5823 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 323 - Loss:   732.7645 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 324 - Loss:   357.9745 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 325 - Loss:   687.9796 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 326 - Loss:   334.7580 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 327 - Loss:   387.3586 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 328 - Loss:   606.5232 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 329 - Loss:   657.2526 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 330 - Loss:   291.7683 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 331 - Loss:   424.5497 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 332 - Loss:   483.3171 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 333 - Loss:   375.7328 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 334 - Loss:   753.7684 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 335 - Loss:   675.2654 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 336 - Loss:   564.9047 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 337 - Loss:   386.2638 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 338 - Loss:   718.5962 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 339 - Loss:   578.6205 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 340 - Loss:   628.4760 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 341 - Loss:   596.6960 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 342 - Loss:  1082.5415 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 343 - Loss:   431.5081 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 344 - Loss:   682.2277 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 345 - Loss:   914.4651 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 346 - Loss:   704.2061 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 347 - Loss:   674.4375 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 348 - Loss:   608.4352 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 349 - Loss:   516.7606 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 350 - Loss:   802.5419 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 351 - Loss:   207.7690 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 352 - Loss:   384.7239 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 353 - Loss:   213.3076 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 354 - Loss:   594.6786 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 355 - Loss:   399.7155 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 356 - Loss:   727.6713 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 357 - Loss:   288.0955 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 358 - Loss:   609.3542 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 359 - Loss:   740.1028 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 360 - Loss:   304.0157 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 361 - Loss:   379.6640 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 362 - Loss:   408.3659 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 363 - Loss:   748.2185 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 364 - Loss:   519.5845 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 365 - Loss:   562.4561 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 366 - Loss:   792.9855 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 367 - Loss:   507.3022 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 368 - Loss:   328.3475 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 369 - Loss:   976.7948 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 370 - Loss:   984.8869 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  8, Batch 371 - Loss:   373.8763 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 372 - Loss:   749.9650 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 373 - Loss:   166.3459 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 374 - Loss:   607.6515 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 375 - Loss:   540.0359 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 376 - Loss:   814.9247 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 377 - Loss:   262.7020 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 378 - Loss:   187.6807 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 379 - Loss:   134.5727 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  8, Batch 380 - Loss:   623.2966 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 381 - Loss:   438.1605 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 382 - Loss:   461.7130 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 383 - Loss:   648.0088 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 384 - Loss:   690.6302 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 385 - Loss:   537.3382 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 386 - Loss:   648.5747 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 387 - Loss:   502.8528 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 388 - Loss:   308.2828 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 389 - Loss:   866.0253 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 390 - Loss:   573.7092 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 391 - Loss:   361.2589 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 392 - Loss:   602.3114 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 393 - Loss:    93.7603 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 394 - Loss:   546.1632 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 395 - Loss:   412.3336 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 396 - Loss:   183.3353 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 397 - Loss:   590.7061 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 398 - Loss:   473.6420 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 399 - Loss:   558.3134 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 400 - Loss:   432.4008 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 401 - Loss:   476.2850 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 402 - Loss:   225.6614 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 403 - Loss:   756.4611 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 404 - Loss:   326.0598 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 405 - Loss:   848.7744 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 406 - Loss:   442.2346 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 407 - Loss:   339.0791 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 408 - Loss:   809.1665 Validation Accuracy: 0.902344\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 409 - Loss:   375.1473 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 410 - Loss:   666.0541 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 411 - Loss:   605.9907 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  8, Batch 412 - Loss:   247.4594 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 413 - Loss:   488.9880 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 414 - Loss:   518.9868 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 415 - Loss:   266.2617 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  8, Batch 416 - Loss:   563.3540 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 417 - Loss:   836.3055 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  8, Batch 418 - Loss:   524.9888 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 419 - Loss:   483.2291 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  8, Batch 420 - Loss:   333.2738 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 421 - Loss:   464.6701 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  8, Batch 422 - Loss:   707.3708 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  8, Batch 423 - Loss:   874.3892 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  8, Batch 424 - Loss:   651.6511 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 425 - Loss:   638.8105 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 426 - Loss:   757.3273 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 427 - Loss:   239.2087 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 428 - Loss:   566.2765 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  8, Batch 429 - Loss:   784.9117 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch   1 - Loss:   763.6598 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch   2 - Loss:   334.1397 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch   3 - Loss:   297.2234 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch   4 - Loss:   316.1752 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch   5 - Loss:   407.5951 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch   6 - Loss:   354.2258 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch   7 - Loss:   511.1987 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch   8 - Loss:   518.1801 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch   9 - Loss:   609.8505 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  10 - Loss:   686.8810 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  11 - Loss:   315.9941 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch  12 - Loss:   557.2102 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  13 - Loss:   517.1862 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  14 - Loss:   755.1823 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  15 - Loss:   665.3807 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  16 - Loss:   782.9401 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  17 - Loss:   390.0132 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  18 - Loss:   282.2236 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  19 - Loss:   515.8583 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  20 - Loss:   589.6883 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  9, Batch  21 - Loss:   874.6510 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  22 - Loss:   391.9772 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  23 - Loss:   597.5094 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  24 - Loss:   815.7483 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  25 - Loss:   362.3789 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  26 - Loss:   684.5859 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  27 - Loss:   488.9449 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  28 - Loss:  1044.8398 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  29 - Loss:   591.4620 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  30 - Loss:   359.2446 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  31 - Loss:   472.1033 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  32 - Loss:   195.3667 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  33 - Loss:   339.6431 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  34 - Loss:   550.4575 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  35 - Loss:   257.0880 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch  36 - Loss:   410.5883 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  37 - Loss:   584.9199 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch  38 - Loss:   417.5959 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  39 - Loss:   410.9594 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  40 - Loss:   407.7558 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  41 - Loss:   458.2701 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch  42 - Loss:   493.6931 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  43 - Loss:   270.6323 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  44 - Loss:   712.0900 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  45 - Loss:   252.2464 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  46 - Loss:   993.1093 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  47 - Loss:   393.9427 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  48 - Loss:   689.5718 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  49 - Loss:   442.1452 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  50 - Loss:   604.9075 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  51 - Loss:   646.1926 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  52 - Loss:   659.7404 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  53 - Loss:   653.0679 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  54 - Loss:    81.1322 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  55 - Loss:   242.7399 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  56 - Loss:   433.0031 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  57 - Loss:   204.0077 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  58 - Loss:   630.1570 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  59 - Loss:   271.7885 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  60 - Loss:   463.9443 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  61 - Loss:   415.4305 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  62 - Loss:   466.8597 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  63 - Loss:   567.7617 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  64 - Loss:   609.7499 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  65 - Loss:   716.4883 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  66 - Loss:   428.9686 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  67 - Loss:   533.7261 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  68 - Loss:   338.4079 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  69 - Loss:   371.0692 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  70 - Loss:   592.7395 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  71 - Loss:   150.0105 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  72 - Loss:   437.2317 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  73 - Loss:   527.2386 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  74 - Loss:   498.3644 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  75 - Loss:   922.7794 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  76 - Loss:   650.1268 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  77 - Loss:   886.9588 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  78 - Loss:   321.1794 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  79 - Loss:   131.5456 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  80 - Loss:   563.2145 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  81 - Loss:   209.3415 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch  82 - Loss:   257.7775 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  83 - Loss:   685.3602 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  84 - Loss:   427.2635 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  85 - Loss:   347.8754 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  86 - Loss:   576.8233 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  87 - Loss:  1038.4385 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch  88 - Loss:   281.8066 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  89 - Loss:   371.4268 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  90 - Loss:   177.5936 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  9, Batch  91 - Loss:   340.0813 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  92 - Loss:   354.9063 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  93 - Loss:   487.2253 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  94 - Loss:   166.0494 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  95 - Loss:   908.5389 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch  96 - Loss:   791.3419 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  97 - Loss:   599.0353 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch  98 - Loss:   353.6560 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch  99 - Loss:   247.9264 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 100 - Loss:   940.8949 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 101 - Loss:   779.4344 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 102 - Loss:   711.0740 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 103 - Loss:   614.9579 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 104 - Loss:   710.1666 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 105 - Loss:   316.0484 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 106 - Loss:   589.0776 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 107 - Loss:   385.8311 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 108 - Loss:   400.3389 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 109 - Loss:   529.5325 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 110 - Loss:   583.3846 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 111 - Loss:   859.2358 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 112 - Loss:   190.3976 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 113 - Loss:   952.9786 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 114 - Loss:   854.3458 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 115 - Loss:   192.4652 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 116 - Loss:   555.2836 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 117 - Loss:   350.4349 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 118 - Loss:   148.9103 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 119 - Loss:   482.0020 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 120 - Loss:   602.5137 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 121 - Loss:   554.5576 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 122 - Loss:   800.4976 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 123 - Loss:   512.0490 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 124 - Loss:   395.4492 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 125 - Loss:   400.4891 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 126 - Loss:   530.1859 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 127 - Loss:   259.8171 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 128 - Loss:   791.0845 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 129 - Loss:   845.2133 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 130 - Loss:   248.4821 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 131 - Loss:   860.9319 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 132 - Loss:   283.0805 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 133 - Loss:   330.8452 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 134 - Loss:   799.8746 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 135 - Loss:   462.4555 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 136 - Loss:   587.0030 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 137 - Loss:   884.0929 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 138 - Loss:   358.2412 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 139 - Loss:   168.7830 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 140 - Loss:   209.6982 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 141 - Loss:   760.5192 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 142 - Loss:   248.0137 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 143 - Loss:   393.6848 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 144 - Loss:   756.6067 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 145 - Loss:   389.3494 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 146 - Loss:  1012.1572 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 147 - Loss:   617.4750 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 148 - Loss:   539.9092 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 149 - Loss:   392.6092 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 150 - Loss:   585.6428 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 151 - Loss:   473.2622 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 152 - Loss:   217.0753 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 153 - Loss:   358.9611 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 154 - Loss:   838.1050 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 155 - Loss:   835.0718 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 156 - Loss:   251.7071 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 157 - Loss:   896.7531 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 158 - Loss:   785.1175 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 159 - Loss:   724.8537 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 160 - Loss:   666.7851 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 161 - Loss:   230.1546 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 162 - Loss:   210.5522 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 163 - Loss:   499.2746 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 164 - Loss:   385.1432 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 165 - Loss:   335.5113 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 166 - Loss:   505.1016 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 167 - Loss:   540.2711 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 168 - Loss:   724.0013 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 169 - Loss:   242.9506 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 170 - Loss:   537.2131 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 171 - Loss:   543.3011 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 172 - Loss:   290.9511 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 173 - Loss:   361.2969 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 174 - Loss:   239.7716 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 175 - Loss:   298.3087 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 176 - Loss:   187.3440 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 177 - Loss:   701.7795 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 178 - Loss:   417.4468 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 179 - Loss:   191.9664 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 180 - Loss:   222.6279 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 181 - Loss:   729.0233 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 182 - Loss:   642.0164 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 183 - Loss:   415.0995 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 184 - Loss:   199.4129 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 185 - Loss:   313.9568 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 186 - Loss:   587.7582 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 187 - Loss:   734.0522 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 188 - Loss:   724.3581 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 189 - Loss:   299.0613 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 190 - Loss:   227.2180 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 191 - Loss:   297.9970 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 192 - Loss:   468.0429 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 193 - Loss:   668.4954 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 194 - Loss:   146.8421 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 195 - Loss:   192.0095 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 196 - Loss:   610.0735 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 197 - Loss:  1231.2207 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 198 - Loss:   305.8510 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 199 - Loss:   609.6548 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 200 - Loss:   258.3025 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 201 - Loss:   385.8720 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 202 - Loss:   293.0076 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 203 - Loss:   821.2690 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 204 - Loss:   582.2140 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 205 - Loss:   589.5580 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 206 - Loss:   815.3743 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 207 - Loss:   361.8296 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 208 - Loss:   531.3203 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 209 - Loss:   412.1027 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 210 - Loss:   652.4140 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 211 - Loss:   227.1069 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 212 - Loss:   887.9551 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 213 - Loss:  1289.2668 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 214 - Loss:   647.0532 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  9, Batch 215 - Loss:   237.8305 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  9, Batch 216 - Loss:   593.1867 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 217 - Loss:   316.6991 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 218 - Loss:   490.5314 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 219 - Loss:   237.6741 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 220 - Loss:   330.0130 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 221 - Loss:   352.6563 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 222 - Loss:   207.8489 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 223 - Loss:   490.5456 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 224 - Loss:   552.1026 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 225 - Loss:   557.2096 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 226 - Loss:   656.8766 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 227 - Loss:   406.8314 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 228 - Loss:   402.3343 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 229 - Loss:   693.5012 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 230 - Loss:   501.9802 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 231 - Loss:   556.8879 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 232 - Loss:   306.1588 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 233 - Loss:   350.1462 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 234 - Loss:   458.7733 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 235 - Loss:   698.7983 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 236 - Loss:   323.4794 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 237 - Loss:   268.9604 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 238 - Loss:   546.7068 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 239 - Loss:   592.8425 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 240 - Loss:   585.2513 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 241 - Loss:   527.1406 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  9, Batch 242 - Loss:   326.4670 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 243 - Loss:   390.7594 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 244 - Loss:   410.9154 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 245 - Loss:   285.3414 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 246 - Loss:   108.4044 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 247 - Loss:   263.7169 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 248 - Loss:   458.3449 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 249 - Loss:   337.6595 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 250 - Loss:   296.0793 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 251 - Loss:   481.0388 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 252 - Loss:   552.1025 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 253 - Loss:   571.4590 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 254 - Loss:   527.8360 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 255 - Loss:   592.2800 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 256 - Loss:   389.0778 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 257 - Loss:   386.4725 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 258 - Loss:   298.1969 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 259 - Loss:   378.4279 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 260 - Loss:   598.5841 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 261 - Loss:   355.9399 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 262 - Loss:   598.1150 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 263 - Loss:   676.2749 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 264 - Loss:   337.1008 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 265 - Loss:   713.2399 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 266 - Loss:   627.9827 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 267 - Loss:   745.7527 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 268 - Loss:   828.6036 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 269 - Loss:   573.2091 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 270 - Loss:   409.6300 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 271 - Loss:   410.4059 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 272 - Loss:   684.6952 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 273 - Loss:   596.6815 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 274 - Loss:   434.8184 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 275 - Loss:   537.0786 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 276 - Loss:   359.9072 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 277 - Loss:   596.9098 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 278 - Loss:   611.7430 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 279 - Loss:   528.9766 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 280 - Loss:   495.2917 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 281 - Loss:   326.5833 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 282 - Loss:   374.9728 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 283 - Loss:   305.9667 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 284 - Loss:   497.4907 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 285 - Loss:   850.9323 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 286 - Loss:   339.4652 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 287 - Loss:   857.7889 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 288 - Loss:   281.9830 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 289 - Loss:   157.3259 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 290 - Loss:   755.0994 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 291 - Loss:   471.8809 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 292 - Loss:   484.0371 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 293 - Loss:   177.6400 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 294 - Loss:   335.6857 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 295 - Loss:  1005.2339 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 296 - Loss:   482.0762 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 297 - Loss:   317.4368 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 298 - Loss:   217.1984 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 299 - Loss:   362.2021 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 300 - Loss:   356.8146 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 301 - Loss:   492.4015 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 302 - Loss:   765.7985 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 303 - Loss:   691.8688 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 304 - Loss:   526.2211 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 305 - Loss:   471.8140 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 306 - Loss:   442.0281 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 307 - Loss:   329.4401 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 308 - Loss:   519.4862 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 309 - Loss:   650.7106 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 310 - Loss:   259.0549 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 311 - Loss:   174.6414 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 312 - Loss:   509.9987 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 313 - Loss:   709.7123 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 314 - Loss:   666.8917 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 315 - Loss:   799.2782 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 316 - Loss:   285.8090 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 317 - Loss:   710.1356 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 318 - Loss:   636.7145 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  9, Batch 319 - Loss:   514.7720 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 320 - Loss:   529.3598 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 321 - Loss:   434.5900 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 322 - Loss:   565.7085 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 323 - Loss:   486.7424 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 324 - Loss:   120.5148 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 325 - Loss:   617.0452 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 326 - Loss:   571.6373 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 327 - Loss:   714.5663 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 328 - Loss:   601.7598 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 329 - Loss:   471.0649 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 330 - Loss:   624.5320 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 331 - Loss:   578.6663 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 332 - Loss:   216.8505 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 333 - Loss:   356.9700 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 334 - Loss:   260.0854 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 335 - Loss:   548.1611 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 336 - Loss:   836.6622 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 337 - Loss:   501.5288 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 338 - Loss:   185.9838 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 339 - Loss:   304.7472 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 340 - Loss:   677.2296 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 341 - Loss:   659.1236 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 342 - Loss:   420.3511 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 343 - Loss:   448.3075 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 344 - Loss:   516.8490 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 345 - Loss:   346.4954 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 346 - Loss:   299.8002 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 347 - Loss:   694.2333 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 348 - Loss:   609.1195 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 349 - Loss:   517.3481 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 350 - Loss:   481.4051 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 351 - Loss:   794.3017 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 352 - Loss:   355.7398 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 353 - Loss:   324.2303 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 354 - Loss:   769.2772 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 355 - Loss:   500.4997 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 356 - Loss:   323.5576 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 357 - Loss:   415.4541 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 358 - Loss:   754.1709 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 359 - Loss:   846.5880 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 360 - Loss:   237.0508 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 361 - Loss:   437.0589 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 362 - Loss:   497.6038 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 363 - Loss:   574.4526 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 364 - Loss:   477.2343 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 365 - Loss:   279.9338 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 366 - Loss:   424.8673 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 367 - Loss:   728.2921 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 368 - Loss:   559.7838 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 369 - Loss:   740.4281 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 370 - Loss:   496.3287 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 371 - Loss:   700.9590 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 372 - Loss:   588.1060 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 373 - Loss:   386.9380 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 374 - Loss:   439.9630 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 375 - Loss:   706.8285 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 376 - Loss:   404.7195 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 377 - Loss:   480.7464 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 378 - Loss:   272.5670 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 379 - Loss:   454.8825 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch  9, Batch 380 - Loss:   550.4982 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 381 - Loss:   434.2710 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 382 - Loss:   783.0024 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 383 - Loss:   380.2441 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 384 - Loss:   568.4347 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 385 - Loss:   586.5574 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 386 - Loss:   472.2015 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 387 - Loss:   531.5651 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 388 - Loss:   948.6200 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 389 - Loss:   446.7592 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 390 - Loss:   804.4943 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 391 - Loss:   378.4674 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 392 - Loss:   454.9040 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 393 - Loss:   991.1059 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 394 - Loss:   676.2126 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 395 - Loss:   429.8448 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 396 - Loss:   862.9579 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 397 - Loss:   477.7651 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 398 - Loss:   591.1003 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 399 - Loss:   345.8875 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 400 - Loss:   507.9674 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 401 - Loss:   251.4298 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 402 - Loss:   396.3471 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 403 - Loss:   389.1869 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 404 - Loss:   175.6476 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 405 - Loss:   416.3750 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 406 - Loss:   227.1023 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.90625\n",
      "Epoch  9, Batch 407 - Loss:   450.6080 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  9, Batch 408 - Loss:   225.6941 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch  9, Batch 409 - Loss:   290.9205 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.90234375\n",
      "Epoch  9, Batch 410 - Loss:   669.4260 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch  9, Batch 411 - Loss:   437.2240 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 412 - Loss:   853.4235 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 413 - Loss:   721.8467 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 414 - Loss:   381.1211 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 415 - Loss:   384.1199 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 416 - Loss:   380.6728 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 417 - Loss:   364.3718 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.921875\n",
      "Epoch  9, Batch 418 - Loss:   352.2665 Validation Accuracy: 0.906250\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch  9, Batch 419 - Loss:   389.4746 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 420 - Loss:   637.8542 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch  9, Batch 421 - Loss:   328.7390 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 422 - Loss:   890.4092 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 423 - Loss:    68.2687 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 424 - Loss:   171.4490 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch  9, Batch 425 - Loss:   683.8156 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 426 - Loss:    99.5924 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9375\n",
      "Epoch  9, Batch 427 - Loss:   908.2919 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 428 - Loss:   374.0755 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch  9, Batch 429 - Loss:   454.5269 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch   1 - Loss:   638.2772 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch   2 - Loss:   417.3075 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch   3 - Loss:   454.6560 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch   4 - Loss:   106.5749 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch   5 - Loss:   441.8076 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch   6 - Loss:   563.9196 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch   7 - Loss:   683.3240 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch   8 - Loss:   239.2339 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch   9 - Loss:   338.4960 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  10 - Loss:   635.6175 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  11 - Loss:   372.5777 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  12 - Loss:   787.1184 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  13 - Loss:   313.6262 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  14 - Loss:   257.2295 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  15 - Loss:   274.8032 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch  16 - Loss:   404.6044 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch  17 - Loss:   681.1820 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  18 - Loss:   780.5929 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  19 - Loss:   454.2763 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  20 - Loss:   248.6135 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  21 - Loss:   552.4893 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  22 - Loss:   903.0831 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  23 - Loss:   518.1848 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  24 - Loss:   393.9933 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  25 - Loss:   901.7158 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  26 - Loss:   265.4625 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  27 - Loss:   320.6525 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  28 - Loss:   352.4774 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  29 - Loss:   221.7777 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  30 - Loss:   386.8253 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  31 - Loss:   409.6112 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  32 - Loss:   502.3370 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  33 - Loss:   171.1787 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  34 - Loss:   370.0695 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  35 - Loss:   285.3110 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  36 - Loss:   455.8198 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  37 - Loss:   331.7338 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  38 - Loss:   464.4096 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  39 - Loss:   535.4747 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  40 - Loss:   317.2260 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  41 - Loss:   534.8165 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  42 - Loss:   693.5330 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  43 - Loss:   521.7139 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  44 - Loss:   227.4216 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  45 - Loss:   632.3787 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  46 - Loss:   432.6135 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  47 - Loss:   308.8355 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  48 - Loss:   718.8633 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  49 - Loss:   483.2271 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  50 - Loss:   471.4866 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  51 - Loss:   759.0496 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  52 - Loss:   313.6756 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  53 - Loss:   440.0059 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  54 - Loss:   445.4827 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  55 - Loss:   710.8441 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  56 - Loss:   297.0883 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  57 - Loss:   526.7073 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch  58 - Loss:   560.5905 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  59 - Loss:   607.3031 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  60 - Loss:   655.8286 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  61 - Loss:   570.4298 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  62 - Loss:   568.5042 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  63 - Loss:   739.1973 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  64 - Loss:   368.0732 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  65 - Loss:   563.6239 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  66 - Loss:   719.3915 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch 10, Batch  67 - Loss:   389.9860 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  68 - Loss:   501.1272 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  69 - Loss:   408.8709 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  70 - Loss:   410.2681 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch 10, Batch  71 - Loss:   610.7151 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  72 - Loss:   392.3926 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  73 - Loss:   422.1279 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  74 - Loss:   185.0161 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch  75 - Loss:   218.2277 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  76 - Loss:   356.9656 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  77 - Loss:   435.7492 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  78 - Loss:   315.2219 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  79 - Loss:   255.9068 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  80 - Loss:   379.7320 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  81 - Loss:   558.8845 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  82 - Loss:   252.5618 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  83 - Loss:   295.4230 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  84 - Loss:   841.9808 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  85 - Loss:   339.4814 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  86 - Loss:   404.1951 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  87 - Loss:   657.5589 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  88 - Loss:   284.3234 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  89 - Loss:   386.2349 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  90 - Loss:   470.9489 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch  91 - Loss:   735.2567 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  92 - Loss:   621.5391 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  93 - Loss:   309.4516 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  94 - Loss:   267.4890 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch  95 - Loss:   231.5081 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  96 - Loss:   708.7722 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch  97 - Loss:   404.8331 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch  98 - Loss:   820.7405 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch  99 - Loss:   403.0504 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 100 - Loss:   754.4583 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 101 - Loss:   599.0012 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 102 - Loss:   789.7688 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 103 - Loss:   292.2833 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 104 - Loss:   758.7311 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 105 - Loss:   329.1310 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 106 - Loss:   252.8931 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 107 - Loss:   284.2506 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 108 - Loss:   588.3614 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 109 - Loss:   295.5817 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 110 - Loss:   340.7819 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 111 - Loss:  1029.4968 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 112 - Loss:   209.6097 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 113 - Loss:   738.6422 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 114 - Loss:   329.0900 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 115 - Loss:   399.9411 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 116 - Loss:   913.1188 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 117 - Loss:   692.9908 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 118 - Loss:   424.3756 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 119 - Loss:   370.9545 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 120 - Loss:   764.5079 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 121 - Loss:   857.7033 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 122 - Loss:   614.0904 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 123 - Loss:   632.8686 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 124 - Loss:   564.3525 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 125 - Loss:   500.3177 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 126 - Loss:   279.5299 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 127 - Loss:   681.0624 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 128 - Loss:   889.1335 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 129 - Loss:   275.6782 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 130 - Loss:   246.7080 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 131 - Loss:   515.5265 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 132 - Loss:   271.9963 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 133 - Loss:   588.8983 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 134 - Loss:   551.3256 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 135 - Loss:   341.4657 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 136 - Loss:   445.0715 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 137 - Loss:    86.3750 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 138 - Loss:   771.2368 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 139 - Loss:   411.5818 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 140 - Loss:   525.1774 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 141 - Loss:   393.0972 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 142 - Loss:   811.4147 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 143 - Loss:   783.8080 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 144 - Loss:   203.1262 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 145 - Loss:   700.9426 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 146 - Loss:   559.6619 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 147 - Loss:   176.0893 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 148 - Loss:   421.9455 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 149 - Loss:   397.2859 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 150 - Loss:   694.5032 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 151 - Loss:   557.0982 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 152 - Loss:   902.0007 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 153 - Loss:   589.9494 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 154 - Loss:   298.8151 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 155 - Loss:   450.2145 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 156 - Loss:   384.5590 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 157 - Loss:   549.9695 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 158 - Loss:   473.6747 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 159 - Loss:   300.1632 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 160 - Loss:   675.2080 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 161 - Loss:   327.9885 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 162 - Loss:   733.0696 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 163 - Loss:   274.2765 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 164 - Loss:   311.8515 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 165 - Loss:   583.3367 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 166 - Loss:   348.9548 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 167 - Loss:   897.5229 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 168 - Loss:   420.6986 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 169 - Loss:   314.8427 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 170 - Loss:   369.0052 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 171 - Loss:   596.7549 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 172 - Loss:   413.6648 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 173 - Loss:   179.6805 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 174 - Loss:   397.9510 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 175 - Loss:   360.3591 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 176 - Loss:   299.7830 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 177 - Loss:   417.4092 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 178 - Loss:   461.3849 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 179 - Loss:   853.6122 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 180 - Loss:   586.1077 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 181 - Loss:   604.4214 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 182 - Loss:   490.2031 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 183 - Loss:   459.4473 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 184 - Loss:   323.4940 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 185 - Loss:   275.0308 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 186 - Loss:   307.7531 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 187 - Loss:   273.4417 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 188 - Loss:   945.6949 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 189 - Loss:   357.7159 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 190 - Loss:   421.4377 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 191 - Loss:   661.8062 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 192 - Loss:   592.7286 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 193 - Loss:   205.4232 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 194 - Loss:    77.8676 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 195 - Loss:   389.7413 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 196 - Loss:   334.3108 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 197 - Loss:   607.7148 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 198 - Loss:   620.2286 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 199 - Loss:   682.4949 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 200 - Loss:   710.8892 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 201 - Loss:   419.8919 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 202 - Loss:   361.6729 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 203 - Loss:   884.2251 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 204 - Loss:   350.6709 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 205 - Loss:   201.6364 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 206 - Loss:   374.8092 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 207 - Loss:   523.6981 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 208 - Loss:   542.6123 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 209 - Loss:   214.3237 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 210 - Loss:   251.2128 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 211 - Loss:   465.3397 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 212 - Loss:   347.5273 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 213 - Loss:   285.9930 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 214 - Loss:   447.8446 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9140625\n",
      "Epoch 10, Batch 215 - Loss:   591.5229 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 216 - Loss:   276.7836 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 217 - Loss:   463.5016 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 218 - Loss:   132.5079 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 219 - Loss:   990.1593 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 220 - Loss:   398.9584 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 221 - Loss:   432.2254 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 222 - Loss:   538.0225 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 223 - Loss:   771.2607 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 224 - Loss:   188.7336 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 225 - Loss:   595.4669 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 226 - Loss:   230.9237 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 227 - Loss:   635.4695 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 228 - Loss:   580.9324 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 229 - Loss:   393.3212 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 230 - Loss:   513.1017 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 231 - Loss:   196.8533 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 232 - Loss:   273.1620 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 233 - Loss:   637.5825 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 234 - Loss:   488.2825 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 235 - Loss:   381.4546 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 236 - Loss:   621.5285 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 237 - Loss:   419.0400 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 238 - Loss:   584.7183 Validation Accuracy: 0.941406\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 239 - Loss:   373.4754 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 240 - Loss:   335.6812 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 241 - Loss:   181.7385 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 242 - Loss:   296.2928 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 243 - Loss:   305.3623 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 244 - Loss:   639.9195 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 245 - Loss:   397.3308 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 246 - Loss:   700.7149 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 247 - Loss:   381.0506 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 248 - Loss:   292.5058 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 249 - Loss:   717.5515 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 250 - Loss:   745.9457 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 251 - Loss:   638.7664 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 252 - Loss:   460.0394 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 253 - Loss:   662.8280 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 254 - Loss:   477.7726 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 255 - Loss:   526.3463 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 256 - Loss:   376.3967 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 257 - Loss:   351.5861 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 258 - Loss:   175.4110 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 259 - Loss:   169.2198 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 260 - Loss:   517.2872 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 261 - Loss:   776.5922 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 262 - Loss:   304.9551 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 263 - Loss:   686.4265 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 264 - Loss:   357.3218 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 265 - Loss:   427.3195 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 266 - Loss:   395.6791 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 267 - Loss:   650.7310 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 268 - Loss:   406.6242 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 269 - Loss:   168.7245 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 270 - Loss:   753.1394 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 271 - Loss:   138.1636 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 272 - Loss:  1155.1388 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 273 - Loss:   231.2038 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 274 - Loss:   492.0714 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 275 - Loss:   406.0056 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 276 - Loss:   425.1490 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 277 - Loss:   495.6352 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 278 - Loss:   415.5670 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 279 - Loss:   798.4559 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 280 - Loss:   378.1089 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 281 - Loss:   475.2559 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 282 - Loss:   700.4947 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 283 - Loss:   350.6870 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 284 - Loss:   372.9370 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 285 - Loss:   336.6303 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 286 - Loss:   217.9232 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 287 - Loss:   621.8870 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 288 - Loss:    77.4933 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 289 - Loss:   451.9128 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 290 - Loss:   326.7786 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 291 - Loss:   789.7377 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 292 - Loss:   534.5051 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 293 - Loss:   652.4418 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 294 - Loss:   262.8625 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 295 - Loss:   388.2780 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 296 - Loss:   424.2105 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 297 - Loss:   312.1398 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 298 - Loss:   438.7455 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 299 - Loss:   768.6266 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 300 - Loss:   729.3336 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 301 - Loss:   450.2921 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 302 - Loss:   415.0818 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 303 - Loss:   437.1305 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 304 - Loss:   773.7876 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 305 - Loss:   393.9436 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 306 - Loss:   643.5509 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 307 - Loss:   390.0703 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 308 - Loss:   231.2796 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 309 - Loss:   340.7366 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 310 - Loss:   454.8308 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 311 - Loss:   252.5947 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 312 - Loss:   285.2210 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 313 - Loss:   198.4760 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 314 - Loss:   404.5153 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 315 - Loss:   194.2775 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 316 - Loss:   452.2354 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 317 - Loss:   526.1101 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 318 - Loss:   760.9476 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 319 - Loss:   184.8185 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 320 - Loss:   370.7601 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 321 - Loss:   201.2639 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 322 - Loss:   856.1904 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 323 - Loss:   395.9592 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 324 - Loss:   354.2865 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 325 - Loss:   339.2895 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 326 - Loss:   312.7911 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 327 - Loss:   578.4192 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 328 - Loss:   521.0912 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 329 - Loss:   638.6232 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 330 - Loss:   752.3150 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 331 - Loss:   461.8769 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 332 - Loss:   472.6666 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 333 - Loss:   644.9792 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 334 - Loss:   521.3742 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 335 - Loss:   147.7413 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 336 - Loss:   578.4003 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 337 - Loss:   376.4183 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 338 - Loss:   155.0087 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 339 - Loss:   534.1150 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 340 - Loss:   473.4986 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 341 - Loss:   814.2037 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 342 - Loss:   584.1200 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 343 - Loss:   398.3242 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 344 - Loss:   408.2518 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 345 - Loss:   463.5613 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 346 - Loss:   846.5885 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 347 - Loss:   741.1375 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 348 - Loss:   577.3302 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 349 - Loss:   363.9521 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 350 - Loss:   283.5950 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 351 - Loss:   297.7122 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 352 - Loss:   430.2522 Validation Accuracy: 0.941406\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 353 - Loss:   224.9486 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 354 - Loss:   660.5106 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 355 - Loss:   257.4779 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 356 - Loss:   722.7289 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 357 - Loss:   393.1894 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 358 - Loss:   594.8680 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 359 - Loss:    90.9225 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 360 - Loss:   366.5507 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 361 - Loss:   254.6743 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 362 - Loss:   241.5972 Validation Accuracy: 0.937500\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 363 - Loss:   425.5370 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 364 - Loss:   236.3716 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 365 - Loss:   398.3887 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 366 - Loss:   248.7785 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9453125\n",
      "Epoch 10, Batch 367 - Loss:   280.4777 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 368 - Loss:   500.7592 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 369 - Loss:   507.8298 Validation Accuracy: 0.910156\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 370 - Loss:   476.5858 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 371 - Loss:   429.8734 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 372 - Loss:   334.9708 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 373 - Loss:   770.4900 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 374 - Loss:   298.9769 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 375 - Loss:   597.4385 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 376 - Loss:   663.3187 Validation Accuracy: 0.914062\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 377 - Loss:   353.3284 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 378 - Loss:   631.5698 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 379 - Loss:   480.2919 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 380 - Loss:   351.1677 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 381 - Loss:   633.3955 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 382 - Loss:   547.6058 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 383 - Loss:   249.9485 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 384 - Loss:   342.9951 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 385 - Loss:   534.2238 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 386 - Loss:   840.0775 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 387 - Loss:   558.5180 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 388 - Loss:   460.9886 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.91015625\n",
      "Epoch 10, Batch 389 - Loss:   164.9022 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 390 - Loss:   457.1847 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.91796875\n",
      "Epoch 10, Batch 391 - Loss:   156.8414 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 392 - Loss:   595.8873 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 393 - Loss:   749.3776 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 394 - Loss:   378.8903 Validation Accuracy: 0.917969\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 395 - Loss:   501.9958 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 396 - Loss:   659.0500 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 397 - Loss:   637.0842 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 398 - Loss:   345.3804 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 399 - Loss:   421.5323 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 400 - Loss:   304.5083 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 401 - Loss:   307.8904 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 402 - Loss:   217.7507 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 403 - Loss:   163.9114 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 404 - Loss:   267.0058 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 405 - Loss:   231.6076 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 406 - Loss:   381.0261 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 407 - Loss:   555.2496 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 408 - Loss:   413.0174 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 409 - Loss:   495.2534 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 410 - Loss:   495.5582 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.94140625\n",
      "Epoch 10, Batch 411 - Loss:   372.9967 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 412 - Loss:   462.6013 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 413 - Loss:   255.7357 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.93359375\n",
      "Epoch 10, Batch 414 - Loss:   495.6585 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 415 - Loss:   397.5366 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 416 - Loss:   632.1274 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 417 - Loss:   524.8340 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 418 - Loss:   409.3245 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9375\n",
      "Epoch 10, Batch 419 - Loss:   291.9158 Validation Accuracy: 0.921875\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 420 - Loss:   539.6645 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 421 - Loss:   414.0916 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.9296875\n",
      "Epoch 10, Batch 422 - Loss:   307.5497 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 423 - Loss:   594.2006 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 424 - Loss:   434.1402 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 425 - Loss:   333.9901 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 426 - Loss:   570.8594 Validation Accuracy: 0.925781\n",
      "Test Accuracy: 0.921875\n",
      "Epoch 10, Batch 427 - Loss:   351.0827 Validation Accuracy: 0.933594\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 428 - Loss:   231.6484 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n",
      "Epoch 10, Batch 429 - Loss:   570.0853 Validation Accuracy: 0.929688\n",
      "Test Accuracy: 0.92578125\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                    x: batch_x,\n",
    "                    y: batch_y,\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                    x: batch_x,\n",
    "                    y: batch_y, \n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                    x: mnist.validation.images[:test_valid_size],\n",
    "                    y: mnist.validation.labels[:test_valid_size],\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "            \n",
    "            # Calculate Test Accuracy\n",
    "            test_acc = sess.run(accuracy, feed_dict={\n",
    "                    x: mnist.test.images[:test_valid_size],\n",
    "                    y: mnist.test.labels[:test_valid_size],\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "- [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/index.html)\n",
    "- [Goodfellow-et-al-2016 - Deep Learning](http://www.deeplearningbook.org/)\n",
    "- [Udacity - Deep Learning](https://www.udacity.com/course/deep-learning--ud730)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow3]",
   "language": "python",
   "name": "conda-env-tensorflow3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
